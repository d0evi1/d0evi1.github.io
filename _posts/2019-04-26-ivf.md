---
layout: post
title: IVF
description: 
modified: 2019-04-26
tags: 
---

faiss中有IVF的概念。其实就是inverted file (IVF)。它在2003的《Video Google: A Text Retrieval Approach to Object Matching in Videos》中提出。我们来看下，该paper有两段提及，我们来看下：

# 一、

文本检索系统通常需要采用一些标准steps。文档首先被解析成words。接着，words通过它们的stems来表示，例如：“walk”、"walking"、"walks"会使用stem 'walk'来表示。第三，会使用stop list来拒绝常用words，比如："the"、"an"，它们很常见。剩余words接着会被分配一个唯一的id，每个document会通过一个vector来表示，该vector的components由该文档中所包含的words的词频组成。除了components会以多种方式加权外，在google的case中，一个web page的weighting取决于web pages链接到特定页的数目。上述所有steps都在实际检索前完成，在语料中的所有文档会表示成vectors集合，通过一个inverted file进行组织来更高效的检索。**一个inverted file的结构类似于一个理想的book index。在corpus中每个word都有一个entry，它会跟一个该word出现的所有文档（以及在该文档中的位置）的list。**

一个text会通过计算词频向量进行检索，并返回最近向量（通过角度）的文档。

## 二、目标检索(object retrieval)

实现-使用inverted files：在一个经典的文件结构中，所有words会存储在它们出现的文档中。一个inverted file结构，会为每个word生成一个entry（hit list），并存储在所有文档中该word的出现次数。在我们的case中，inverted file会为每个可视化的word生成一个entry，它会存储所有matches，例如：在所有帧中相同word的出现次数。document vector是非常稀疏的，使用一个inverted file可以使得检索非常快。在2GHz的pentium上使用matlab实现，查询一个4k frames的database只需要0.1秒。


# 三、faiss IVF

上面提到的都是IR中的inverted file。关于faiss IVF，Chris McCormick在它的[blog](http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/)中有提到，我们可以看下：

Inverted File Index(IVF) 是pre-filtering技术，以便你无需对所有vectors做exhaustive search。实现相当简单：**首先，你使用聚类(比如：kmeans)将数据集聚类生成较大数目（比如：100个）的数据分区(partitions)。接着，在query时，你会将你的query vector与partition centroids进行对比，（例如：找到10个最近的聚类），接着你只在这些分区上对vectors进行搜索**。

在IR中，"inverted index"指的是文本搜索索引，它会将词汇表中的每个词映射到数据文档中的所有位置。看起来有点像textbook的索引，将words映射到page numbers，因而称为inverted index。

然而，在我们的上下文中，该技术的意思是，使用k-means聚类将数据集进行划分，以便你可以重定义你的搜索（只需搜索部分分区，忽略其它）。

在构建index时，使用聚类将数据集聚到多个partitions上。在dataset中的每个vector会属于这些clusters/partitions的其中之一。对于每个partition，你都具有一个属于它的所有vectors的list（被称为：inverted file lists）。你具有关于所有这些partition centroids的一个matrix，它会被用于找出哪些partitions会进行search。

按这种方式划分数据集并不完美，因为如果一个query vector落到离它最近cluster的外面，那么它的最近邻很可能停留在多个附近的cluster上。解决该问题的简单方法是，搜索多个partitions。搜索多个附近的partitions很明显会花费更多时间，但它会给出更好的accuracy。

在搜索时，你可以比较你的query vector与所有partition centroids来找到离它最近的partition。可以配置多少个。一旦你发现了这些centroids，你只需从这些partitions中选择dataset vectors，使用product quantizer来进行KNN search。

需要注意一些术语：

- verb "probe"指的是，选择partitions进行search。代码中你会看到index参数"nprobe"意味着：有多少partitions进行probe。
- Faiss的作者喜欢使用术语：Voronoi cells（而非“dataset partitions”）。一个Voronoi cell指的是，属于一个cluster的space区域。也就是说，它会包含在space中的所有points（vector与某个cluster的centroid会比其它clusters更接近）。

# 参考

- [Video Google: A Text Retrieval Approach to Object Matching in Videos](http://www.robots.ox.ac.uk/~vgg/publications/papers/sivic03.pdf)

- [http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/](http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/)
