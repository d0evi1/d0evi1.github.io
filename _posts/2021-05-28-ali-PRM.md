---
layout: post
title: PRM介绍
description: 
modified: 2021-05-28
tags: 
---


阿里在《Personalized Re-ranking for Recommendation》中提出了PRM算法：


# 1.介绍

ranking对推荐系统很重要。由ranking算法给出的ranked list的quality对于用户满意度以及推荐系统收益来说具有很大影响。大量的ranking算法被提出来优化ranking的效果。在推荐系统中，ranking通常只考虑user-item pair features，并没有考虑在list中的其它items，特别是那些在旁边的items【8，35】。尽管pairwise和listwise的L2R方法尝试通过**将item-pair或者item-list作为input**来解决该问题，他们只关注于最优化loss function以便更好地利用labels，例如：click-through data。他们不会**显式建模在feature space中的items间的相互影响**。

一些工作【1，34，37】尝试显式建模在items间的相互影响，来对之前ranking算法给出的initial list进行refine，这被称为“re-ranking”。主要思想是，通过对intra-item patterns进行编码到feature space的方式来构建scoring function。进行feature vectors编码的SOTA方法有：RNN-based（比如：GlobalRerank，或者DLCM）。他们会将initial list来顺序feed给RNN-based结构，在每个time step输出encoded vector。然而，RNN-based方法对于建模在list间的交互来说具有局限性。之前编码的item的特征信息会随着编码距离降低。受transformer的启发，我们提出使用transformer架构来建模items间的相互影响。transformer结构使用self-attention机制，其中：任意两个items可以直接相互交叉，不会随着编码距离降级。同时，由于并行化，Transformer的encoding过程要比RNN-based方法更高效。

除了items间的交互外，对于交叉的个性化encoding功能，也要在推荐系统中的re-ranking中被考虑。推荐系统的re-ranking是user-specific的，依赖于用户偏好和意图。对于一个对价格很敏感的用户，“price”特征间的交叉对于re-ranking model来说很重要。例如，当用户关于价格对比时，具有不同价格的相似items趋向于在list中会更集中。当用户没有明显的购买意图时，在推荐列表中的items趋向于更分散。因此，我们会引入一个**个性化模块**到Transformer结构来表示在item交互上的用户偏好和意图。在list中的items与user间的交互，可以在PRM中被并行捕获。

该paper的主要贡献如下：

- **问题**。我们提出一个个性化re-ranking问题：并且首次显式地引入个性化信息到reranking任务中。实验结果表明，在list representation中引入用户表示（users' representation）的效果。
- **模型**: 我们使用Transformer并且带上个性化embedding来计算initial input ranking list的representations，并输出re-ranking score。对比起RNN-based方法，self-attention机制允许我们以一个高效地方式来建模user-specific在任意两个items间的交互影响。
- **评估**：我们在离线和在线实验上，展示了我们的方法极大地胜过SOTA方法。online A/B测试表明了它能达到更高的CTR和收益。

# 2.相关工作

略

# 3.Reranking模型公式化

在本节中，我们首先给出一些关于l2r的前置知识，以及推荐系统的reranking方法。接着，我们将问题进行公式化来求解。概念如表1所示。

Learning to Rank（也称为LTR）方法在IR和推荐的排序中被广泛使用，用来生成一个有序列表。**LTR方法会基于items的feature vector学习一个全局的scoring function**。有了这个全局函数，LTR方法会通过对candidate set中的每个item进行打分输出一个有序列表。该**全局scoring function**通常通过最小化以下的loss function L来学到：

$$
L = \sum\limits_{r \in R} l (\lbrace y_i, P(y_i | x_i;\theta) | i \in I_r \rbrace)
$$

...(1)

这里：

- R：推荐的所有用户请求的集合。
- $$I_r$$：对于请求 $$r \in R$$的items的候选集合。
- $$x_i$$：表示item i的feature space。
- $$P(y_i \mid x_i; \theta)$$是在给定参数$$\theta$$的ranking model对item i的预估点击概率。
- l是由$$y_i$$和$$P(y_i \mid x_i; \theta)$$计算的loss

然而，$$x_i$$对于学习一个好的scoring function来说是不够的。我们发现：对推荐系统来说ranking需要考虑以下额外信息：

- a) **在item pairs间的相互影响（mutual influence）**
- b) **users和items间的交叉（interaction）**

对于请求r，在item pairs间的相互影响，可以通过由给定的已经存在的LTR model中，直接从intial list $$S_r = [i_1, i_2, \cdots, i_n]$$中直接学到。【1，37，2，3】提出了更好的方法使用item-pairs间的互信息（mutual information）。然而，少量工作则会考虑在users和items间的交叉。在本paper中，我们引入一个个性化matrix PV来学习user-specific encoding function，它可以建模在item-pairs间的个性化相互影响。该模型的loss function可以公式化为等式2.

$$
L = \sum\limits_{r \in R} l (\lbrace y_i, P(y_i | X, PV; \hat{\theta}) | i \in S_r \rbrace)
$$

...(2)

其中：

- $$S_r$$：是在给定前面的ranking model时的intial list
- $$\hat{\theta}$$：是我们的re-ranking model的参数
- X：是在list中所有items的fearture matrix

# 4.个性化reranking model

在本节中，我们首先给定：我们提出的个性化reranking Model(PRM)的一个总览。接着，我们引入：我们模型的每个组件。

## 4.1 模型结构

PRM的结构如图1所示。模型包含了三个部分：

- input layer
- encoding layer
- output layer

它会将由前面ranking模型生成的关于items的initial list作为input，并输出一个rerank后的list。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/fe2283c8879479da030cc10f62961d87059dd757cc754a53b8e6a491f38547a4e717c6e04664b313de206bceddac643d?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 PRM（个性化reranking model）的详细网络结构以及它的子模块

## 4.2 Input layer

input layer的目标是：**为在intial list中所有items准备综合representations，并将它feed到encoding layer**。首先，我们有：

- 一个固定长度的intial sequential list $$S=[i_1, i_2, \cdots, i_n]$$，它由之前的ranking方法给出。
- 有一个raw feature matrix $$X \in R^{n \times d_{feature}}$$，与之前的ranking方法相同。X中的每一行表示对于每个item $$i \in S$$的raw feature vector $$x_i$$

**个性化向量（Personalized Vector（PV））**

两个items的feature vectors的encoding可以建模两者间的相互影响，**但这种influences对于用户来说影响有多深是未知的。需要学习一个user-specific encoding function**。尽管整个initial list的representation可以部分影响用户的偏好，但对于一个强大的personalized encoding function来说是不够的。如图1(b)所示，我们：

**将raw feature matrix $$X \in R^{n \times d_{feature}}$$与一个个性化矩阵$$PV \in R^{d \times d_{pv}}$$进行concat**，以便获得intermediate embedding矩阵$$E' \in R^{n \times (d_{feature} + d_{pv})}$$，如等式（3）所示。**PV通过一个预训练模型生成**，它会在以下章节中介绍。PV的效果增益会在evaluation部分介绍。

$$

E' = \left[\begin{array}
x_{i_1}; pv_{i_1} \\
x_{i_2}; pv_{i_2} \\
\cdots \\
x_{i_n}; pv_{i_n} 
\end{array}
\right]
$$

...(3)

**Position Embedding(PE)**

为了利用在initial list中的顺序信息，我们会注入一个**position embedding**： $$PE \in R^{n \times (d_{feature} + d_{pv}})$$到input embedding中。接着，使用等式(4)计算encoding layer的embedding matrix。在本paper中，一个可学习的PE会被使用，我们发现它的效果要比【24】中使用的固定的position embedding效果稍好些。

$$
E'' = \left[
\begin{array}
x_{i_1}; pv_{i_1} \\
x_{i_2}; pv_{i_2} \\
\cdots \\
x_{i_n}; pv_{i_n} 
\end{array} 
\right]
+ \left[\begin{array} 
pe_{i_1} \\
pe_{i_2} \\
\cdots \\
pe_{i_n} 
\end{array} 
\right]
$$

...(4)

最后，我们会使用一个简单的feed-forward network来将feature matrix $$E'' \in R^{n \times (d_{feature} + d_{pv})}$$转换成$$E \in R^{n \times d}$$，其中d是encoding layer的每个input vector的隐维度（latent dimensionality）。E可以公式化为等式5。

$$
E = EW^E + b^E
$$

...(5)

其中:

- $$W^E \in R^{(d_{feature} + d_{pv}) \times d}$$是投影矩阵
- $$b^E$$是d维向量

## 4.3 Encoding Layer

图1(a)中的encoding layer的目标是：**将item-pairs的相互影响与其它额外信息进行集成**，包括：用户偏好、initial list S的ranking顺序等。为了达到该目标，我们采用Transformer-like encoder，因为Transformer已经被证明在许多NLP任务中很有效，特别的是在机器翻译中具有强大的encoding和decoding能力。**Transformer中的self-attention机制非常适合在我们的re-ranking任务中，因为它会直接建模任意两个items间的相互影响，并且忽略它们间的实际距离**。没有了距离衰减（distance decay），Transformer可以捕获那些在initial list中相互相隔较远的items间的更多交互。如图1(b)所示，我们的encoding module包含了Transformer encoder的$$N_x$$个块。每个块（图1(a)）包含了一个attention layer和一个Feed-Froward Network（FFN） layer。

**Attention Layer**

attention function如等式（6）所示：

$$
Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d}}) V
$$

...（6）

其中，矩阵Q, K, V分别表示queries、keys和values。d是矩阵K的维度，为了避免inner product 的大值。softmax被用来将inner product 的值转化成value vector V的adding weight。在本paper中，我们使用self-attention，其中：Q, K, V来自相同的矩阵进行投影。

为了建模复杂的mutual influences，我们使用multi-head attention，如等式7所示：

$$
S' = MH(E) = Concat(head_1, \cdots, head_h) W^0 \\
head_i = Attention(EW^Q, EW^K, EW^V)
$$

...(7)

其中：

- $$W^Q, W^K, W^V \in R^{d \times d}$$。$$W^O \in R^{hd \times d_{model}}$$是投影矩阵。h是headers的数目。h的不同值的影响，会在下部分进行研究

**Feed-Forward Network**

该position-wise FFN主要是使用非线性和在input vectors的不同维度间的交叉来增强模型

**对Encoding Layer进行Stacking**

在position-wise FFN后，这里我们接着使用attention module作为Transformer encoder的一个block。通过将多个blocks进行stacking，我们可以获得更复杂和高阶的mutual information

## 4.4 Output Layer

output layer的function主要目的是，为在图1(b)中的每个item $$i=i_1, \cdots, i_n$$生成一个score（标记为Score(i)）。我们会使用一个linear layer，后接一个softmax layer来实现。softmax layer的输出为：每个item的点击概率，它被标记为$$P(y_i \mid X, PV; \hat{\theta})$$。我们使用$$P(y_i \mid X, PV; \hat{\theta})$$作为Score(i)来对items在one-step中进行rerank。Score(i)公式为：

$$
Score(i) = P(y_i \mid X, PV; \hat{\theta}) = softmax(F^{N_x} W^F + b^F), b \in S_r
$$

...(8)

其中：

- $$F^{(N_x)}$$是Transformer encoder的$$N_x$$块（blocks）的output。
- $$W^F$$是可学习的投影矩阵
- $$b^F$$是bias项
- n：在initial list中的items数目

在训练过程中，我们会使用click through数据作为label，并最小化以下的loss function：


$$
L = - \sum\limits_{r \in R} \sum\limits_{i \in S_r} y_i log(p(y_i | X, PV; \hat{\theta}))
$$

...(9)

## 4.5 Personalized Module

在本节中，我们会介绍该方法来**计算个性化矩阵（personlized matrix: PV），它表示user与items间的交互**。直接方法是：使用PRM model以end-to-end的方式通过reranking loss来学习PV。然而，如第3节所示，reranking task任务是：对之前的ranking方法的output进行refine。在reranking task上学到的task-specific representation会缺乏用户的泛化偏好（generic perferences）。因此，我们会**利用一个pre-trained neural network来生产用户的personalized embeddings PV，它接着会被用于PRM model中的额外features**。预训练的neural network从平台的整体click-through logs学习到。图1(c)展示了在我们paper中使用的per-trained model的结构。sigmoid layer会输出user u在item i在给定用户所有行为历史$$H_u$$以及用户的side information下的点击概率$$(P(y_i \mid H_u, u; \theta'))$$。用户的side information包括：gender、age、purchasing level等。该model的loss通过一个point-wise cross entropy function来计算，如等式（4）所示：

$$
L = \sum\limits_{i \in D} (y_i log (P(y_i | H_u, u; \theta'))) + (1 - y_i) log(1 - P(y_i | H_u, u; \theta'))
$$

...(10) 

其中:

- D是user u在该平台上展示的items集合。
- $$\theta'$$：是pre-trained model的参数矩阵
- $$y_i$$是在item i上的label（点 or 不点）

受[13]的启发，我们在sigmoid layer之前采用hidden vector作为personalized vector $$pv_i$$（图1(c)）feed给我们的PRM model。

图1(c)展示了pre-trained model的一个可能架构，其它模型(如：FM、DeepFM、DCN等)也可以作为选择用于生成PV。


# 5.实验

## 5.3 Evaluation Metrics

对于离线评估，我们使用Precision和MAP来对比不同的方法。更特别的，我们使用:

- Precision@5，Precision@10作为precision
- MAP@5，MAP@10, MAP@30作为MAP

。。。


略

- 1.[https://arxiv.org/pdf/1904.06813.pdf](https://arxiv.org/pdf/1904.06813.pdf)