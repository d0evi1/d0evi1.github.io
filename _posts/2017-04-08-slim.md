---
layout: post
title: Slim i2i介绍
description: 
modified: 2017-04-08
tags: 
---

《Local Item-Item Models for Top-N Recommendation》一文提到了slim的实现。

# 1.介绍

top-N推荐系统无处不在。它们会提供一个用户可能感兴趣的关于N个items的ranked list。

。。。

# 2.概念


# 3.相关工作

## 3.1 top-N推荐方法

在top-N推荐领域有许多工作。这里我们提出了一新的SOTA的方法。Deshpande[8]开发了一种最近邻item-based方法，它展示了item-based模型会比user-based模型生成更好的top-N推荐。Cremonesi【7】开发了pureSVD方法，它使用一个trucated SVD矩阵分解R来生成top-N的推荐。该工作表明：**将missing entries看成0会比矩阵补全方法生成更好的结果**。这也是l2r方法的观点。

### 3.1.1 topN推荐的Sparse LInaear Method（SLIM）

Ning引入了SLIM，它是首个使用使用statistical learning来计算item-item关系的方法，并表明了对top-N推荐的最好方法之一。SLIM会估计一个sparse m x m的聚合系数矩阵S。用户u在一个urated item i上的推荐分，可以通过对所有用户过往rated items进行一个sparse aggregation来计算：

$$
\sim{r}_{ui} = r_u^T s_i
$$

其中：

- $$r_u^T$$是对应于user u的R的row-vector
- $$s_i$$是matrix S的第i个column vector，通过求解以下的optimization问题来进行估计得到：

$$
minimize_{s_i} \frac{1}{2} || r_i - R s_i ||_2^2 + \frac{\beta}{2} || s_i ||_2^2 + \lambda ||s_i||_1 \\
subject\ to \ s_i >=0, and \ s_ii=0
$$

..(2)

常量 $$\beta$$和$$\lambda$$是正则参数。使用非负constraint，以便vector估计包含正系数（positive coefficients）。其中$$s_ii=0$$的constraint确认了：当计算一个item的weights时，item本身不会被用到，因为它会导致trivial solutions。

## 3.2 推荐的local models

估计多个local models的思想在O'connor[6]中被提出，它通过对rating matrix进行item-wise聚类、并为每个使用最近邻CF生成的cluster估计一个独立的local model来进行rating prediction。

Xu、【19】开发了一个方法会将users和items进行co-clusters，并在每个cluster（通过不同的CF方法，包括item-based最近邻方法）上估计一个独立的local model。一个user-item pair的predicted rating是来自于对该用户具有最大weight的subgroup的prediction。

Lee[14,15]提出了一个方法，它依赖于：rating matrix是本地low-rank。首先，neighborhoods被标记成为在user-item pairs周围的anchor points，它基于一个衡量users和items的pairs间的距离函数来生成，对于每个neighborhood会估计一个local low-rank model。该估计会以一种迭代的方式进行，其中：首先latent factors表示anchor points会被估计，接着基于与这些anchor points与 observed entries的相似度，latent factors会被重新估计，直到收敛。prediction的计算被看成是一个local models的convex组合，它会通过相对应的local anchor point的相似度对user-item pair进行加权。

GLSLIM则有些不同：

i) 在上述提到的工作中，只有local models会被考虑到；而GLSLIM也会计算一个global model，它对于每个user具有一个个性化的factor来决定在global和local信息间的相互影响（interplay）。
ii) GLSLIM会更新users的assignment到subsets上，可以更好地估计local models。
iii) Lee[14,15]使用user和item latent factors，而GLSLIM则关注于item-item models
iiv) 在[6]中，作者使用item clusters，在[19]中作者使用co-clusters，在[14,15]中他们使用user-item anchor points。而GLSLIM则使用user subsets。

# 4.提出的方法

## 4.1 动机

。。。


# 参考

- 1.[https://www-users.cs.umn.edu/~chri2951/recsy368-christakopoulouA.pdf](https://www-users.cs.umn.edu/~chri2951/recsy368-christakopoulouA.pdf)
