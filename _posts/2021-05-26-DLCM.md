---
layout: post
title: DLCM介绍
description: 
modified: 2021-05-26
tags: 
---

在《Learning a Deep Listwise Context Model for Ranking Refinement》提出了DLCM.




# 4.DEEP LISTWISE CONTEXT MODE

在该paper中，我们提出了一个DNN模型，它会包含local ranking context到LTR框架中。该模型的整体思想是：**使用一个RNN网络为每个query对应的top retrieved documents进行编码，并且基于编码后的local context model来对ranked list进行refine**。我们将该模型称为DLCM（Deep Listwise Context Model）。

使用DLCM的document ranking的pipeline包括三个steps。

- 第一个step是：一个**初始检索（initial retrieval）**，它使用标准的LTR算法。在该step中，每个query-document pair(q, d)是可以被转化成一个feature vector $$x_{(q,d)}$$以及一个size=n的ranked list $$R_q^n$$，它会基于一个全局的ranking function f为query q生成。
- 第二个step是：**一个编码过程**，它使用一个GRU的RNN对top retrieved documents的feature vectors $$X_q^n$$进行编码。RNN会一个接一个地方式从最低位置到最高位置获取documents，并生成一个latent vector $$s_n$$来表示**编码后的local context model**： $$I(R_q^n, X_q^n)$$。
- 第三个step是：一个**re-ranking过程**，其中，top documents会使用一个local ranking function $$\phi$$（它基于$$s_n$$以及RNN的hidden outputs $$o$$）来进行rerank。DLCM的整体结构如图1所示。



<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/95062c16e25983ae6600028dc558ca75ef4fe0268aabaad69ac056cc6cecb056983f5f9b8d0e93aae5a94d44e3c58c7e?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 

## 4.1 Input Document Representations

第3节所示，大多数L2R算法使用一个feature vector来表示每个query-document pair。在我们提出的框架中，DLCM使用相同的feature vectors。我们在模型输出侧不会包括其它额外的features。

直接将原始的feature vectors进行feed到我们的模型中，并不是使用NN的完整能力的最好方法。另一方法，原始features的维度会受限，并使用低维表示会限制neural encoders的表达能力。另一方面，高级feature抽象对于neural models的健壮性来说是有益的，特别是当原始input features有噪声时。受Wide&Deep模型的启发，我们使用一个two-step方法来获得DLCM的高级input表示。我们首先使用一个two-layer feed-forward network来学习原始features的抽象：

$$
z_i^{(0)} = x_{(q,d_i)} \\
z_i^{(l)} = elu(W_z^{(l-1)} \cdot z_i^{(l-1)} + b_z^{(l-1)}, l=1, 2) 
$$

其中：

- $$W_z^{(l)}$$和$$b_z^{(l)}$$是在第l个layer的weight matrix和bias。
- elu是非线性激活函数，当x>=0时，它等于x；否则为 $$e^x - 1$$。我们接着将$$z_i^{(2)}$$与原始的feature vector $$x_{(qq, d_i)}$$进行concatenate来形成一个新的input vector $$x_{(q, d_i)}'$$

假设：$$\alpha$$和$$\beta$$是$$x_{(q,d_i)}$$和$$z_i^{(2)}$$的维度。当$$beta$$等于零时，我们不会进行区分，因为$$x'(q,d_i)$$可以被缩减为$$x_{(q, d_i)}$$。

## 4.2 编码Listwise Local Context

给定由一个global ranking function f给出的top n个检索结果，以及它们的feature vectors $$X_q^n = \lbrace x_{(q,d_i)} \mid d_i \in R_q^n\rbrace$$，DLCM中的local context model I会使用一个RNN来实现。RNN是一种deep network，在顺序数据建模中常用。**一个标准的RNN包括一个输入序列，一个输出序列，以及一个state vector**。由于我们会一个接一个地feed input实例（每个实例会使用一个feature vector进行表示），RNN会根据当前input进行更新它的state vector，并在每个step生成一个新的output vector。**最终的state vector可以被看成是一个关于所有信息的编码（会feed到该网络中）**。

在DLCM中，我们使用GRU的RNN。GRU network是一个由Cho[10]提出的技术，用于解决RNN中的梯度消失问题。它的基本思想是：使用一个update gate和一个reset gate来控制网络的states的更新。正式的，假设$$x_t \in R^{\alpha}$$是在第t个step的input vector，$$\alpha$$是$$x_t$$的维度。output vector（也是在GRU中的activation vector）$$o_t \in R^{\alpha}$$，network state $$s_t \in R^{\alpha}$$会被计算为：

$$
o_t = (1-u_t) \odot o_{t-1} + u_t \odot s_t \\
u_t = \sigma(W_u^x \cdot x_t + W_u^s \cdot o_{t-1}) \\
s_t = tanh(W^x \cdot x_t + W^s \cdot (r_t \odot o_{t-1})) \\
r_t = \sigma(W_r^x \cdot x_t + W_r^s \cdot o_{t-1})
$$

...(4)

其中：

- $$\odot$$是element-wise product
- $$\sigma(x) = \frac{1}{1+e^{-x}}$$是一个sigmoid function
- $$u_t \in R^{\alpha}$$是update gate
- $$r_t \in R^{\alpha}$$是reset gate
- 所有的weight矩阵$$W^x, W^s, W_u^x, W_u^s, W_r^x, W_r^s \in R^{\alpha \times \alpha}$$是在训练过程中学到的
- encoded context 模型$$I(R_q^n, X_q^n)$$是final network state $$s_n$$

在DLCM中使用GRU的RNN天然满足一个local context model的两个需求。RNN的inputs是一个vectors序列，它可以是从LTR系统中是scalar features。由于RNN会天然地学习将current input与在network state中编码的previous input进行结合，我们不会需要人工定义heuristics来建模local ranking context。同时，RNN的结果使得它能够捕获在encoding process中的位置效果。**当我们使用input data一个接一个地输入到network中时，current input会趋向于比之前的inputs具有对当前network state更多的影响**。

**由于我们会输入排完序的top结果（从最低到最高position），在高位置的documents会对最终network state具有更多的影响**。

图一的单向RNN部分，另一个可选方法是，我们也会测试双向RNN。尽管它被认为是在NLP中的高级能力，我们观察到在检索实验中没有提升。这表明，反方向的编码信息没啥用。实际上，如果我们只使用反向方式的uni-directional RNN，DLCM的效果会更差。


## 4.3 Local context的reranking

DLCM的最后一个step是，，它通过使用一个local ranking function $$\phi$$对documents进行排序来生成一个新的ranked list。当预测一个ranking score时，function $$\phi$$同时会考虑RNN的hidden outputs，以及关于local ranking context的编码后的latent表示：假设：$$o_{n+1-i}$$是document $$d_i \in R_q^n$$的output表示，我们将local ranking function $$\phi$$定义为：

$$
\phi(o_{n+1-i, s_n}) = v_{\phi} \cdot ( o_{n+1-i} \cdot tanh(W_{\phi}\cdot s_n + b_{\phi}))
$$

...(5)

其中：

- $$W_{\phi} \in R^{\alpha \times k \times \alpha}, b_{\phi} \in R^{\alpha \times k}, V_{\phi} \in R^k$$，
- k是超参数，它控制着hidden units的数目。

**我们的local ranking function的定义是，与RNN中广泛使用的attention function相似**。在许多机器学习应用中（例如：机器翻译），一个RNN decoder需要对不同steps的input data的不同部分进行attention。例如，我们需要关注一个句子的不同部分，当我们生成一个接一个的翻译时。attention function常被用于计算在input data上的一个attention分布，并生成一个attention vector来指导一个RNN的decode过程。**在DLCM中，我们直接使用$$\phi$$的output值来对input文档进行排序**。

我们尝试其它设置：比如：将o使用x进行替代，并使用一个3-layer的FFN来实现$$\phi$$，或者一个neural tensor network。然而，它们的效果会更差，或者不明显，因此，我们只汇报了等式5.

## 4.4 Loss function

为了训练DLCM，我们实现了**两个已存在的listwise loss function（ListMLE【36】和SoftRank【34】），也提出了一个新的listwise loss function称为Attention Rank。**

**ListMLE**是一个listwise loss function，它会将LTR公式化成一个最小化likelihood loss的问题。它将ranking看成是一个顺序选择过程，并将概率定义为：从$$\phi_{m}^n=\lbrace d_j \mid j \in [m, n] \rbrace$$选择文档：

$$
P(d_i | \pi_m^n) = \frac{e^{S_i}}{\sum_{j=m}^n e^{S_j}}
$$

其中：

- $$S_i$$和$$S_j$$是$$d_i$$的$$d_j$$的ranking scores

如果我们从一个ranked list $$R_q^n$$的top开始进行选择，并在每个step后从candidate set中移除选中的document，在给定ranking scores S下，我们具有$$R_q^n$$的概率：

$$
P(R_q^n | S) = \prod_{i=1}^n P(d_i | \pi_i^n) = \prod_{i=1}^n \frac{e^{S_i}}{\sum_{j=1}^n e^{S_j}}
$$

假设：$$R_q^*$$是对于query q最可能的ranked list，接着ListMLE loss会定义为：在给定S下$$R_q^*$$的log似然的较小者。

**SoftRank**：

首先在[34]中提出，是一个listwise loss function，它直接最优化关于信息检索（比如：NDCG）的ranking metrics。假设：$$S_i$$和$$S_j$$是document $$d_i$$和$$d_j$$对于query $$q_i$$的ranking scores。SoftRank function假设：文档$$d_i$$的"real" score $$S_i'$$从一个Gaussian分布中抽出，定义为：$$N(S_i, \sigma_s^2)$$，其中，$$\sigma_s$$是一个共享平滑variance。给定该假设，$$d_i$$高于$$d_j$$的概率为：

$$
\pi_{ij} = Pr(S_i' - S_j' > 0) = \int_0^{\inf} N(S | S_i - S_j, 2 \sigma_s^2) dS
$$

...(8)

其中，$$P_j^{(1)}(r)$$是$$d_j$$的初始rank分布，当$$d_j$$是在ranked list中的唯一文档时，接着$$p_j^{(i)}(r)$$会在添加第i个文档后被计算：

$$
p_j^{(i)}(r) = p_j^{(i-1)}(r-1) \pi_{ij} + p_j^{(i-1)}(r)(1 - \pi_{ij})
$$

其中，有了最终的rank分布$$p_j^{(n)}(r)$$以及所有n个documents的label，我们可以计算在每个rank上的期望相关值，并定义一个loss function作为一个期望metric score的减法。

在本paper中，我们使用NDCG作为SoftRank的objective metric。在SoftRank中的唯一超参数是共享的smoothing variance $$\sigma_s$$。我们尝试0.1, 1.0，并观察对应的效果没有变化。这里我们统一使用0.1.

**Attention Rank**

受attention-based NN的影响，我们提出了一个Attention Rank loss function，它会对一个ranked list的评估公式化为一个attention分配过程。假设：在文档中包含的信息是相互排斥的，一个ranked list的总信息增益是每个文档的增益的累积。如果我们进一步假设：

一个文档的相关评估得分，直接受它的信息增益的影响，最好的策略是：在有限时间内，**通过分配更多attention给最好的结果、更低的attention给fair结果、以及不给不相关的结果分配attention，来最大化它的总信息增益。**Attention Rank的思想是：使用我们模型的ranking scores来计算一个attention分布，并使用attention策略（通过相关评估计算）来计算它。假设：relevance label $$y_{(q,d_i)}$$表示对于query q的文档$$d_i$$的信息增益。在一个ranked list $$R_q^n$$上的最好的attention分配策略定义如下：

$$
a_i^y = \frac{\sum\limits_{d_k \in R_q^n} \phi(y(q, d_k))}{\phi(y(q,d_i))}
$$

其中：

- $$\phi(x)$$是一个修正的指数函数，当x>0时为$$e^x$$，否则为0. 

相似的，我们会计算我们的模型$$a_i^S$$的attention分布，它使用ranking score $$S_i$$，并使用cross entropy来计算attention策略与最好的attention策略间的loss：

$$
l(R_q^n) = - \sum\limits_{d_i \in R_q^n} (a_i^y log(a_i^S) + (1-a_i^y)log(1-a_i^S))
$$

...(11)

Attention Rank不会直接预测文档的relevance labels，但会关注在ranked list中的每个结果的relative importance。因为，一个在不相关结果中的list中的fair document，会比在好结果中的list中的一个好文档会接受更多的attention。由于它会基于ranked lists来计算ranking loss，Attention Rank是一个listwise function，它不是一个 pointwise function。Attention Rank的主要优化是：它的简单和高效。通过使用修正的指数函数$$\phi(x)$$，我们可以显式分配更多的精力来最优化在训练过程中的高相关结果。使用Attention Rank的DLCM的训练，要比使用ListMLE和SoftRank的更快2倍和20倍。因而，它可以直接被用于无偏的LTR框架中。



- 1.[https://dl.acm.org/doi/pdf/10.1145/3209978.3209985](https://dl.acm.org/doi/pdf/10.1145/3209978.3209985)