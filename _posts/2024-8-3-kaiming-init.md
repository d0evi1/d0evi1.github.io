---
layout: post
title: kaiming初始化介绍
description: 
modified: 2024-8-5
tags: 
---

kaiming在MS在《Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》中提出了它的initialize方法。

# 摘要

修正激活单元（rectifiers）对于当前最先进的神经网络至关重要。在本研究中，我们从两个方面探讨了用于图像分类的修正神经网络（rectifier neural networks）。首先，我们提出了一种**参数化修正线性单元（PReLU：Parametric Rectified Linear Unit）**，它是对传统修正单元的推广。PReLU在几乎不增加额外计算成本和极小过拟合风险的情况下，提升了模型的拟合能力。其次，我们推导出一种特别考虑**修正非线性的鲁棒初始化方法**。该方法使我们能够直接从零开始训练极深的修正模型，并探索更深或更宽的网络架构。基于我们的PReLU网络（PReLU-nets），我们在ImageNet 2012分类数据集上实现了4.94%的top-5测试错误率。这比ILSVRC 2014的冠军（GoogLeNet，6.66% [29]）相对提高了26%。据我们所知，我们的成果是首次在这一视觉识别挑战中超越人类水平表现（5.1%，[22]）。

# 1. 引言

卷积神经网络（CNNs）[17, 16] 在多个视觉识别任务中展示了优于或可与人类媲美的识别准确率，包括交通标志识别 [3]、人脸识别 [30, 28] 和手写数字识别 [3, 31]。在本研究中，我们提出了一项成果，在一个更通用且更具挑战性的识别任务——1000类ImageNet数据集 [22] 的分类任务中，超越了人类水平的表现。

在过去几年中，我们见证了识别性能的巨大提升，这主要归功于两个技术方向的进步：构建更强大的模型，以及设计有效的过拟合抑制策略。一方面，由于**复杂度的增加**（例如，增加深度 [25, 29]、扩大宽度 [33, 24] 和使用更小的步幅 [33, 24, 2, 25]）、新的非线性激活函数 [21, 20, 34, 19, 27, 9] 以及复杂的层设计 [29, 11]，神经网络能够更好地拟合训练数据。另一方面，通过**有效的正则化技术[12, 26, 9, 31]、激进的数据增强 [16, 13, 25, 29] 和大规模数据 [4, 22]**，实现了更好的泛化能力。

在这些进展中，修正神经元（rectifier neuron）[21, 8, 20, 34]，例如修正线性单元（ReLU），是近年来深度网络成功的关键之一 [16]。**与传统类Sigmoid单元相比，它加速了训练过程的收敛 [16]，并带来了更好的解决方案** [21, 8, 20, 34]。尽管修正网络广泛流行，但最近的模型改进 [33, 24, 11, 25, 29] 和训练它们的理论指导 [7, 23] 很少关注修正单元的特性。

在本文中，我们从两个特别受修正单元驱动的方面研究了神经网络。首先，我们提出了一种新的ReLU泛化形式，称为**参数化修正线性单元（PReLU）**。该激活函数自适应地学习修正单元的参数，并以几乎可以忽略的额外计算成本提高了准确性。其次，我们**研究了训练非常深的修正模型的困难**。通过显式建模修正单元（ReLU/PReLU）的非线性，我们推导出一种理论上有依据的初始化方法，这有助于直接从零开始训练非常深的模型（例如，具有30个权重层）的收敛性。这为我们探索更强大的网络架构提供了更大的灵活性。

在1000类ImageNet 2012数据集上，我们的PReLU网络（PReLU-net）实现了单模型5.71%的top-5错误率，超越了所有现有的多模型结果。此外，我们的多模型结果在测试集上达到了4.94%的top-5错误率，相对于ILSVRC 2014冠军（GoogLeNet，6.66% [29]）相对提升了26%。据我们所知，我们的成果首次在这一视觉识别挑战中超越了人类水平表现（5.1%，[22]）。

# 2. 方法

在本节中，我们首先介绍PReLU激活函数（第2.1节），然后推导出用于深度修正网络的初始化方法（第2.2节），最后讨论我们的架构设计（第2.3节）。

## 2.1 参数化修正单元

我们展示了通过将无参数的ReLU激活替换为可学习的参数化激活单元，可以提高分类准确性1。

### 定义

形式上，我们考虑一个激活函数，其定义如下：

$$
f(y_i) = 
\begin{cases} 
y_i, & \text{if } y_i > 0 \\
a_i y_i, & \text{if } y_i \leq 0 
\end{cases}
$$

其中：

- $ y_i $ 是第 $ i $ 个通道上非线性激活函数 $ f $ 的输入
- $ a_i $ 是控制负半轴斜率的系数。
- 下标 $ i $ 表示我们允许非线性激活在不同通道上变化。

当 $ a_i = 0 $ 时，该函数退化为ReLU；当 $ a_i $ 是一个可学习的参数时，我们将公式（1）称为**参数化ReLU（PReLU）**。图1展示了ReLU和PReLU的形状。公式（1）等价于 $ f(y_i) = \max(0, y_i) + a_i \min(0, y_i) $。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/ace4c32426b4267101af9ad1754028fe8f2ac10cbe36def3bbce37f87a9f4e658b343172ed3a32c2e621cc5b6e8a6d1c?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图 1 ReLU vs. PReLU。对于PReLU，negative part的系数不是常数，是自适应学习的

如果 $ a_i $ 是一个较小的固定值，PReLU就变成了[20]中的**Leaky ReLU（LReLU）**（$ a_i = 0.01 $）。LReLU的动机是避免零梯度。[20]中的实验表明，与ReLU相比，LReLU对准确性的影响可以忽略不计。相反，我们的方法自适应地学习PReLU参数，并与整个模型联合训练。我们希望端到端的训练能够产生更专门的激活函数。

PReLU引入了非常少量的额外参数。额外参数的数量等于通道总数，与总权重数相比可以忽略不计。因此，我们预计不会增加过拟合的风险。我们还考虑了一种通道共享的变体：$ f(y_i) = \max(0, y_i) + a \min(0, y_i) $，其中系数 $ a $ 在一层中的所有通道之间共享。这种变体每层仅引入一个额外参数。

### 优化

PReLU可以通过反向传播[17]进行训练，并与其他层同时优化。参数 $ \{a_i\} $ 的更新公式可以通过链式法则简单推导得出。对于某一层，$ a_i $ 的梯度为：

$$
\frac{\partial E}{\partial a_i} = \sum_{y_i} \frac{\partial E}{\partial f(y_i)} \frac{\partial f(y_i)}{\partial a_i},
$$

其中 $ E $ 表示目标函数。项 $ \frac{\partial E}{\partial f(y_i)} $ 是从更深层传播的梯度。激活函数的梯度为：

$$
\frac{\partial f(y_i)}{\partial a_i} = 
\begin{cases} 
0, & \text{if } y_i > 0 \\
y_i, & \text{if } y_i \leq 0 
\end{cases}
$$

求和 $ \sum_{y_i} $ 遍历特征图的所有位置。对于通道共享的变体，$ a $ 的梯度为 $ \frac{\partial E}{\partial a} = \sum_i \sum_{y_i} \frac{\partial E}{\partial f(y_i)} \frac{\partial f(y_i)}{\partial a} $，其中 $ \sum_i $ 对层中所有通道求和。由于PReLU引入的时间复杂度在前向和反向传播中都可以忽略不计。

在更新 $ a_i $ 时，我们采用动量方法：

$$
\Delta a_i := \mu \Delta a_i + \epsilon \frac{\partial E}{\partial a_i},
$$

其中 $ \mu $ 是动量，$ \epsilon $ 是学习率。值得注意的是，我们在更新 $ a_i $ 时不使用权重衰减（L2正则化）。权重衰减倾向于将 $ a_i $ 推向零，从而使PReLU偏向ReLU。即使没有正则化，在我们的实验中，学习到的系数很少会大于1。此外，我们没有限制 $ a_i $ 的范围，因此激活函数可能是非单调的。在本文中，我们使用 $ a_i = 0.25 $ 作为初始化值。

## 对比实验

我们在一个具有14个权重层的深度但高效的模型上进行了对比实验。该模型在[10]中进行了研究（[10]中的模型E），其架构如表1所示。我们选择该模型是因为它足以代表一类非常深的模型，同时也使实验具有可行性。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/50ec4e7c11b373fef2e648753fcf881b8b80731e97d33fbcdd8b641c2d5500cd111eac669ab0f23ec36838873f54d85a?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=t1.jpg&amp;size=750">

表1

作为基线，我们在卷积层（conv）和前两个全连接层（fc）中使用ReLU进行训练。训练实现遵循[10]。在ImageNet 2012数据集上，使用10-view测试得到的top-1和top-5错误率分别为33.82%和13.34%（表2）。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/7d2cc6755a492130a7f3061cf12df36343a18289d294166d4fc66ba232cb03c333720d2cdb36e946d2f4dd098526d161?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=t2.jpg&amp;size=750">

表2

然后，我们从零开始训练相同的架构，但将所有ReLU替换为PReLU（表2）。top-1错误率降低至32.64%，相比ReLU基线提升了1.2%。表2还显示，通道独立和通道共享的PReLU表现相当。对于通道共享版本，PReLU仅比ReLU多引入了13个额外参数。然而，这些少量的额外参数发挥了关键作用，相比基线提升了1.1%。这表明自适应学习激活函数形状的重要性。

表1还展示了每层PReLU的学习系数。表1中有两个有趣的现象。首先，第一个卷积层（conv1）的系数（0.681和0.596）显著大于0。由于conv1的滤波器大多是类似Gabor滤波器的边缘或纹理检测器，学习结果表明滤波器的正负响应都被充分利用。我们认为，在滤波器数量有限（例如64个）的情况下，这是一种更经济地利用低层信息的方式。其次，对于通道独立版本，较深的卷积层通常具有较小的系数。这表明随着深度的增加，激活逐渐变得“更加非线性”。换句话说，学习到的模型倾向于在早期阶段保留更多信息，并在更深阶段变得更加具有判别性。

## 2.2 修正网络的滤波器权重初始化

与传统类Sigmoid激活网络相比，修正网络更容易训练[8, 16, 34]。但不良的初始化仍然会阻碍高度非线性系统的学习。在本小节中，我们提出了一种鲁棒的初始化方法，消除了训练极深修正网络的障碍。

最近的深度CNN大多通过从高斯分布中抽取的随机权重进行初始化[16]。在固定标准差（例如[16]中的0.01）的情况下，非常深的模型（例如>8个卷积层）难以收敛，正如VGG团队[25]所报告的那样，并且我们在实验中也观察到了这一点。为了解决这个问题，[25]中他们通过预训练一个具有8个卷积层的模型来初始化更深的模型。但这种策略需要更多的训练时间，并且可能导致较差的局部最优解。在[29, 18]中，通过在中间层添加辅助分类器来帮助收敛。

Glorot和Bengio[7]提出采用适当缩放的均匀分布进行初始化。这在[14]中被称为“Xavier”初始化。其推导基于激活是线性的假设。这一假设对于ReLU和PReLU是无效的。

接下来，我们通过考虑ReLU/PReLU推导出理论上更合理的初始化方法。在我们的实验中，我们的初始化方法使得极深的模型（例如30个卷积/全连接层）能够收敛，而“Xavier”方法[7]则无法做到。

### 前向传播情况

我们的推导主要遵循[7]。核心思想是研究每一层响应的方差。

对于卷积层，响应为：

$$
y_l = W_l x_l + b_l
$$

其中，$ x $ 是一个 $ k^2 c \times 1 $ 的向量，表示 $ c $ 个输入通道中 $ k \times k $ 像素的共位点。$ k $ 是该层的空间滤波器大小。用 $ n = k^2 c $ 表示一个响应的连接数，$ W $ 是一个 $ d \times n $ 的矩阵，其中 $ d $ 是滤波器的数量，$ W $ 的每一行表示一个滤波器的权重。$ b $ 是偏置向量，$ y $ 是输出图中某个像素的响应。我们用 $ l $ 来索引层。我们有 $ x_l = f(y_{l-1}) $，其中 $ f $ 是激活函数。我们还满足 $ c_l = d_{l-1} $。

### 3. 实现细节

#### 训练
我们的训练算法主要遵循 [16, 13, 2, 11, 25]。从短边为 $ s $ 的调整大小图像中，随机裁剪一个 224×224 的区域，并减去每个像素的均值。缩放比例 $ s $ 在 [256, 512] 范围内随机抖动，遵循 [25]。一半的随机样本会水平翻转 [16]。还使用了随机颜色变换 [16]。

与 [25] 仅在微调期间应用尺度抖动不同，我们从训练一开始就应用它。此外，与 [25] 使用较浅模型初始化较深模型不同，我们直接使用第 2.2 节中描述的初始化方法训练极深模型（我们使用公式(14)）。我们的端到端训练可能有助于提高准确性，因为它可能避免较差的局部最优解。

其他可能重要的超参数如下：权重衰减为 0.0005，动量为 0.9。在前两个全连接层中使用 Dropout（50%）。mini-batch 大小固定为 128。学习率为 1e-2、1e-3 和 1e-4，当误差趋于平稳时切换。每个模型的总 epoch 数约为 80。

#### 测试
我们采用了 SPP-net 论文 [11] 中使用的“特征图上的多视图测试”策略。我们进一步使用 [24, 25] 中的密集滑动窗口方法改进了这一策略。

我们首先在调整大小的完整图像上应用卷积层，并获取最后一个卷积特征图。在特征图中，每个 14×14 的窗口使用 SPP 层 [11] 进行池化。然后，全连接层应用于池化后的特征以计算分数。同样在水平翻转的图像上进行此操作。所有密集滑动窗口的分数取平均值 [24, 25]。我们进一步结合了多尺度的结果，如 [11] 中所述。

#### 多 GPU 实现
我们采用了一种简单的 Krizhevsky 方法 [15] 变体，用于在多个 GPU 上进行并行训练。我们在卷积层上采用“数据并行” [15]。在第一个全连接层之前同步 GPU。然后，全连接层的前向/反向传播在单个 GPU 上执行——这意味着我们没有并行化全连接层的计算。全连接层的时间成本较低，因此没有必要并行化它们。这比 [15] 中的“模型并行”实现更简单。此外，模型并行由于滤波器响应的通信引入了一些开销，并且并不比在单个 GPU 上计算全连接层更快。

我们在修改后的 Caffe 库 [14] 上实现了上述算法。我们没有增加 mini-batch 大小（128），因为准确性可能会下降 [15]。对于本文中的大型模型，我们观察到使用 4 个 GPU 时加速比为 3.8 倍，使用 8 个 GPU 时加速比为 6.0 倍。

### ReLU 与 PReLU 的比较

在表 4 中，我们在大型模型 A 上比较了 ReLU 和 PReLU。我们使用了通道独立的 PReLU 版本。为了公平比较，ReLU 和 PReLU 模型都使用相同的总 epoch 数进行训练，并且在运行相同数量的 epoch 后切换学习率。表 4 显示了三个尺度和多尺度组合的结果。最佳单尺度为 384，可能是因为它处于抖动范围 [256, 512] 的中间。在多尺度组合中，与 ReLU 相比，PReLU 将 top-1 错误率降低了 1.05%，top-5 错误率降低了 0.23%。表 2 和表 4 的结果一致表明，PReLU 在小模型和大模型上都能带来改进，且几乎没有增加计算成本。

---

### 单模型结果的比较

接下来我们比较单模型的结果。我们首先在表 5 中展示了 10-view 测试结果 [16]。这里，每个视图是一个 224 裁剪。VGG-16 的 10-view 结果基于我们使用公开模型 [25] 的测试，因为 [25] 中未报告此结果。我们最佳的 10-view 结果为 7.38%（表 5）。我们的其他模型也优于现有结果。

表 6 展示了单模型结果的比较，这些结果均通过多尺度和多视图（或密集）测试获得。我们的结果标记为 MSRA。我们的基线模型（A+ReLU，6.51%）已经显著优于 [25] 最新更新（arXiv v5）中报告的 VGG-19 最佳单模型结果 7.1%。我们认为这一提升主要归功于我们的端到端训练，无需预训练浅层模型。

此外，我们最佳的单模型（C，PReLU）的 top-5 错误率为 5.71%。这一结果甚至优于之前的所有多模型结果（表 7）。通过比较 A+PReLU 和 B+PReLU，我们发现 19 层模型和 22 层模型表现相当。另一方面，增加宽度（C 对比 B，表 6）仍然可以提高准确性。这表明当模型足够深时，宽度成为影响准确性的关键因素。

---

### 多模型结果的比较

我们结合了表 6 中的六个模型。目前我们只训练了一个架构为 C 的模型。其他模型的准确性明显低于 C。我们推测通过使用更少但更强的模型可以获得更好的结果。

多模型结果如表 7 所示。我们的测试集 top-5 错误率为 4.94%。这一数字由 ILSVRC 服务器评估，因为测试集的标签未公开。我们的结果比 ILSVRC 2014 冠军（GoogLeNet，6.66% [29]）高出 1.7%，相对提升了约 26%。这也比最新结果（百度，5.98% [32]）相对提升了约 17%。

---

### 结果分析

图 4 展示了一些通过我们的方法成功分类的验证集图像示例。除了正确预测的标签外，我们还关注 top-5 结果中的其他四个预测。其中一些标签是多对象图像中的其他对象，例如“马车”图像（图 4，第 1 行，第 1 列）包含“小巴”，算法也识别出了它。另一些标签是由于相似类别之间的不确定性，例如“鸦鹃”图像（图 4，第 2 行，第 1 列）预测了其他鸟类的标签。

图 6 展示了我们的结果（平均 4.94%）在测试集上每个类别的 top-5 错误率，按升序排列。我们的结果在 113 个类别中 top-5 错误率为零——这些类别中的图像全部被正确分类。top-5 错误率最高的三个类别是“开信刀”（49%）、“聚光灯”（38%）和“餐厅”（36%）。错误的原因是多对象的存在、小对象或类内差异较大。图 5 展示了我们的方法在这三个类别中错误分类的一些示例图像。其中一些预测标签仍然有一定的意义。

在图 7 中，我们展示了我们的结果（平均 4.94%）与我们在 ILSVRC 2014 竞赛中的结果（平均 8.06%）之间每个类别的 top-5 错误率差异。错误率在 824 个类别中降低，在 127 个类别中保持不变，在 49 个类别中增加。

# 

[https://arxiv.org/pdf/1502.01852](https://arxiv.org/pdf/1502.01852)