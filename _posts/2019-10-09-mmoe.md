---
layout: post
title: MMoE多任务学习介绍
description: 
modified: 2019-10-09
tags: 
---

google在2019《Modeling Task Relationships in Multi-task Learning with
Multi-gate Mixture-of-Experts》提出了mmoe：

# 摘要

基于神经网络的多任务学习已经在许多现实世界中的大规模应用中取得了成功，例如推荐系统。例如，在电影推荐中，除了向用户提供他们倾向于购买和观看的电影外，系统还可能优化用户之后对电影的喜好。通过多任务学习，我们的目标是构建一个单一模型，同时学习这些多个目标和任务。然而，**常用多任务模型的预测质量通常对任务之间的关系非常敏感**。因此，研究任务特定目标（task-specific objectives）与任务间（inter-task）关系之间的建模权衡是非常重要的。

在这项工作中，我们提出了一种新颖的多任务学习方法，多门控混合专家(MMoE)，它明确地从数据中学习建模任务关系。我们通过在所有任务中共享专家子模型，并将**混合专家(MoE)结构**适应于多任务学习，同时还有一个针对每个任务进行训练的门控网络以优化该任务。为了验证我们的方法在具有不同任务相关性水平的数据上的有效性，我们首先将其应用于一个我们可以控制任务相关性的合成数据集。我们展示了**当任务相关性较低时，所提出的方法比基线方法表现更好**。我们还展示了MMoE结构根据训练数据和模型初始化的不同随机性水平，带来了额外的可训练性好处。

此外，我们通过在包括一个二元分类基准测试和谷歌的大规模内容推荐系统在内的真实任务上展示MMoE的性能提升，进一步证明了我们方法的有效性。

# 1.介绍

近年来，深度神经网络模型已经在许多现实世界中的大规模应用中取得了成功，例如推荐系统[11]。这样的推荐系统通常需要同时优化多个目标。例如，在为用户推荐电影时，我们不仅希望用户购买和观看电影，还希望他们在观看后喜欢这些电影，这样他们就会回来观看更多电影。也就是说，我们可以创建模型**同时预测用户的购买行为和他们的评分**。实际上，许多大规模推荐系统已经采用了使用深度神经网络（DNN）模型的多任务学习[3]。

研究人员报告说，多任务学习模型可以通过**利用正则化和迁移学习**来改善所有任务的模型预测[8]。然而，在实践中，多任务学习模型并不总是能在所有任务上胜过相应的单任务模型[23, 26]。实际上，许多基于DNN的多任务学习模型对诸如数据分布差异和任务间关系等因素非常敏感[15, 34]。**任务差异固有的冲突**实际上可能会损害至少某些任务的预测，特别是当模型参数在所有任务中广泛共享时。

先前的工作[4, 6, 8]通过假设每个任务的特定数据生成过程，根据假设测量任务差异，然后根据任务的不同程度提出建议，来研究多任务学习中的任务差异。然而，**由于现实应用通常具有更加复杂的数据模式，通常很难测量任务差异**，并且很难利用这些先前工作的建议方法。

最近有几项工作提出了新颖的建模技术来处理多任务学习中的任务差异，而无需依赖于显式的任务差异测量[15, 27, 34]。然而，这些技术通常涉及为每个任务添加更多的模型参数以适应任务差异。由于大规模推荐系统可能包含数百万或数十亿个参数，这些额外的参数通常受到的约束不足，这可能会损害模型质量。这些参数的额外计算成本在实际生产环境中通常也是禁止的，因为服务资源有限。

在本文中，我们提出了一种基于新颖的多门控混合专家(MMoE)结构的多任务学习方法，该结构受到混合专家(MoE)模型[21]和最近的MoE layer[16, 31]的启发。**MMoE显式地建模任务关系，并学习任务特定功能（task-specific functionalities）以利用共享表示（shared representations）**。它允许参数自动分配，以捕获共享任务信息或任务特定信息，避免了为每个任务添加许多新参数的需要。

**MMoE的backbone**是建立在最常用的共享底层多任务深度神经网络(DNN)结构之上的[8]。**共享底层模型（share bottom）结构**如图1(a)所示，其中输入层之后的几层在所有任务中共享，然后每个任务在底层表示之上有一个单独的“塔”形网络。与所有任务共享一个底层网络不同，我们的模型，如图1(c)所示，有一组底层网络，**每个网络都被称为一个专家**。在我们的论文中，**每个专家是一个前馈网络**。然后我们为每个任务引入了一个**门控网络**。门控网络接收输入特征，并输出softmax门控，将不同权重的专家组合起来，允许不同任务以不同方式利用专家。组合后的专家结果随后被传递到特定任务的塔形网络中。通过这种方式，不同任务的门控网络可以学习到不同的专家组合模式，从而捕捉到任务之间的关系。



图1

为了理解MMoE如何在不同任务相关性水平下学习其专家和任务门控网络，我们进行了一个合成实验，在这个实验中，我们可以通过它们的**皮尔逊相关性来测量和控制任务相关性**。类似于[24]，我们使用两个合成回归任务，并使用正弦函数作为数据生成机制来引入非线性。在这种设置下，我们的方法在性能上超过了基线方法，**特别是当任务相关性较低时**。在这组实验中，我们还发现MMoE更容易训练，并在多次运行中收敛到更好的损失。这与最近的发现有关，即调制和门控机制可以改善在训练非凸深度神经网络时的可训练性[10, 19]。

我们进一步在基准数据集上评估了MMoE的性能，UCI人口普查收入数据集，采用多任务问题设置。我们将其与几种使用软参数共享来建模任务关系的最先进多任务模型进行了比较，并观察到我们的方法有所改进。

最后，我们在真实的大规模内容推荐系统上测试了MMoE，在这个系统中，在向用户推荐项目的同时，同时学习两个分类任务。我们训练了MMoE模型，使用了数千亿个训练实例，并将其与共享底层的生产模型进行了比较。我们观察到离线指标如AUC有显著提高。此外，我们的MMoE模型在实时实验中一致地提高了在线指标。

本文的贡献有三个方面：

- 首先，我们提出了一种新颖的多门控混合专家模型，该模型显式地建模任务关系。通过调制和门控网络，我们的模型自动调整参数化，以模拟共享信息和模拟任务特定信息。
- 其次，我们在合成数据上进行了控制实验。我们报告了任务相关性如何影响多任务学习中的训练动态，以及MMoE如何提高模型的表达能力和可训练性。
- 最后，我们在真实的基准数据和拥有数亿用户和项目的大规模生产推荐系统上进行了实验。我们的实验验证了我们提出的方法在现实世界环境中的效率和有效性。

# 2 相关工作

## 2.1 DNN中的多任务学习

多任务模型可以学习不同任务之间的共性和差异。这样做可以提高每个任务的效率和模型质量[4, 8, 30]。一种广泛使用的多任务学习模型是由Caruana[8, 9]提出的，该模型具有共享底部模型结构，其中底部隐藏层在任务之间共享。这种结构大大降低了过拟合的风险，但由于任务差异导致的优化冲突，可能会受到影响，因为所有任务都需要在共享底部层上使用同一组参数。

为了了解任务相关性如何影响模型质量，先前的工作使用合成数据生成并操纵不同类型的任务相关性，以评估多任务模型的有效性[4–6, 8]。

为了了解任务相关性如何影响模型质量，先前的工作使用合成数据生成并操纵不同类型的任务相关性，以评估多任务模型的有效性[4–6, 8]。

一些最近的方法不是在任务之间共享隐藏层和相同的模型参数，而是在任务特定参数上添加不同类型的约束[15, 27, 34]。例如，对于两个任务，Duong等人[15]在两组参数之间添加L-2约束。交叉缝合网络[27]为每个任务学习任务特定隐藏层嵌入的独特组合。Yang等人[34]使用张量分解模型为每个任务生成隐藏层参数。与共享底部模型相比，这些方法具有更多的任务特定参数，并且在任务差异导致更新共享参数时的冲突时可以实现更好的性能。然而，更多的任务特定参数需要更多的训练数据来适应，并且在大规模模型中可能效率不高。

## 2.2 子网集成与专家混合

在本文中，我们将深度学习中的一些最新发现，如参数调制和集成方法，应用于多任务学习中的任务关系建模。在DNN中，集成模型和子网集成已被证明可以提高模型性能[9, 20]。
Eigen等人[16]和Shazeer等人[31]将混合专家模型转变为基本构建块（MoE层），并将其堆叠在DNN中。MoE层具有与MoE模型相同的结构，但接受前一层的输出作为输入并向后续层输出。然后整个模型以端到端的方式进行训练。

Eigen等人[16]和Shazeer等人[31]提出的MoE层结构的主要目标是实现条件计算[7, 12]，其中网络的一部分仅在每个示例的基础上处于活动状态。对于每个输入示例，模型能够通过门控网络根据输入选择仅一部分专家。

## 2.3 多任务学习应用

得益于分布式机器学习系统的发展[13]，许多大规模现实世界应用已经采用了基于DNN的多任务学习算法，并观察到了显著的质量改进。在多语言机器翻译任务中，通过共享模型参数，具有有限训练数据的翻译任务可以通过与具有大量训练数据的任务联合学习来改进[22]。在构建推荐系统时，多任务学习被发现有助于提供上下文感知的推荐[28, 35]。在[3]中，通过共享特征表示和下层隐藏层改进了文本推荐任务。在[11]中，使用共享底部模型学习视频推荐的排名算法。类似于这些先前的工作，我们在现实世界的大规模推荐系统上评估了我们的建模方法。我们证明了得益于分布式机器学习系统的发展[13]，许多大规模现实世界应用已经采用了基于DNN的多任务学习算法，并观察到了显著的质量改进。

在多语言机器翻译任务中，通过共享模型参数，具有有限训练数据的翻译任务可以通过与具有大量训练数据的任务联合学习来改进[22]。在构建推荐系统时，多任务学习被发现有助于提供上下文感知的推荐[28, 35]。在[3]中，通过共享特征表示和下层隐藏层改进了文本推荐任务。在[11]中，使用共享底部模型学习视频推荐的排序算法。

类似于这些先前的工作，我们在现实世界的大规模推荐系统上评估了我们的建模方法。我们证明了我们的方法确实是可扩展的，并且与其他最先进的建模方法相比具有有利的性能。

# 3.前提

## 3.1 Shared-bottom Multi-task Model

我们首先介绍了图1(a)中的共享底层多任务模型，这是由Rich Caruana[8]提出并被许多多任务学习应用广泛采用的一个框架[18, 29]。因此，我们将其视为多任务建模中的代表性基线方法。

给定K个任务，该模型由一个共享底层网络组成，表示为函数𝑓，以及K个塔形网络$h_k$，其中：k=1，2，...,K。分别对应每个任务。共享底层网络跟在输入层之后，塔形网络建立在共享底层的输出之上。然后，每个任务的单独输出$y_k$跟随相应的特定任务塔形网络。对于任务k，模型可以表述为：

$$
y_k = h_k(f(x))
$$

...(1)

# 3.2 合成数据生成

先前的研究[15,27]表明，多任务学习模型的性能高度依赖于数据中固有的任务相关性。然而，在实际应用中直接研究任务相关性如何影响多任务模型具有挑战性，因为我们无法轻易改变任务间的相关性并观察其效果。因此，为了建立这种关系的实证研究，我们首先使用可以方便测量和控制任务相关性的合成数据。

受Kang等人[24]的启发，我们生成两个回归任务，并使用这两个任务标签的皮尔逊相关系数作为任务关系的量化指标。由于我们关注的是DNN模型，不同于[24]中使用的线性函数，我们采用[33]中的正弦函数组合作为回归模型。具体合成数据生成步骤如下：

1. 给定输入特征维度$d$，生成两个正交单位向量$\mathbf{u}_1, \mathbf{u}_2 \in \mathbb{R}^d$，即满足：
   $$\mathbf{u}_1^\top \mathbf{u}_2 = 0, \quad \|\mathbf{u}_1\|_2 = 1, \quad \|\mathbf{u}_2\|_2 = 1$$

2. 给定尺度常数$c$和相关性分数$-1 \leq \rho \leq 1$，生成两个权重向量$\mathbf{w}_1, \mathbf{w}_2$：
   $$\mathbf{w}_1 = c\mathbf{u}_1$$
   $$\mathbf{w}_2 = c\left( \rho\mathbf{u}_1 + \sqrt{1-\rho^2}\mathbf{u}_2 \right) \tag{2}$$

3. 随机采样一个输入数据点$\mathbf{x} \in \mathbb{R}^d$，其每个元素服从标准正态分布$N(0,1)$。

4. 为两个回归任务生成标签$y_1, y_2$：
   $$y_1 = \mathbf{w}_1^\top \mathbf{x} + \sum_{i=1}^m \sin(\alpha_i \mathbf{w}_1^\top \mathbf{x} + \beta_i) + \epsilon_1 \tag{3}$$
   $$y_2 = \mathbf{w}_2^\top \mathbf{x} + \sum_{i=1}^m \sin(\alpha_i \mathbf{w}_2^\top \mathbf{x} + \beta_i) + \epsilon_2 \tag{4}$$
   其中$\alpha_i, \beta_i$（$i=1,2,...,m$）是控制正弦函数形状的给定参数，$\epsilon_1, \epsilon_2$独立同分布于$N(0,0.01)$。

5. 重复步骤3-4直至生成足够数据量。

该合成数据生成方法通过控制参数$\rho$可以精确调节两个任务间的相关性（$\rho=1$表示完全相关，$\rho=-1$表示完全负相关，$\rho=0$表示不相关），同时通过正弦函数组合引入非线性特征，更符合DNN模型的学习特性。

# 数据生成中的相关性控制

由于非线性数据生成过程，直接生成具有给定标签皮尔逊相关性的任务并不直观。因此，我们通过调整公式(2)中权重向量的余弦相似度$\cos(\mathbf{w}_1,\mathbf{w}_2) = \rho$来间接控制相关性，随后测量生成的标签皮尔逊相关系数。需要注意的是，在线性情况下：

$$
\begin{cases}
y_1 = \mathbf{w}_1^\top \mathbf{x} + \epsilon_1 \\
y_2 = \mathbf{w}_2^\top \mathbf{x} + \epsilon_2
\end{cases}
$$

标签$y_1$和$y_2$的皮尔逊相关系数严格等于$\rho$。

在非线性情况下（公式(3)和公式(4)），如图2所示，$y_1$和$y_2$仍然保持正相关关系。为简化表述，在本文后续部分，我们将权重向量的余弦相似度直接称为"任务相关性"。



图2：标签皮尔逊相关系数 vs. 权重余弦相似度（任务相关性）。X轴表示权重向量$\mathbf{w}_1$和$\mathbf{w}_2$的余弦相似度$\cos(\mathbf{w}_1,\mathbf{w}_2) = \rho$，取值范围$[-1, 1]$。**Y轴**表示实际生成的标签$y_1$和$y_2$之间的皮尔逊相关系数

## 3.3 任务相关性的影响

为了验证在基线多任务模型设置中，任务相关性较低会损害模型质量，我们在合成数据上进行了如下对照实验：

1. 给定一组任务相关系数列表，为每个相关系数生成对应的合成数据集；
2. 在严格控制所有模型与训练超参数保持一致的前提下，分别在每个数据集上训练一个共享底层（Shared-Bottom）多任务模型；
3. 独立重复执行步骤1和2数百次，确保每次生成的数据集相互独立，但始终保持任务相关系数列表与超参数设置相同；
4. 计算每个任务相关系数下模型的平均性能表现。

图3展示了不同任务相关性对应的损失曲线。与预期一致，随着任务相关性的降低，模型性能呈现下降趋势。这一规律在多种超参数设置下均成立。此处我们仅以图3为例展示对照实验结果：

- 在该案例中，每个塔式网络（tower network）采用包含8个隐藏单元的单层神经网络结构；
- 共享底层网络为规模=16的单层网络；
- 模型基于TensorFlow [1]框架实现；
- 使用默认参数设置的Adam优化器[25]进行训练。

由于两个回归任务具有对称性，故仅需汇报其中一个任务的结果。该现象验证了我们的假设：传统多任务模型对任务间关系具有敏感性。

## 4 建模方法

### 4.1 专家混合模型（Mixture-of-Experts）

原始专家混合模型（MoE, Mixture-of-Experts）[21] 可表述为：
$$
y = \sum_{i=1}^{n} \delta(x)_i f_i(x) \quad (5)
$$
其中满足 $\sum_{i=1}^{n} \delta(x)_i = 1$，且 $\delta(x)_i$（即 $\delta(x)$ 的第 $i$ 个输出logit）表示选择专家 $f_i$ 的概率。

这里，$f_i$（$i=1,...,n$）代表 $n$ 个专家网络，$\delta$ 表示门控网络（gating network），其作用是对所有专家的输出结果进行集成。具体而言：
- 门控网络 $\delta$ 根据输入数据生成一个关于 $n$ 个专家的概率分布
- 最终输出是所有专家输出的加权和

#### MoE层结构：
虽然MoE最初是作为多个独立模型的集成方法开发的，但Eigen等人[16]和Shazeer等人[31]将其转化为基础构建模块（MoE层），并堆叠在深度神经网络（DNN）中。MoE层与原始MoE模型结构相同，但：
- 输入来自前一层的输出
- 输出传递给后一层

整个模型通过端到端方式进行训练。

Eigen等人[16]和Shazeer等人[31]提出的MoE层结构的主要目标是实现**条件计算**[7,12]——即根据每个输入样本动态激活网络的部分组件。具体表现为：对于每个输入样本，门控网络能够基于输入条件仅选择一部分专家参与计算。

## 4.2 多门控混合专家模型（Multi-gate Mixture-of-Experts）

我们提出了一种新的MoE模型，该模型旨在捕捉任务差异，同时相较于共享底层多任务模型，不需要显著增加模型参数量。这个新模型被称为多门控混合专家模型（MMoE, Multi-gate Mixture-of-Experts），其核心思想是将公式1中的共享底层网络f替换为公式5中的MoE层。更重要的是，我们为每个任务k添加了一个单独的门控网络δ^k。更准确地说，任务k的输出y_k可以表示为：

$$
y_k = h_k(f_k(x)) (6)
$$

其中f_k(x)的计算公式为：

$$
f_k(x) = Σ_{i=1}^n δ^k(x)_i f_i(x) (7)
$$

模型结构示意图请参见图1(c)。

我们的实现采用具有ReLU激活函数的相同多层感知机。门控网络简单地通过对输入进行线性变换并添加softmax层构成：

$$
δ^k(x) = softmax(W_{δ^k}x) (8)
$$

其中：

- $W_{δ^k} ∈ R^{n×d}$是一个可训练矩阵。n表示专家数量，d表示特征维度。

每个门控网络可以学习根据输入样本"选择"要使用的专家子集。这对于多任务学习中实现灵活的参数共享是非常可取的。作为一种特殊情况，如果只选择门控得分最高的单个专家，那么每个门控网络实际上将输入空间线性划分为n个区域，每个区域对应一个专家。MMoE能够通过决定不同门控产生的划分如何相互重叠，以一种复杂的方式对任务关系进行建模。如果任务相关性较低，那么共享专家会受到惩罚，这些任务的门控网络将学会利用不同的专家。相较于共享底层模型，MMoE只增加了几个额外的门控网络，而门控网络中的模型参数数量可以忽略不计。因此，整个模型仍然尽可能地享受多任务学习中的知识迁移优势。

为了理解为每个任务引入单独的门控网络如何帮助模型学习任务特定信息，我们将其与所有任务共享一个门控的网络结构进行比较。我们称之为单门控混合专家模型（OMoE, One-gate Mixture-of-Experts）。这是MoE层对共享底层多任务模型的直接改编。模型结构示意图请参见图1(b)。

## 5 MMoE在合成数据上的表现

在本节中，我们希望了解MMoE模型是否确实能够更好地处理任务相关性较低的情况。与第3.3节类似，我们在合成数据上进行对照实验来研究这个问题。我们改变合成数据的任务相关性，观察不同模型的行为变化。我们还进行了可训练性分析，结果表明基于MoE的模型相比Shared-Bottom模型更容易训练。

### 5.1 不同任务相关性数据上的表现

我们对提出的MMoE模型和两个基线模型（Shared-Bottom模型和OMoE模型）重复了第3.3节中的实验。

#### 模型结构
输入维度为100。两个基于MoE的模型都有8个专家，每个专家实现为单层网络。专家网络隐藏层的大小为16。塔式网络仍然是大小为8的单层网络。我们注意到共享专家和塔式网络中的模型参数总数为100 × 16 × 8 + 16 × 8 × 2 = 13056。对于基线Shared-Bottom模型，我们仍将塔式网络设置为大小为8的单层网络。我们将单层共享底层网络的大小设置为13056/(100 + 8 × 2) ≈ 113。

#### 实验结果
所有模型都使用Adam优化器进行训练，学习率通过网格搜索从[0.0001, 0.001, 0.01]中选取。对于每个模型-相关性对设置，我们进行了200次独立随机数据生成和模型初始化的运行。平均结果如图4所示。观察结果总结如下：

1. 对于所有模型，在相关性较高的数据上的表现都优于在相关性较低的数据上的表现。

2. MMoE模型在不同相关性数据上的表现差距比OMoE模型和Shared-Bottom模型小得多。这一趋势在我们比较MMoE模型和OMoE模型时尤为明显：在两个任务完全相同的极端情况下，MMoE模型和OMoE模型的表现几乎没有差异；然而当任务相关性降低时，OMoE模型的表现会出现明显的退化，而MMoE模型几乎不受影响。因此，在任务相关性较低的情况下，拥有针对特定任务的门控机制来建模任务差异至关重要。

3. 在所有场景下，就平均表现而言，两个MoE模型都优于Shared-Bottom模型。这表明MoE结构本身带来了额外的优势。基于这一观察，我们将在下一小节展示MoE模型比Shared-Bottom模型具有更好的可训练性。

### 5.2 可训练性

对于大型神经网络模型，我们非常关注它们的可训练性，即模型在一系列超参数设置和模型初始化范围内的鲁棒性。

最近，Collins等人[10]发现，一些我们原以为比普通RNN表现更好的门控RNN模型（如LSTM和GRU）实际上只是更容易训练，而不是具有更好的模型容量。虽然我们已经证明MMoE能够更好地处理任务相关性较低的情况，但我们还想更深入地了解它在可训练性方面的表现。

在我们的合成数据上，我们可以自然地研究模型对数据和模型初始化中随机性的鲁棒性。我们在每个设置下重复进行多次实验。每次实验数据都来自相同的分布但使用不同的随机种子，并且模型也采用不同的初始化方式。我们在图5中绘制了重复运行最终损失值的直方图。

从直方图中我们可以得到三个有趣的观察结果：

首先，在所有任务相关性设置下，Shared-Bottom模型的表现方差都比基于MoE的模型大得多。这意味着Shared-Bottom模型通常比基于MoE的模型有更多质量较差的局部最小值。

其次，虽然当任务相关性为1时，OMoE模型的表现方差与MMoE模型同样稳健，但当任务相关性降低到0.5时，OMoE的稳健性明显下降。值得注意的是，MMoE和OMoE之间唯一的区别是否有多门控结构。这验证了多门控结构在解决由任务差异引起的冲突导致的不良局部最小值方面的有效性。

最后，值得注意的是，三个模型的最低损失值是可比的。这并不令人惊讶，因为从理论上讲神经网络是通用逼近器。只要有足够的模型容量，就应该存在一个能够同时学好两个任务的"正确"Shared-Bottom模型。然而需要注意的是，这是200次独立实验运行的分布结果。我们怀疑对于更大更复杂的模型（例如当共享底层网络是循环神经网络时），获得"正确"任务关系模型的机会将更低。因此，显式地建模任务关系仍然是可取的。

# 6.实验 

略

# 参考

- 1.[https://dl.acm.org/doi/pdf/10.1145/3219819.3220007](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007)