---
layout: post
title: kuaishou CREAD介绍
description: 
modified: 2024-8-5
tags: 
---

# 摘要

观看时间是视频推荐系统中衡量用户满意度的重要指标。然而，**将观看时间作为目标变量进行预测常常受到其高度不平衡分布的阻碍，对于较大的目标值观察稀缺，而对于小值样本过多**。最先进的观看时间预测模型将连续的观看时间离散化为一组桶，以考虑观看时间的分布。然而，如何从连续的观看时间分布中创建这些离散桶的问题尚未得到充分研究，现有的离散化方法要么存在较大的学习误差(learning error)，要么存在较大的恢复误差(restoration error)。为了解决这一挑战，我们提出了一个**带有错误自适应离散化（CREAD）的分类-恢复框架，以准确预测观看时间**。所提出的框架包含一个离散化模块、一个分类模块和一个恢复模块。它通过多个分类问题来预测观看时间。离散化过程是CREAD框架的关键贡献。我们从理论上分析了离散化对学习误差和恢复误差的影响，然后提出了错误自适应离散化（EAD:error-adaptive discretization）技术，以更好地平衡这两种误差，这比传统的离散化方法实现了更好的性能。我们在公共数据集和工业数据集上进行了详细的离线评估，两者都显示出所提出方法的性能提升。此外，我们已经将我们的框架全面推广到快手应用，这是一个在线视频平台，通过A/B测试，用户的视频观看时间显著增加了0.29%。这些结果突出了CREAD框架在视频推荐系统中预测观看时间的有效性。

# 1 引言

推荐系统在匹配用户感兴趣的item方面取得了巨大成功（Herlocker 等人，2004）。其中最受欢迎的应用之一是短视频社交媒体（Tang 等人，2017；Wu, Rizoiu, 和 Xie 2018），如 TikTok 和 Instagram Reels，用户屏幕上会出现短视频，而无需任何主动操作，例如点击。因此，**传统的指标如点击率不再适用**。直观地说，**观看时间(watch time)成为衡量用户参与度的关键指标（Covington, Adams, 和 Sargin 2016）**。为确保最佳的用户体验，准确预测在线推荐系统中的观看时间至关重要。通过这样做，这些平台可以更好地了解用户偏好，并根据他们的兴趣提供个性化的视频推荐。大量研究（Zhan 等人，2022；Gong 等人，2022；Lin 等人，2022；Wang 等人，2022；Cai 等人，2023；Zhao 等人，2023）致力于开发神经网络模型，并显著提高了传统回归方法的预测准确性。

由于用户观看时间值的连续性和广泛性，观看时间的预测提出了一个回归问题，这增加了对异常值的敏感性和潜在预测偏差。如图1所示，**短视频的观看时间分布是右偏的，大量的集中在短时间内：30% 的观看时间在 3 秒内，80% 在 32 秒内**。这种分布给早期的观看时间预测尝试（Zhan 等人，2022；Covington, Adams, 和 Sargin 2016）带来了挑战，它们忽视了回归问题的长尾特性，因此对于尾部实例产生了次优结果。此外，在推荐系统中，**预测之间的序数关系起着关键作用**，以观看时间为视频比较的指标，突出了序数排序的重要性。然而，标准的回归损失如 ℓ1 和 ℓ2 并不考虑排序比较，只关注差异的大小。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/74b82fbf091f1ed514439073fe5e4a9b47ce3beab283b5764e40404964b73cee6678eea75ea6ba928c1e9b7920a6d8f5?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 观看时间的概率密度图

因此，在不平衡的连续标签分布中保持实时推荐系统中的预测准确性和排序效率面临巨大挑战。

为了解决这个问题，我们引入了一个有效的基于分类-恢复(classification-restoration)的框架，用于从现实世界中的不平衡连续目标中学习。该框架包含三个关键组件：

- 一个有效的**离散化**：将连续标签转换为序数区间，
- 一个**分类模块**：训练多个二元分类器跨越这些段以确保排序准确性，
- 一个**恢复模块**：用于根据这些分类器的预测预测观看时间

这种方法的挑战在于从连续分布中创建离散类别的模糊性。这涉及到解决两种误差类型：

- 与样本桶计数相关的**学习误差**
- 影响从离散化预测中估计观看时间的**恢复误差**

平衡这些误差证明是复杂的；较窄的桶间隔通过降低样本概率降低了学习误差，而较宽的间隔减少了信息并提高了恢复误差。我们检查了离散化对学习和恢复误差的影响，并提出了一种错误自适应离散化（EAD）方法，以在实际分布中协调这些误差。

我们全面的框架，命名为带有 EAD 的 Classification-Restoration（CREAD），提供了一个适用于现有学习方法（如 D2Q）的多功能扩展。

总之，我们的主要贡献是：

- 我们提出了一个用于学习观看时间的序数信息的通用分类-恢复框架，以及减少分类和恢复误差的训练算法。
- 我们分析了离散化引入的误差界限，并提出了一种新的离散化方法，根据现实数据集分布平衡学习误差和恢复误差。

现实大规模数据集的离线和在线实验表明，我们的框架与最先进的方法相比取得了竞争性的结果。

# 2 相关工作

# 2.1 观看时间预测

观看时间预测的任务是：预测用户在给定用户画像、互动历史和一系列候选短视频的情况下的观看时间。

- VR：值回归（Value Regression）直接预测观看时间的绝对值，其中学习函数的准确性通过均方误差来评估。
- WLR：Covington, Adams 和 Sargin (2016) 将观看时间作为样本权重纳入（WLR）印象深刻的视频的逻辑回归中，将直接回归观看时间转化为学习视频点击率的概率。然而，这种假设仅在展示率较低时成立，而不适用于短视频设置中自动播放的视频。
- D2Q：最近，Zhan 等人（2022）研究了视频推荐中观看时间预测的持续时间偏差（D2Q），通过基于持续时间的分箱数据去除不需要的偏差。尽管他们基于等频的方法去除了偏差，但他们忽略了观看时间不平衡分布对长尾样本的影响，导致与头部样本相比准确性较低。尽管有效，但他们没有利用在离散化过程中丢失的额外桶内信息，而我们在建模过程中**施加了一个错误自适应框架**。

## 2.2 通过分类进行回归

最近，有一种趋势是将回归问题表述为一组分类问题，这在直接回归上取得了显著改进。第一个相关工作是**序数回归（OR： Ordinal Regression）**。它最初用于因变量表现出相对排序的分类问题，后来扩展到包括年龄估计（Niu 等人，2016；Beckham 和 Pal，2017）和深度估计（Diaz 和 Marathe，2019）等多个领域。

OR的一个关键问题是：**从分布中创建离散类别的模糊性**。大多数工作使用固定标准方法，如等宽或等频离散化来划分连续变量，而其他人则手动选择多个阈值（Crammer 和 Singer，2001；Shashua 和 Levin，2002）作为超参数。正如第 4 节所分析的，这些方法引入了较大的离散化误差，特别是当数据遵循不平衡分布时。相比之下，我们的方法通过提出一种**自适应离散化方法来最小化总误差**，从而缓解了这个问题。

# 3 方法

记号。设：  $\{(x_i, y_i)\}^N_{i=1}$ 为训练集，

其中：

- $y_i \in Y \subset \mathbb{R}^+$ ：是对应的真实观看时间（ground truth）
- $x_i \in \mathbb{R}^d$： 表示第 $i$ 个输入，包括与用户相关的特征（如人口统计特征和浏览历史）和与视频相关的特征（如标签和转发计数）。

不失一般性，我们假设：目标变量的值域通过 $T_{\text{max}} \in \mathbb{R}^+$ 来限制。

我们使用 $M-1$ 个阈值 $ \lbrace t_m \rbrace_{m=1}^{M-1} $ 将值域划分为$M$个离散桶 $ D \equiv \lbrace d_m \rbrace^M_{m=1} $，其中：

- 第 $m$ 个桶 $d_m = [t_{m-1}, t_m)$ 对于 $m = 1, \cdots, M$，并且 $t_0 = 0$，$t_M = T_{\text{max}}$。
- 设 $\widehat{y}_i$ 表示 $x_i$ 的预测观看时间。

设：

- $1(\cdot)$ 表示指示函数。

为了简化，当我们不特指某个样本时，我们省略下标 $i$。

## 3.1 整体框架

CREAD框架，如图2 所示，包括三个模块，即离散化、分类和恢复。以下，我们解释每个组件的设计。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/c48655d9ecaa8c8f872bd5e2a22df327b7e12793713228fdd3b641b47c5fe6d026b4fe3987dca0a6ba09de3d6dd4d3c9?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2 CREAD框架

**离散化（Discretization）** 

这个模块是一个独立的预处理模块，与训练和评估过程无关。它根据数据分布获得阈值 $\{t_m\}_{m=1}^{M-1}$，并将目标域 $Y$ 分割成 $M$ 个不重叠的桶 $D \equiv \{d_m = [t_{m-1}, t_m)\}^M_{m=1}$。这些桶用于将观看时间 $y$ 转换为 $m$ 个离散标签：

$$ 
y_m = 1(y > t_m). \quad (1) 
$$

**离散化策略对预测精度至关重要**，我们将在第 4.3 节详细讨论。

**分类（Classification）** 

训练 $M$ 个分类器来**预测观看时间 $y$ 是否大于第 $m$ 个阈值 $t_m$**，即方程 (1) 中的 $y_m$，并输出一系列概率：

$$ 
\widehat{\phi}_m(x_i; \Theta_m) = P(y > t_m | x_i), \quad 1 \leq i \leq N. \quad (2) 
$$

分类器是具有可学习参数 $\Theta_m$ 的神经网络。我们在第 3.2 节介绍如何训练这些模型。

**恢复（Restoration）** 

给定 $\lbrace \widehat{\phi}_m \rbrace^M_{m=1}$，我们能够恢复预测的观看时间。恢复基于以下期望的事实：

$$ 
\begin{align}
E(y | x_i) & = \int_{t=0}^{t_M} tP(y = t | x_i)dt \\
& = \int_{t=0}^{t_M} P(y > t | x_i)dt \\
& \approx \sum_{m=1}^M P(y > t_m | x_i) (t_m - t_{m-1}).
\end{align} 

\quad (3) 
$$

根据方程 (2) 中的 $\hat{\phi}_m$ 的定义，我们可以从这些离散预测 $\hat{\phi}_m$ 重建预测的观看时间：

$$ 
\hat{y} = \sum_{m=1}^M \hat{\phi}_m (t_m - t_{m-1}). \quad (4) 
$$

## 3.2 模型训练

这里，我们提供了 $M$ 个分类器训练中的loss函数。损失函数包含三部分，其中第一部分是：通过标准交叉熵的分类损失。

$$ 
L_{ce} = \sum_{m=1}^M -y_m \log(\hat{\phi}_m) - (1 - y_m) \log(1 - \hat{\phi}_m). \quad (5) 
$$

第二部分是：restore loss，以减少方程 (4) 中重建观看时间的误差：

$$ 
L_{restore} = \ell(\hat{y}, y), \quad (6) 
$$

其中：

- $\ell$ 是衡量 $\hat{y}$ 到 $y$ 偏差的损失函数。

我们发现使用 Huber 损失 (Huber 1992) 作为 $L_{restore}$ 是有益的，这将在第 5.3 节详细分析。

第三部分是：通过序数先验的正则化项。根据定义，$M$ 个分类器的输出 $\{\hat{\phi}_m\}_{m=1}^M$ 有一个先验，即 $\hat{\phi}_m$ 随着 $m$ 的增长而单调递减。因此，我们通过最小化以下正则化项将先验纳入所提出的框架：

$$ 
L_{ord} = \sum_{m=1}^{M-1} \max(\hat{\phi}_{m+1} - \hat{\phi}_m, 0). \quad (7) 
$$

总之，最终的优化目标是:

$$ 
L_{CREAD} = \lambda_{ce}L_{ce} + \lambda_{restore}L_{restore} + \lambda_{ord}L_{ord}, \quad (8) 
$$

其中：

- $\lambda_{ce}$、$\lambda_{restore}$ 和 $\lambda_{ord}$ 是超参数。

## 3.3 离散化的挑战

在 CREAD 框架中，一个关键模块是离散化模块，离散化方法在很大程度上影响最终预测精度。如图3 所示，离散化引入了两种误差：

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/d1263d6c7883c02e69c5a9928e9a1eab15420e9667b48eb7d2d371dff1675f8c392955fa8c3e74ab1d00763fae348e0e?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3

- 学习误差：由于每个桶中的实例数量是有限的，$M$ 个分类器不能无限精确。随着我们增加桶的数量 $M$，落入每个桶的实例数量减少，从而限制了分类性能。
- 恢复误差：方程 (4) 中的恢复是期望的一个近似函数，省略了每个桶 [$t_{m-1}$, $t_m$] 中的详细概率密度，这也会引入误差。

不幸的是，这两种误差不能同时减少。为了减少学习误差，需要更大的桶宽度，导致更大的恢复误差（见图 3）。现有方法通常使用等宽或等频方法 (Gai 等人，2017) 来启发式地设置离散化集 $D$。我们将在第 4 节展示等宽和等频方法都不能很好地平衡这两种误差，并提出我们的 EAD 方法。

# 4 在离散化中平衡误差

本节旨在平衡离散化过程中引入的误差。我们首先提供对离散化过程中引入的学习误差和恢复误差的理论分析，然后提出EAD方法来有效平衡这两种误差。

## 4.1 离散化误差的分解

假设：训练数据集 $\{(x_i, y_i)\}^N_{i=1} \sim \mu(x, y) = \mu(x)\mu(y|x)$ 是独立同分布的。设：

- $p_m(x) = P(y \in d_m | x)$ 表示标签 $y$ 属于第 $m$ 个桶 $d_m$ 给定 $x$ 的概率。
- $v_m(x) = E(y | x, y \in d_m)$ 是样本 $x$ 的观看时间的期望值，假设它属于第 $m$ 个桶。
- $w_m = E_{x \sim \mu(x)}v_m(x)$ 表示区间 $d_m$ 中观看时间的期望值。

我们添加帽子上标来表示预测值，例如，$\hat{p}_m(x)$ 作为 $p_m(x)$ 的预测，$\hat{w}_m$ 作为 $w_m$ 的预测。然后我们可以将观看时间表示为：

$$ 
\hat{y} = \sum_m \hat{p}_m(x) \hat{w}_m. 
$$

注意，这种形式等同于方程 (4) 中的累积形式，其中 $\hat{p}_m = \hat{\phi}_m - \hat{\phi}_{m-1}$。

现在我们的目标是估计预测观看时间 $\hat{y}$ 和真实值 $y$ 之间的误差界限。为了实现这一点，我们首先提供一个误差分解：

引理 4.1。假设 $\hat{p}_m(x)$ 和 $\hat{w}_m$ 分别是 $p_m(x)$ 和 $w_m$ 的无偏估计，我们有：

$$ 
E(\hat{y} - y)^2 = V_p + V_w + V_b + V_y, 
$$

其中:

$$ V_p = \text{Ex}[\text{Ep}^{\hat{}}\hat{E}_w^{\hat{}}\sum_m (\hat{p}_m(x) - p_m(x)) \hat{w}_m]^2, $$

$$ V_w = \text{Ex}[\text{Ew}^{\hat{}}\sum_m p_m(x) (\hat{w}_m - w_m)]^2, $$

$$ V_b = \text{Ex}[\sum_m p_m(x) (w_m - v_m(x))^2], $$
$$ V_y = \text{Ex},y[\sum_m p_m(x)v_m(x) - y]^2. $$

详细证明请参见附录 A。直观上，$V_p$ 由学习误差决定，即 $y$ 落入每个桶的概率 $p_m(x)$。$V_w$ 描述了学习误差对代表性值 $\hat{w}_m$ 的影响，$V_b$ 是由离散化重建观看时间引起的误差，$V_y$ 是观看时间 $y$ 的内在方差。

两个预测误差 $V_p$ 和 $V_w$ 受到学习算法误差的影响。因此，这两个误差项对应于学习误差。相比之下，$V_b$ 对应于与具体学习算法无关的恢复误差。最后，$V_y$ 与学习或离散化过程无关，后续不再讨论。

## 4.2 离散化的误差界限

本节分析离散化过程如何影响误差界限。为了理论分析的简便，我们只考虑表格输入的情况，并假设 $\mu(x, y)$ 足够平滑。但我们强调，受理论分析启发的离散化方法在现实世界设置中也将有效。

定理 4.2。假设输入 $x$ 从有限集合 $X$ 中采样。此外，假设 $\hat{p}_m(x)$，$x \in X$ 和 $\hat{w}_m$ 从最大似然估计中获得。此外，假设 $\mu(x, y)$ 具有有界的二阶偏导数。那么我们有：

$$ V_p \leq V_p \equiv C_p |X|/N \cdot A_p(D), $$
$$ V_w \leq V_w \equiv C_w/N \cdot A_w(D), $$
$$ V_b \leq V_b \equiv C_b \cdot A_b(D), $$

其中 $C_p$，$C_w$ 和 $C_b$ 是与离散化 $D$ 无关的常数，$A_p$，$A_w$，$A_b$ 是 $D$ 的函数：

$$ A_p(D) = ME_y^{\Psi}(y^2), $$
$$ A_w(D) = \sum_{m \in M} [\Psi(t_m) - \Psi(t_{m-1})]^2 \cdot \frac{\sum_{m \in M} (t_m - t_{m-1})^2}{\Psi(t_m) - \Psi(t_{m-1})}, $$
$$ A_b(D) = \sum_{m \in M} [\Psi(t_m) - \Psi(t_{m-1})]^2 \cdot \frac{\sum_{m \in M} (t_m - t_{m-1})^2}{1}, $$

其中 $\Psi$ 是观看时间 $y$ 的累积分布函数（CDF）：

$$ \Psi(t) \equiv P\{y \leq t\} = \text{Ex} \int_0^t \mu(y|x)dy. $$

证明。见附录 B。

因此，我们发现预测误差受到仅依赖于观看时间分布 $\Psi$ 和离散化 $D$ 的几个函数 $A_p$，$A_w$ 和 $A_b$ 的限制。现在我们提供一些直观的解释。

讨论 不同离散化方法对每个误差项的影响是什么？这里我们主要讨论误差项 $A_w$ 和 $A_b$，因为它们依赖于 $D$ 的分割点 $\{t_m\}_{m=1}^M$。我们考虑一个在 $[0, 1]$ 上截断的指数分布，即 $\Psi(t) = (1 - e^{-5t})/(1 - e^{-5})$，由 10 个桶离散化。表 1 显示了等宽和等频离散化的不同项。结果表明，等宽方法导致较低的 $A_b$，而等频方法导致较低的 $A_w$。这个结果有一个非常直观的解释，显示了 $A_b$ 和 $A_w$ 的含义：

- 学习误差：学习误差由 $A_w$ 显示，受每个桶中的样本数量影响。具体来说，$A_w$ 的分母中存在一个 $\Psi(t_m) - \Psi(t_{m-1})$ 项。因此，如果某些桶中的样本很少，相应的概率 $\Psi(t_m) - \Psi(t_{m-1})$ 将很小，导致较大的误差。
- 恢复误差：$A_b$ 显示恢复误差界限。它包含一个 $t_m - t_{m-1}$ 项作为乘数。当某些 $m$ 的 $t_m - t_{m-1}$ 较大时，误差项将增加，这与较大的桶宽度将导致较大的恢复误差的直觉一致。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/a69770d67d52942afc661c62e494419097b6887a5c793a6232a94836bd1872c23100b064007c29a2d9de11f5a39cc631?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=4.jpg&amp;size=750">

图4

现在我们再次讨论离散化引入的误差困境：学习误差和恢复误差通常相互矛盾。如果我们要减少学习误差，我们需要增加每个桶中的样本数量，但较大的桶宽度会导致较大的恢复误差。正式地，桶概率 $\Psi(t_m) - \Psi(t_{m-1})$ 通常与桶宽度 $t_m - t_{m-1}$ 正相关。根据上述讨论，我们即将提供 EAD 方法来平衡这两种误差。

## 4.3 EAD 方法

这里我们主要讨论给定桶的数量 $M$ 时的离散化策略 $D$。我们不讨论 $M$ 的选择，因为它是一个单一变量，可以被视为超参数。根据第 4.2 节，离散化策略 $D$ 需要平衡学习误差 $A_w$ 和恢复误差 $A_b$。因此，EAD 的离散化策略最小化以下目标：

$$ \min_D J(D) = A_w(D) + \beta A_b(D), $$

其中：

- $\beta$ 根据定理 4.2 由 $C_w$，$C_b$ 和 $N$ 确定。

由于 $C_w$ 和 $C_b$ 依赖于数据集的特征，无法从理论上获得，我们将 $\beta$ 视为超参数。

方程 (21) 是一个维度为 $M - 1$ 的优化问题。找到最优离散化策略是具有挑战性的，因为 $M$ 通常是几十或几百。这里我们提出一个更轻量级的方法。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/cc31a7f2d706989260d299cb0469eeec422ff42c6862c66bec9781d043400dcf3b30024ed8cebc73d0e035b65eb3246e?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=5.jpg&amp;size=750">

图5


# 

[https://arxiv.org/pdf/2401.07521](https://arxiv.org/pdf/2401.07521)