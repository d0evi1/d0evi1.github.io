---
layout: post
title: DFN介绍
description: 
modified: 2020-12-11
tags: 
---

微信在《Deep Feedback Network for Recommendation》提出了DFN。

# 摘要

显式与隐式反馈可以影响用户关于items的opinions，这对于学习用户偏好来说是必要的。然而，大多数当前的推荐算法主要关注于隐式正反馈（implicit positive feedbacks: 例如：click），忽略了其它有信息的用户行为。在本paper中，我们的目标是：**联合考虑explicit/implicit以及positive/negative feedbacks来学习用户的无偏偏好**。特别的，我们提出了一种新的Deep feedback network(DFN)来建模**click、unclick和dislike行为**。DFN具有一个内部feedback interaction组件，它可以捕获用户行为间的细粒度交叉（fine-grained interactions），一个额外的feedback interaction组件可以使用精准但相对少的feedbacks(click/dislike)来从丰富但带噪声的feedbacks（unclick）中抽取有用信息。在实验中，我们在wechat top stories的推荐系统上，对数百万用户做了实验。DFN带来了极大的提升。源代码为：https://github.com/qqxiaochongqq/DFN

# 1.介绍

个性化推荐系统的目标是，为用户根据它们的偏好提供定制的items。它们在视频和电商业被广泛使用。

推荐系统中大量使用user-item interactions来进行个性化。这些重要的信息主要有两大类：explicit feedback和implicit feedback。explicit feedback来自于用户对items的直接意见（比如：评分、like/dislike等）。它可以很精准地表示用户的真实偏好，而收集这样的feedback相当不容易。相反，implicit feedback主要来自于具有暗示非直接意见的用户行为（例如：click或unclick）。在真实推荐系统中，很容易从大量用户行为中收集这样的隐式反馈。然而，implicit feedbacks会混杂着许多其它内在的noises，以及少量的真实负反馈，这会损害学习用户的无偏偏好.

最近，推荐系统通常会将个性化推荐看成是一个CTR预测任务。因此，它很自然地，大多数推荐算法主要关注于显式正反馈：点击，这在实际中很容易获取。这些模型会直接使用点击行为和CTR目标进行最优化，它会产生以下的问题。首先，CTR目标的objectives通常关注于：用户喜欢什么，忽略掉用户不喜欢什么。简单依赖于这些implicit positive feedbacks会使得模型趋向于提供均匀的（homogeneous）、短视（myopic）的结果，这会伤害用户体验。因此，negative feedbacks应在推荐中被考虑。第二，除了被动地接受由模型选中的信息外，用户也需要有效和高效的反馈机制来激活与推荐系统的交互。再者，由于用户的implicit feedbacks与它的真实偏好（点击并不总是意味着喜欢）间存在gap。它也证实了explicit feedbacks的必要性。

多个explicit/implicit和positive/negative feedbacks可以互补，并影响用户的无偏偏好。有一些工作：使用隐式反馈和显式反馈的CF(Liu 2010)、多任务学习（Hadash 2018）。然而，这些工作中，negative feedbacks通常会被忽略，或者只存在显式反馈（这很精准、但量很少）。一些工具会考虑unclick或missing行为作为隐式负反馈来乘上负信号（negative signals）。不幸的是，在这些implicit negative feedbacks中的noises会严格限制效果表现，因此，这些implicit negative feedbacks会通过许多除了dislike之外的原因造成。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/9f9064ce231f609be6f113190ac0b528087f3da4c9101357cba7d275dff7a7c98ebeaefbb8e52eb14de4e8882dbd1090?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=1.jpg&amp;size=750">

图1

。。。

# 2.相关工作

。。。

# 3.方法

我们的目标是，将多个explicit/implicit和positive/negative feedbacks进行联合考虑来学习用户无偏偏好。特别的，我们提出了DFN模型，它会收集用户历史行为中的三种类型的feedbacks：

- implicit positive feedbacks：implicit positive feedbacks是在大规模推荐中被广泛使用的feedbacks，它在量级和质量上均比较满意。根据大多数conventional模型，我们考虑点击行为序列 $$\lbrace c_1, \cdots, c_{n_1}\rbrace$$作为在DFN中使用的implicit positive feedback。
- explicit negative feedbacks：Explicit feedbacks是高质量的，但在真实推荐中很少。我们会使用与每个item相关的dislike按钮来收集explicit negative feedback序列 $$\lbrace d_1, \cdots, d_{n_2}\rbrace$$
- implicit negative feedbacks：我们会将曝光未点击（impressed but unclick）的行为序列$$\lbrace u_1, \cdots, u_{n_3}\rbrace$$作为implicit negative feedbacks。这种未点击行为在所有feedbacks类型中占绝大多数，而它会与噪声和false-negative信号相混杂。

CFN尝试使用高质量的click和dislike behaviors作为instructors来从未点击行为中抽取有用信息。在DFN中很容易添加其它类型的feedbacks。

## 3.1 整体架构

Deep feedback network主要包含两个模块，称为：deep feedback interaction模块与feature interaction模块。首先，deep feedback interaction模块会采用多个feedbacks作为inputs，使用内部和外部的feedback interactions来抽取用户无偏的positive和negative偏好。第二，refined feedback features会与其它有信息特征（比如：user profiles、item features以及contexts）进行组合。我们会实现Wide、FM和Deep组件来进行特征聚合（feature aggregation）。最终，feature interaction模块的outputs会feed给full connected和softmax layers来进行positive和negative losses的模型最优化。图2(a)展示了DFN的整体架构。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/ebf6a62be12d28dfdca110d3549f73b8e2e55fa443ca2ff2b21ec804cfb54fab3ce17016ca2e954e179ce78b21632813?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=2.jpg&amp;size=750">

图2

## 3.2 DFN module

图2(b)中的deep feedback interaction模块会采用对于target item的implicit positive(click)，explicit negative(dislike)以及implicit negative(unclick) feedbacks作为inputs。我们会使用两个components来从inside和between不同类型的feedbacks的交叉中进行学习。

**Internal Feedback Interaction Component**

对于一个特定类型的feedback，该component会关注target item和individual behaviors间的交叉。我们会根据Vaswani[2017]的行为使用一个multi-head self-attention。所有的行为特征包含了它们的item embeddings和position embeddings，会被投影到一个联合语义空间（joint semantic space）中来形成behavior embeddings。以点击行为为例，我们会将target item t与点击序行的behavior embeddings进来组合来形成输入矩阵 $$B_c = \lbrace t, c_1, \cdots, c_{n_1} \rbrace$$。query, key, value矩阵可以通过如下进行计算：

$$
Q = W^Q B_c, K=W^K B_c, V=W^V B_c
$$

...(1)

其中，$$W^Q, W_K, W^V$$是投影矩阵。我们接着通过下面方式计算self-attention：

$$
Attention(Q, K, V) = softmax(\frac{Q^T K}{\sqrt{n_h}}) V
$$

...(2)

其中，$$n_h$$是query、key、value的维度。总共h个multi-heads的第i个head可以通过如下进行计算：

$$
head_i = Attention(W_i^Q Q, W_i^K K, W_i^V V)
$$

...(3)

$$W_i^Q, W_i^K, W_i^V \in R^{n_k \times n_k / h}$$是第i个head的weighting矩阵。self-attention的最终输出矩阵是：

$$
F_c = concat(head_1, \cdots, head_h) \cdot W^O
$$

...(4)

$$W_O \in R^{n_h \times n_h}$$是投影矩阵。最终，我们通过在$$F_c$$中所有n+1的output embeddings上进行一个average pooling来生成implicit positive feedback embedding $$f_c$$：

$$
f_c = Average_pooling(F_c), f_c \in R^{n_h}
$$

...(5)

我们也会使用相同的带type-specific hyper-params的transformer来生成explicit negative feedback embedding $$f_d$$以及从dislike和unclick behaviors中的implicit negative feedback embedding $$f_u$$。internal feedback interaction component可以很好地捕获在每种类型的feedback序列中target item和behaviors的behavior-level interactions。它可以提供与target item相关的user positive和negative偏好。

**External Feedback Interaction Component**

隐式负反馈（implicit negative feedbacks）是够多的，但有非常noisy。总之，unclick behaviors看起来暗示着negative signals，而曝露给用户的items则需通过特定策略进行选择，它也会包含来自粗粒度的用户兴趣。external feedback interaction组件的目标是，根据在click和dislike行为上的强反馈，来区别用户在未点击行为（unclick behaviors）上的真实喜欢（like）和不喜欢（dislike）。特别的，我们通过两个vanilla attentions，它会考虑隐式正反馈和隐式负反馈的embeddings $$f_c$$和$$f_d$$作为instructors来指导来自unclick序列$$u_1, \cdots, u_{n_3}$$。我们将unclick-dislike interaction embedding $$f_{ud}$$使用dislike和unclick行为公式化：

$$
f_{ud} = \sum\limits_{i=1}^{n_3} \alpha_i u_i, \alpha_i = \frac{f(f_d, u_i)}{\sum_{j=1}^{n_3} f(f_d, u_j)}
$$

...(6)

其中，weighting score function $$f(a,b)$$定义如下：

$$
f(a, b) = MLP(concat(a, b, a-b,  a\odot b))
$$

...(7)

我们将$$\odot$$看成是element-wise product，并使用一个2-layer Multi-layer perceptron (MLP)。$$f_d$$包含了user的强的negative偏好，它从与target item相关的显式负反馈（explicit negative feedbacks）进行重定义得到。它会帮助vanilla attention来抽取用户真实dislike和unclick行为的items。我们也会使用隐式正反馈（implicit positive feedback）的embedding $$f_c$$来放大在unclick行为中positive的声音。

$$
f_{uc} = \sum\limits_{i=1}^{n_3} \beta_i u_i, \beta = \frac{f(f_c, u_i)}{\sum_{j=1}^{n_3} f(f_c, u_j)}
$$

...(8)

最后，我们将所有5种feedback features组合来构建最终的refined feedback feature $$f_{Feed}$$：

$$
f_{Feed} = \lbrace f_c, f_d, f_u, f_{uc}, f_{ud}\rbrace
$$

...(9)

隐式正反馈与显式负反馈$$f_c$$和$$f_d$$被看成是强的positive和negative信号，而其余unclick-related feedbacks则被看成是弱信号（weak signals）。

## 3.3 Feature Interaction Module

在feature interaction中，我们将refined feedback feature与其它features（包括：user profiles、item features、以及context）进行refined。根据Guo[2017]，我们将这些sparse features进行group到m个fields中 $$\lbrace x_1, \cdots, x_m \rbrace$$包括：continuous fields(例如：age)和categorical fields（例如：location）。所有的fields被表示成one-hot embeddings。一个lookup table被用于生成所有fields的dense feature：$$\lbrace f_1, \cdots, f_m \rbrace$$。我们为feature interaction实现了Wide, FM以及Deep components。

**Wide Component**

Wide component是一个泛化的linear model，它在推荐中被广泛使用。Wide component $$y^{Wide}$$的output是一个m-dimensional的vector，其中，第i个element被计算成：

$$
y_i^{Wide} = w_i^T x_i + b_i, w_i, x_i \in R^{n_{f_i}}
$$

...(10)

$$w_i$$是第i个one-hot fields embedding $$x_i$$的weighting vector，$$b_i$$是bias，$$n_{f_i}$$是$$x_i$$的维度。

**FM Component**

FM component会捕获所有features间的二阶交叉。FM的input embeddings是所有dense features的组合，最终的refined feedback feature为：$$F' = \lbrace f_1, \cdots, f_m, f_{Feed}\rbrace$$。我们根据Bi-interaction layer，并根据下面方式生成output embedding $$y^{FM}$$：

$$
y^{FM} = \sum\limits_{i=1}^{m+5} \sum\limits_{j=i+1}^{m+5} f_i^' \odot f_j^', f_i^', f_j^' \in F'
$$

...(11)

**Deep component**

在Deep component中，我们实现了一个2-layer MLP来学习高阶feature interactions。input是dense features和feedback features的concatenation，可以表示成：$$f^{(0)} = concat(f_1, \cdots, f_m, f_{Feed})$$。我们有：

$$
y^{Deep} = f^{(2)}, f^{(i+1)} = ReLU(W^{(i)} f^{(i)} + b^{(i)})
$$

...(12)

其中，$$f^{(i)}$$是第i个layer的output embedding。$$W^{(i)}$$是weighting matrix，$$b^{(i)}$$是第i个layer的bias。

最终，我们从三个components中将所有outputs进行concat起来来生成aggregated feature embedding y：

$$
y = concat(y^{Wide}, y^{FM}, y^{Deep})
$$

...(13)

## 3.4 Optimization Objective

我们使用click、unclick以及dislike行为来进行监督训练。预测的点击概率与aggregated feature embedding y通过下式计算：

$$
p(x) = \sigma(w_p^T y)
$$

...(14)

$$w_p$$是weighting vector，$$\sigma(\cdot)$$是sigmoid function。DFN的loss function包含了三个部分：click、unclick、dislike行为：

$$
L = -\frac{1}{N} (\lambda_c \sum\limits_{S_c} log p(x) + \lambda_u \sum\limits_{S_u} log(1 - p(x)) + \lambda_d \sum\limits_{S_d} log(1-p(x)))
$$

...(15)

该训练集具有N个实例，分组成：click set $$S_c$$，dislike set $$S_d$$以及unclick set $$S_u$$。$$\lambda_c, \lambda_d, \lambda_u$$是不同losses的weights来measure不同feedbacks的重要性。

# 4.实验

略

# 参考


- 1.[https://www.ijcai.org/Proceedings/2020/0349.pdf](https://www.ijcai.org/Proceedings/2020/0349.pdf)