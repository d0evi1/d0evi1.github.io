---
layout: post
title: SDM介绍
description: 
modified: 2020-10-10
tags: 
---

阿里在《SDM: Sequential Deep Matching Model for Online Large-scale
Recommender System》提出了SDM，我们来看下。

# 摘要

捕获用户的精准偏好是大规模推荐系统中一个基础问题。当前，item-based CF方法通常会在工业界广泛使用。希而，它们不能有效建模用户的动态演进的偏好。在本paper中，我们提出了一个新的序列深度匹配模型（SDM: sequential Deep Matching）来捕获用户的动态偏好，它通过将short-term sessions和long-term behaviors相结合进行建模。我们对比了已经存在的sequence-aware推荐方法，我们会解决在实验应用中的两个天然问题：

- 1） 他们可以在一个session内存在多个兴趣趋势
- 2）长期偏好（long-term）可能会与当前session兴趣的融合得不够有效

长期行为是多样且复杂的，因而，与short-term session高度相关的行为应该在融合（fusion）时被保留。我们提出，使用两个相应的组件来编码行为序列：

- multi-head self-attention模块：来捕获多种类型的兴趣
- long-short term gated fusion模块：来吸收long-term偏好

在与序列用户行为向量（sequential user behavior vector）与item embedding vectors相匹配后，会推荐连续的items。在真实世界数据集中的离线实验表明，SDM的优点。另外，SDM已经在taobao的在线大规模推荐系统中成功部署，并达到了巨大提升。

# 1.介绍

。。。

# 2.相关工作

。。。

# 3.提出的方法

## 3.1 问题公式化

我们首先将序列匹配问题（sequential matching problem）和我们的解决方法进行公式化。假设：

- U：表示users集合
- I：表示items集合

我们的模型认为：用户$$u \in U$$会与与一个item $$i \in I$$在t时刻进行交互。对于user u，我们可以通过以时间序降序对交互items进行排序来获得他/她的最新sessions。受session-based推荐的启发，我们可以将new session的生成规则进行公式化：

- 由后台系统记录，相同的session ID进行交互属于相同session
- 时间差异少于10分钟内（或者更长时间，具体依赖于场景）的近邻交互也可以合到一个session
- 一个session的最大长度设置为50，它意味着：当session长度超过50时，会新开启一个new session

用户u的每个最近session会看成是短期行为（short-term behavior），命名为$$S^u = [i_1^u, \cdots, i_t^u, \cdots, i_m^u]$$，其中：m是sequence的长度。u在过去7天内在$$S^u$$前发生的长期行为（long-term）被标记为$$L^u$$。基于这样的前提条件，我们会定义我们的推荐任务。给定用户u的短期行为 $$S^u$$以及长期行为 $$L^u$$，我们希望为他/她推荐items。

总的网络结构如图1所示。我们的模型会将当前session $$S^u$$和$$L^u$$作为input。$$S^u$$和$$L^u$$会分别被编码成short-term session表示为时间t的$$s_t^u$$，长期行为表示$$p^u$$。这两种representations会通过一个gated neural network进行组合。我们将该模块命名为user prediction network，它会从$$S^u$$和$$L^u$$中预测用户行为向量$$o_t^u \in R^{d \times 1}$$。假设：$$V \in R^{d \times \mid I \mid}$$表示I的item embedding vectors，其中：$$\mid I \mid $$是所有items的数目，d是每个vector的embedding size。我们的目标是：基于在$$o_t^u$$与V中每个列向量$$v_i$$间的内积得分，预测在time t+1时top N个item candidates：

$$
z_i = score(o_t^u, v_i) = {o_t^u}^T v_i
$$

其中，$$v_i \in R^{d \times 1}$$是第i个item embedding vector。

## 3.2 训练和在线serving

在训练期间，在time t的postive label是next interacted item $$i_{t+1}^u$$。negative labels是从排除了$$i_{t+1}^u$$的I中通过log-uniform sampler抽样得到的。接着预测的class probabitities会通过一个softmax layer做出。称为sampled-softmax，我们会使用cross entropy作为loss function：

$$
\hat{y} = softmax(z)  \\
L(\hat{y}) = - \sum\limits_{i \in K} y_i log(\hat{y}_i)
$$

...(2)

其中，K是I的抽样子集，它包含了positive labels和negative labels，$$z = [z_1, \cdots, z_{\mid K \md}] $$是在$$o_t^u$$与每个$$v_i (i \in K), \hat{y} = [\hat{y}_1, \cdots, \hat{y}_{\mid K \mid}$$是在每个抽样样本（sampled item）上的预测概率分布，其中$$y_i$$是item i的truly probability分布。

我们会在我们的在线推荐系统中部署该模型。item embedding vectors V对于ANN来说很重要。同时，user prediction network会部署在一个高性能的实时inference系统上。这种架构遵循Youtube视频推荐[4]。当顾客使用我们的在线服务时，他们会与多个items交互，他们关于items的feedback会被处理，接着在数据库中作为用户行为日志进行排序。从大量日志中的有用悠会被抽取出来构建成模型所需的结构化数据。在time t时，顾客的历史行为$$S^u$$和$$L^u$$会被feed到inference系统中。接着，用户行为向量$$o_t^u$$会被预测。KNN搜索系统会使用$$o_t^u$$根据它们的内积进行检索。接着推荐top-N items。现在，我们会详述$$S^u$$和$$L^u$$会被编码到network中，并且两个representations会在图2中进行融合。

## 3.3 使用side information的input embedding

在taobao推荐场景中，顾客不只关注于特定item本身，也会关注品牌、商店和价格，等。例如，一些用户趋向于购买指定品牌的items，其它用户可能会从他们信任的商店进行购买。再者，由于工业界存在大规模items造成的稀疏性（sparsity），只对item ID feature级别来编码items不够令人满意。因此，我们会从不同的feature尺度来描述一个item，例如：item ID、leaf category、first level category、brand和shop，它们可以被表示成side information set F。每个input item $$i_t^u \in S^u$$被表示为一个dense vector $$e_{i_t^u} \in R^{d \times 1}$$，它通过embedding layer进行转换，因此，他们可以直接feed到DNN中：

$$
e_{i_t^u} = concat( \lbrace e_i^f | f \in F \rbrace )
$$

...(3)

其中，$$e_i^f = W^f x_i^f \in R^{d_f \times 1}$$是item i关于feature f的input embedding，它具有embedding size $$d_f$$。$$W^f$$是feature。f是转移矩阵，$$x_i^f$$是one-hot vector。

相似的，user profile可以从不同的feature scales来描述user u，比如：age、gender、life stage。用户u的profile信息输入可以被表示成一个dense vector $$e_u \in R^{d \times 1}$$：

$$
e_u = concat( \lbrace e_u^p | p \in P \rbrace)
$$

...(4)

其中，P是这profile features set，$$e_u^p$$是feature p的embedding。

## 3.4 Recurrent Layer

给定用户u的embedded short-term sequence $$[e_{i_1^u}, \cdots, e_{i_t^u}]$$，为了捕获和特征化在short-term序列数据中的全局时序依赖，我们会使用Long Short Term Memory（LSTM） network作为recurrent cell，它遵循session-based recommendation【7，14，15】，LSTM可以描述为：

$$
$$

...

## 3.5 Attention机制

在电商场景下，顾客通常会浏览一些不相关的items，这被称为是“因果点击（causal clicks）”。不相关的行为（unrelated actions）一定程度上会影响在序列中$$h_t^u$$的表示（representation）。我们使用一个self-attention network来减小一些不相关actions的影响。Attention network可以聚合多个vectors到一个总体表示上，通过分配不同的权重分到每个组件上。

### 3.5.1 Multi-head self-attention

self

### 3.5.2 User Attention

对于不同的用户，他们通常会对相似的item sets具有不同的偏好。因此，在 self-attention network的顶部，我们会添加一个user attention module来描述一些细粒度的个性化信息，其中$$e_u$$会被用于query vector，对$$\hat{X}^u = [\hat{h}_1^u, \cdots, \hat{h}_t^u]$$进行attend。time t时的short-term行为表示$$s_t^u \in R^{d \times 1}$$可以被计算：

$$
a_k = \frac{exp(\hat{h}_k^{uT} e_u}{\sum_{k=1}^t exp(\hat{h}_k^{uT} e_u} \\
s_t^u = \sum\limits_{k=1}^t a_k \hat{h}_k^u
$$

## 3.6 长期行为混合

从long-term视角看，用户通常会在不同维度积累不同程度的兴趣。一个用户可能经常浏览一群相似商店，并且重复购买相同品类的items。因此，我们也会从不同的feature scales将long-term行为$$L^u$$进行encode，$$L^u = \lbrace L_f^u \mid f \in F \rbrace$$包含了多个子集：$$L_{id}^u $$(item ID)，$$L_{leaf}^u$$（leaf category），$$L_{cate}^u$$（first level category），$$L_{shop}^u$$（shop）以及$$L_{brand}^u$$（brand），如图2所示。例如：$$L_{shop}^u$$包含了用户u在过往一周内交互的shops。考虑在在线环境下的快速响应，在每个subset中的entries，通过一个attention-based pooling会被嵌入并聚合到一整个vector中。

每个$$f_k^u \in L_f^u$$会通过在第3.3节中的$$W^f$$被转换成一个dense vector $$g_k^u \in R^{d \times 1}$$。接着我们使用user profile embedding $$e_u$$作为query vector来计算attention scores并获得$$L_f^u$$的表示：

$$
a_k = \frac{exp(g_k^{uT} e_u}{\sum_{k=1}^`{| L_f^u |}`exp(g_k^{uT} e_u)} \\
z_f^u = \sum_{k=1}^{| L_f^u |} a_k g_k^u
$$

...(11)

$$\lbrace z_f^u \mid f \in F\rbrace$$会被concatented并feed到一个FC network上：

$$
z^u = concat(\lbrace z_f^u | f \in F \rbrace) \\
p^u = tanh(W^p z^u + b)
$$

...(12)

其中，$$p^u \in R^{d \times 1}$$是long-term行为的表示。

为了与short-term行为进行组合，我们精妙地设计了一个gated neural network，它会将$$e_u, s_t^u, p^u$$作为input进行组合，如图2所示。一个gate vector $$G_t^u \in R^{d \times 1}$$会被用来决定在time t时short-term和long-term的贡献百分比（contribution percentages）

$$
G_t^u = sigmoid(W^1 e_u + W^2 s_t^u + W^3 p^u + b)
$$

...(13)

最终的output，例如：用户行为向量$$o_t^u \in R^{d \times 1}$$，会通过如下计算：

$$
o_t^u = (1 - G_t^u) \odot p^u + G_t^u \odot s_t^u
$$

...(14)

其中：$$\odot $$是一个element-wise乘法。

# 4.实验

## 4.1 数据集

我们会构建一个offline-online train/validation/test framework来开发我们的模型。模型会在两个离线真实电商数据集。一个是移动taobao APP的在线天级日志。另一个来自JD。我们的代码和离线数据集提供在：https://github.com/alicogintel/SDM.

- 离线taobao数据集。随机选取了在连续8天内交互超过40个items的活跃用户（2018年12月）。另外，我们会过滤交互超过100个items的用户，它们会被认为是spam users。接着我们收集他们的历史交互数据，首个7天做为训练，第8天作为测试。我们会过滤出该数据集中少于5次的items。session segmentation会遵循3.1节的规则，并限定每个$$L_f^u$$的最大size为20个。在训练过程期间，我们会移除长度少于2的sessions。在test环节，我们会选择近10000个活跃用户作为快速评估。他们在第8天的的前25%的short-term sessions会被feed到模型中，剩除的交互作为ground truth。除此外，顾客一天内浏览一些items超过一次，并重复推荐不应被鼓励，因此，我们会在test data上对某个user来说对其它items只保留一次。

**离线JD数据集**。由于该数据集相当稀疏和更小，我们选择3周的用户-item交互日志进行训练，一周进行测试。其它data构建和清理过程与taobao相同。在表1中的两个离线数据集的统计详情如下。

**在线数据集**。我们会选择大多数有效离线模型来部署在淘宝的生产环境中。来自taobao APP的user-item交互日志的训练数据来自过往7天，没有进行sampling。相同的数据清理过程会应用在离线训练数据集上。在线用户和items的scales会扩展到亿级别，它可以cover住大多数taobao的活跃商品，更多的long-term行为可以被使用。详情如表1所示。在线model、相应的item和user features会天级更新。

## 4.2 评估指标

### 4.1 离线评估

### 4.2 在线评估

在线指标：pCTR、pGMV和discovery。

pCTR是每个page view的Click-Through-Rate ，其中每个page可以为用户推荐20个items：

$$
pCTR = \frac{#clicks}{#pages}
$$

pGMV是每个1000 PV的Gross Merchandise Volume。它的计算如下：

$$
pGMV = 1000 \times \frac{#pay amount}{#pages}
$$

除了在线流量和收入外，我们也考虑用户的shopping体验。定义了有多少新items推荐系统提供给一个用户：

$$
discovery = \frac{#new \ categories}{#all \ categories}
$$

其中，分母是一个用户在每天点击的所有categories的数目，分子是用户在过往15天内新category的数目。我们会对所有用户求平均。

## 4.3 对比方法

- Item-based CF
- DNN: youtube DNN
- GRU4REC
- NARM: GRU4REC的改进版本
- SHAN
- BINN
- SDMMA： Sequential Deep Matching with Multi-head Attention，我们的增强模型
- PSDMMA：Personalized SDMMA，增加了user attention module来挖掘细粒度的个性化信息
- PSDMMAL：PSDMMA组合了short-term sessions和long-term 行为。
- PSDMMAL-N：基于PSDMMAL，在训练期间，我们会采用以下的N个items作为target classes作为Tang&Wang[24]。本实验中N=4

## 4.4 实现详情

分布式tensorflow。在离线实验上，训练使用5个PSs和6个GPU worksers，平均30 steps/s，在online实验上我们使用20 PSs和100 GPU workers。Adam optimizer具有learning rate 0.001.。。。

略

# 5.经验分析

## 5.1 离线结果

表2展示了不同模型在离线数据集上的结果。我们会从这些模型的训练epochs中选择最好的结果。总之，除YoutubeDNN外，基于deep learning的方法要胜过传统的item-based CF一大截。在item序列上的average pooling会忽略items间的内在的相关性，造成推荐质量（recall、precision）的损伤。GRU4Rec和NARM会考虑short-term行为的演进。他们的效果要好于原始的DNN模型。为什么SHAN和BINN能比GRU4Rec好是因为：他们包含了更多的个性化信息，包括long-term行为和user profile表示。

我们提出的SDMMA会利用multi-head attention结构，并全面好于NARM。我们会在5.3节看一个具体的case来解决multi-head attention是如何捕获多种兴趣的。通过引入user profile表示，PSDMMA会增强该模型，因为不同类型的users会关注不同的items。short-term表示会更准，越多的顾客可以在候选列表中发现他们感兴趣的items。但很难为一个新用户推荐潜在的新items。通过考虑上long-term行为，会infer得到越精准的偏好。

PSDMMAL可以打败所有模型，它会考虑long-term偏好。不同于SHAN和BINN，它会应用一个fusion gate来组合short-term和long-term行为表示。该gate比hierarchical attention结构具有更强的表示能力。SHAN会简单使用user profile表示作为query vector来决定long-term和short-term偏好表示的attention weights。我们提出的PSDMMAL会建模它们间的相关关系。在5.4节会通过一个有意思的case来解释fusion gate的设计。PSDMMAL-N是最好的变种，它在训练期间采用next 5 items作为target classes。它可以召回更多样的items，会满足更广用户的需求，对于推荐系统的matching task更合适。PSDMMAL-NoS的结果表明，我们的模型在没有side information下效果会急剧下降。

## 5.2 在线A/B

当前，taobao的在线匹配算法是一个two-staged方法。**我们会将trigger items定义为一个用户最近交互过的items**。Item-based CF首先会生成item-item相似矩阵。trigger items会通过相似矩阵去召回相似的items。接着这些recalled items会通过GBDT进行rerank作为matching chandidates。这样的方法是我们的online baseline，我们替换它作为一个标准的A/B test。

我们会部署最好的的SDM模型PSDMMAL-N，同时也会部署没有long-term behaviors的版本。对比baseline模型，从顾客的序列行为infer出来的推荐items的质量，会比由item-based CF生成的相似items的要好些。特别是对于那些经常在线浏览的顾客，我们的模型会推荐新items给他们，并吸引更多眼球来提升潜在的订单率。图3展示了7天的在线结果。两个SDM模型会胜过baseline一大截，其中PSDMMAL-N具有一个整体pCTR :7.04%的提升，pGMV：4.5%，cover: 24.37%。合并long-term行为会带来更多的提升。long-term行为总是表示个性化偏好，它可以影响顾客的当时购物决策。注意，我们的sequential matching model在2018 12月后表现稳定。

## 5.3 Multi-head Attention的效果

我们在matching模型中探索了多种heads的影响。直觉上，short-term session会获得heads增加数目带来的准确率。表3上报了在离线taobao dataset上的结果。在该实验中，在PSDMMAL中，只有heads数目是不同的，并且模型的维度 hidden units d设置为64。

我们可以观察到，由head number引起的变化在4个指标上保持一致。当heads的数目少于4时，该效果呈现了heads量间的postive关系。当heads数目大于4时，结果会急剧变差。我们可以下结论：更多head并不必要正向，因为$$d_{head_i} = \frac{64}{#head}$$会变得更小，并造成更差的表示。在我们的settings中，4个heads可以获得最好的结果，我们会将在short-term session上不同heads的attention weights进行可视化，如图4所示。我们会选择LSTM的hidden output $$h_t^u$$作为在multi-head attention中的query vector，来获得到$$[h_1^u, \cdots, h_t^u]$$的attention weights。weight vector也是等式8中$$A_i^u$$的第t个row vetor。$$head_1$$和$$head_2$$主要关注在session中的前几个items，它们是白色羽绒衣（white down jackets）。$$head_3$$会捕获连衣裙（dress）的兴趣，$$head_4$$则会给出对牛仔裤（jeans）更多的attention。

## 5.4 Fusion Gate

element-wise乘法，concatenation和加法操作，会直接在未过滤的long-term偏好表示上进行，并忽略：在long-term上少量偏好会与当前short-term session具有强相关性。这些简单的组合方法会获得来自long-term偏好的所有信息，会天然地伤害fusion的效果，如图4所示，在taobao离线数据集上的效果。作为对比，我们提出的gated fusion network会准确捕获multi-layer user偏好，并达到最好的结果。在long-term偏好中与当前session高度相关的信息会与当前的short-term vector进行融合。

为了更好解释gated fusion，我们使用一个taobao的抽样用户的真实案例来解释gate的功能。如图5所示，$$R^u$$包含了我们模型推荐的items，它会被用户同时点击。我们可以看到，用户会浏览多种类型的玻璃，包括：红酒杯（red wine glass）和冠军杯（champion glass）。我们的模型可以直接推荐champion glasses，因为他们与用户的short-term session $$S^u$$中的最近点击有关。这意味着他更可能在此时对champion glasses感兴趣，该gate会允许保留该信息。同时，我们的gated fusion可以在它大量long-term行为$$L^u$$间捕获最相关的items （red wine），它也包含了许多不相关的点击：比如啤酒（beer）、削皮刀（paring knife）、小板块（small plate），并与short-term session的items（ red wine glasses）组合来生成推荐项：红酒瓶（red wine decanter）。该case表明：我们的gate module是有效的，并具有精准融合的能力。

图5



# 参考

- 1.[https://arxiv.org/pdf/1909.00385.pdf](https://arxiv.org/pdf/1909.00385.pdf)