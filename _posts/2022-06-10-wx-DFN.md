---
layout: post
title: wechat DFN介绍
description: 
modified: 2022-06-10
tags: 
---


wx在《Deep Feedback Network for Recommendation》一文中，提出了DFN用于建模负反馈。

# 1.介绍


# 3.方法

我们的目标是，联合考虑多个explicit/implicit以及postive/negative feedbacks来学习用户的无偏偏好。特别的，我们会认为：DFN模型可以收集用户历史行为的三种类型的feedbacks：

- 隐式正负馈（Implicit positive feedbacks）。隐式正反馈是最广泛使用的feedbacks，它可以满足quantity和quality。大部分常用模型，会考虑点击行为序列$$\lbrace c_1, \cdots, c_{n_1}\rbrace$$作为在DFN中的隐式正负馈
- 显式负反馈（Explicit negative feedbacks）。显式反馈是high-quanlity的，但很少。我们使用dislike按钮来收集，$$\lbrace d_1, \cdots, d_{n_2} \rbrace$$
- 隐式正负馈（Implicit negative feedbacks）。我们将“曝光未点击”行为序列$$\lbrace u_1, \cdots, u_{n_3}\rbrace$$作为隐式负反馈。这种未点击行为占绝大多数，它具有严重的噪音和false-negative信号。

DFN会尝试使用high-quality的click和dislike行为作为指导，来从未点击行为抽取有用信息。在DFN中也可以很方便地添加其它feedbacks.

## 3.1 总体结构

DFN主要包含两个模块，命名为：“deep feedback interaciton”模块和“feature interaction”模块。

- 首先，在外部和内部feedback交叉的帮助下，deep feedback interaction module采用多个feedbacks作为inputs来抽取用户无偏的positive和negative偏好。
- 第二，refined feedback features会与其它有信息的features进行组合、比如：user profiles、item features和推荐contexts。我们会采用Wide、FM和Deep组件来进行特征聚合（feature aggregation）。
- 最终，feature interaction module的outputs会被feed到fully connected和Softmax layers来使用postive和negative losses进行模型最优化。

图2展示了DFN的整体结构。

## 3.2 Deep Feedback Interaction模块

图2(b)中的deep feedback interaction模块会采用对target item的implicit postive(click)、explicit negative(dislike)和implicit negative(unclick) feedbacks作为inputs。我们会引入两个组件来学习从在不同类型feedbacks的interactions。

### Internal Feedback Interaction组件

该组件会关注target item和在一个特定类型的feedback的独立行之间的交叉。我们会在行为上采用一个multi-head self-attention。所有的行为特征包含了item embeddings和postive embeddings，并且投影到一个联合语义空间来形成behavior embeddings。为click behavior为例，我们会将target item t与click序列的behavior embeddings组合一起来形成input matrix $$B_c = \lbrace t, c_1, \cdots, c_{n_1}$$。query、key、value矩阵会被计算如下：

$$
Q = W^Q B_c, K = W^K B_c, V = W^V B_c
$$

...(1)

其中：

- $$W^Q, W^K, W^V$$是投影矩阵。

我们接着将self-attention计算如下：

$$
Attention(Q, K, V) = softmax(\frac{Q^T K}{\sqrt{n_k}}) V
$$

...(2)

其中：

- $$n_h$$是query、key、value的维度。total h个multi-heads的第i个head被计算如下：

$$
head_i = Attention(W_i^Q Q, W_i^K K, W_i^V V)
$$

...(3)

其中：

- $$W_i^K K, W_i^V \in R^{n_k \times n_h /h}$$是第i个head的weighting矩阵。self-attention的最终output matrix：

$$
F_c = concat(head_1, \cdots, head_h) \cdot W^O
$$

...(4)

$$W^O \in R^{n_k \times n_h}$$是投影矩阵。最终，我们在所有的n+1个output embeddings上采用一个average pooling到$$F_c$$来生成implicit postive feedback embedding $$f_c$$：

$$
f_c = Avergage\_pooling(F_c), f_c \in R^{n_h}
$$

...(5)

我们使用具有type-specific超参数的相同的transformer，分别从dislike和unclick行为来生成explicit negative feedback embedding $$f_d$$、以及implicit negative feedback embedding $$f_u$$。内部的feedback interaction组件可以很好捕获在target item和在每种类型的feedback序列行为之间behavior-level交叉。它可以提供与target item相关的user positive和negative偏好。

### External Feedback Interaction组件

Implicit negative feedbacks是必要的，但具有很多噪声。总之，unclick behaviors看起来意味着负信号（negative signals），而曝光给用户的items，会被特定策略选中，它可能包含来自粗粒度的用户兴趣。 external feedback interaction组件的目标是，根据在clickt dislike行为上的强反馈，区分用户在未点击行为上的like和dislike。特别的，我们会采用两个vanilla attentions，它会考虑implicit postive和explicit negative feedback embeddding $$f_c$$和$$f_d$$作为instructors来指导从unclick序列$$\lbrace u_1, \cdots, u_{n_3}\rbrace$$抽取postive和negative偏好。我们将具有dislike和unclick行为的unclick-dislike interaction embedding $$f_{ud}$$公式化成：

$$
f_{ud} = \sum\limits_{i=1}^{n_3} \alpha_i u_i, \alpha_i = \frac{f(f_d, u_i)}{\sum\limits_{j=1}^{n_3} f(f_d, u_j)}
$$
...(6)

其中，weighting score函数$$f(a, b)$$定义如下：

$$
f(a, b) = MLP(concat(a, b, a-b, a \odot b))
$$

...(7)

- $$\odot$$：看成是element-wise product，并使用2-layer multi-layer percentron(MLP)。
- $$f_d$$包含了用户的强负偏好，从与target item相关的explicit negative feedbacks进行refine得到

它可以帮助vanilla attention来抽取那些在未点击行为中用户真正不喜欢的items。我们也会使用implicit postive feedback embedding $$f_c$$来扩大在未点击行为中正信号：

$$
f_{uc} = \sum\limits_{i=1}^{n_3} \beta_i u_i, \beta_i = \frac{f(f_c, u_i)}{\sum\limits_{j=1}^{n_3} f(f_c, u_j)}
$$

...(9)

implicit postive和explicit negative feedbacks $$f_c$$和$$f_d$$被看成是强的正信号和负信号，而剩余的unclick-related feedbacks被看成是弱信号。

## 3.3 Feature Interaction模块

在feature interaction，我们会将refined feedback feature与其它包含了user profiles、item features以及推荐contexts的其它features进行组合。根据Guo[2017]，我们将这些sparse features分组成m个fields $$\lbrace x_1, \cdots, x_m \rbrace$$，包含了连续fields（例如：age）以及categorical fields（例如：location）。所有fields都被表示成one-hot embeddings。一个lookup table被用来生成所有fields的dense feature表示为$$\lbrace f_1, \cdots, f_m \rbface$$。我们实现了Wide、FM以及Deep组件进行feature interaction。

**Wide组件**

Wide组件是推荐中使用的一个通用线性模型。Wide组件$$y^{Wide}$$的output是一个m维vector，其中第i个element被计算如下：

$$
y_i^{Wide} = w_i^T x_i + b_i, w_i, x_i \in R^{n_{f_i}}
$$

...(10)

其中：

- $$w_i$$是第i个one-hot field embedding $$x_i$$的weighting vector
- $$b_i$$是bias
- $$n_{f_i}$$是$$x_i$$的维度

**FM组件**

FM组件会捕获在所有features间的二阶feature interactions。FM的input embeddings是将所有dense features和最终refined feedback features组合，表示为：$$F' = \lbrace f_1, \cdots, f_m, f_{Feed}$$。我们根据He[2017]中的Bi-interaction layer，并生成output embedding $$y^{FM}$$，如下：

$$
y^{FM} = \sum\limits_{i=1}^{m+5} \sum\limits_{j=i+1}^{m+5} 
$$

...(11)

**Deep组件**

在Deep组件中，我们实现了一个2-layer MLP来学习高阶feature interactions。输入部分是dense features与feedback features间的concatenation，被表示为: $$f^{(0)} = concat(f_1, \cdots, f_m, f_{Feed})$$。我们具有：

$$
y^{Deep} = f^{(2)}, f^{(i+1)} = ReLU(W^{(i)} f^{(i)} + b^{(i)})
$$

...(12)

其中：

- $$f^{(i)}$$：第i个layer的output embedding
- $$W^{(i)}$$：weighting matrix
- $$b^{(i)}$$：是第i个layer的bias

最终，我们将来自三个组件的所有outputs进行concatenate来生成聚合的feature embedding y：

$$
y = concat(y^{Wide}, y^{FM}, y^{Deep})
$$

...(13)

## 3.4 最优化目标

我们使用click、unclick和dislike行为来进行监督学习。预估的点击概率会使用aggregated feature embedding y如下计算：

$$
p(x) = \sigma(w_p^T y)
$$

...(14)

$$w_p$$是weighting vector，并且$$\sigma$$是sigmoid function。DFN的loss function包含了三部分，分别对应于click、unclick和dislike行为：

$$
L = - \frac{1}{N} (\lambda_c \sum\limits_{S_c} log p(x) + \lambda_u \sum\limits_{S_u} log(1 - p(x)) + \lambda_d \sum\limits_{S_d} log(1 - p(x))
$$

...(15)

训练集包含了N个样本，被分组成click set $$S_c$$，dislike set $$S_d$$，以及unclick set $$S_u$$。$$\lambda_c, \lambda_d, \lambda_u$$是不同losses的weights，用来measure不同feedbacks间的importances。



- 1.[https://www.ijcai.org/Proceedings/2020/0349.pdf](https://www.ijcai.org/Proceedings/2020/0349.pdf)