---
layout: post
title: AutoFAS粗排介绍
description: 
modified: 2022-05-01
tags: 
---


美团在《AutoFAS: Automatic Feature and Architecture Selection for
Pre-Ranking System》中提出了AutoFAS的做法：


# 1.摘要

工业界搜索和推荐系统大多数遵循经典的multi-stage IR范式：matching、preranking、ranking和reranking stages。为了对系统效率负责，简单的vector-product based模型常被部署到preranking stage中。大多数工作会考虑将大的ranking模型的知识蒸馏到小的preranking模型中以便得到更好的效果。然而，在preranking系统中存在两个主要挑战：

- i) 无法显式建模效果增益 vs. 计算开销，预定义的延迟限制会导致次优解
- ii) ，将ranking teacher的知识转移一个预先手工制作的结构到的preranking student中，仍会有模型效果的损失

在本工作中，提出了一个新的框架AutoFAS，它会联合优化preranking模型的效率和效果：

- i) AutoFAS首先同步选择大多数有价值的features，网络结构使用NAS技术（Neural Architecture Search）
- ii) 在NAS过程中使用ranking model进行指导收益，对于一个给定的ranking teacher，AutoFAS可以选择最好的preranking架构，无需任何计算开销

在真实世界搜索系统中的实验结果，展示了AutoFAS的效果要比SOTA的方法更好，并且开销更低。注意，我们的模型已经在美团的搜索系统的preranking模块上使用，取得了巨大提升。

# 1.介绍

略

# 2.相关工作

略

# 3.方法

我们的工作构建在NAS（neural architecture search）之上，因而我们首先介绍下该主题。接着给出preranking的介绍以及详细介绍我们的方法。

## 3.1 Neural Architecure Search

Neural network设计通常需要人工专家们的大量经验。在最近几年，在研究算法NAS解决方案来将结构设计过程由人工转向自动化上取得了大量关注【1，15，37】。一些工作【1，22】尝试通过共享跨模型权重来提升搜索空间，它会进一步划分成两类：

- continuous relaxation方法【3，17】
- One-Shot方法 【2,8】

基本上，我们遵循weight sharing方法，它包含了三个steps：

- (1) 设计一个过参数化网络（overparameterized network），因为搜索空间包含了每个候选结构
- (2) 在training set或held-out validation set上直接作出结构决策
- (3) 从头到尾retrain大多数有希望的结构，并在test set上验证它们的效果；

注意，在我们的场景和之前的结果间有一个大的不同之处是：我们需要同时联合搜索特征和结构。

## 3.2 搜索和推荐系统介绍

搜索和推荐系统的整体结构如图1所示。基本上，matching stage会从用户的动作历史、以及当前query中取出事件（如果存在）作为input，并从一个大的corpus（上百万）检索出一个小的items子集（上千）。这些与用户相关的候选通常具有适度准确性。接着，preranking stage会提供更大的个性化，过滤出具有高precision和高recall的近千个top items。一些公司会选择组合matching和preranking stages，比如Youtube【6】。接着，复杂的ranking network会根据期望的objective function，使用丰富的特征，为每个item分配一个score。在没有reranking的情况下，具有最高得分的items会根据得分排序展示给用户。通常，preranking会共享相似的ranking功能。最大不同点依赖于问题的scale。直接在preranking系统中使用ranking模型会面临计算开销问题。如何对模型效果和计算开销进行权衡是设计preranking的核心问题。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/6657c7b8c4f13b83e47a7df5bb6e8495adce9c601062da4d99406dba439353e3bba8ef61097a0195190d6a7f4fc9ef15?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1

## 3.3 美团Preranking的历史

之前提到，preranking模块可以被看成是一个在matching和ranking间的transiiton stage。在Meituan的主搜索上，它会接受来自matching阶段的上万个候选，并过滤出数百个结果给到ranking阶段。我们的底层preranking架构的演进：双塔模型、GBDT、当前的DPP模型。随着效果提升，大量的计算复杂度和大量存储使得它面临着更大的挑战。我们的online inference engine的瓶颈主要面临两部分：

- 从database的特征检索（feature retrieve）
- DNN inference

特征选择和神经网络结构选择对于成功部署高效且有效的preranking模型来说非常重要。

## 3.4 在Preranking中的特征选择和结构选择

我们的方法背后的一个关键动机是：我们应该联合构建preranking model以及ranking model，以便ranking model的知识可以自动指导我们为preranking model去发现最有价值的features和architechtures。因而，我们不会采用独立训练preranking models，而是会联合构建preranking model和常规的ranking model。我们首先描述了search space的构建，接着介绍：如何利用feature和architecture参数来搜索最有价值的features和architectures。

最终，我们会展示我们的技术来处理延迟以及KD-guided reward。

**搜索空间**

如图2所示，图的左半边是我们的ranking网络，而右半边是过参数化网络，它包含了所有的候选preranking models。这两部分会共享相同的input features $$F = \lbrace f_1, f_2, \cdots, f_M \rbrace$$。在我们的setup中，F主要包含了user features、item features以及interactive features。我们会使用所有的M个feature inputs来训练ranking model，接着将ranking model的大部分features进行归零（zero out）来评估它们的重要性，从而选出最好的特征组合。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/58655f9a8c58d5a473de4b9980e5727229f5f4f9850526de83134666348975bff69ee0f1eeb5dd19f041b4ffaeb22546?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2

与feature selection并行的是，我们需要搜索最优结构。假设O是一个building block，它包含了N个不同的候选操作符：$$O= \lbrace O_1, O_2, \cdots, O_N \rbrace$$。在所有case中，$$O$$包含了零操作符（zero operator）或具有多个hidden units的MLP。零操作符（zero operator）会保持input与output相同。一些参考里也将它称为等同操作符（identity operator）。注意，零操作符允许layers数目的减少。其它操作符比如外积、点乘可以被相似抽象并集成到框架中，这留给后续探讨。为了构建over-parameterzied network（它包含了每个候选结构），而非设置每条边是一个明确的原始操作（definite primitive operation），我们设置每条边是一个mixed operation（Mixop）具有N个并行路径（paralled paths），表示为$$m_O$$。接着，我们的over-parameterzied network可以被表示为$$N(e_1 = m_O^1, \cdots, e_L = m_O^L)$$，其中L是Mixops的总数。

**Feature和Architecture参数**

为了选择大部分有效的features，我们会引入M个real-valued mask参数$$\lbrace \theta_i \rbrace_{i=1}^M$$，其中M是涉及的features数目。不像[5]中会对每个weights进行二值化（binairzes），我们会将整个feature embedding进行二值化。这里，每个feature $$f_i$$的独立的mask $$g_i$$会被定义成以下的Bernoulli分布：

$$
g_i = \begin{cases}
[1, \cdots, 1], & \text{with probability $\theta_i$} \\
[0, \cdots, 0], & \text{with probability $1-\theta_i$} 
\end{cases}
$$

...(1)

其中，1s和0s的维度通过$$f_i$$的embedding维度来决定。会为样本的每个batch抽样M个独立Bernoulli分布结果。由于binary masks $$\lbrace g_i \rbrace_{i=1}^M$$会涉及计算图，feature参数$$\lbrace \theta_i \rbrace_{i=1}^M$$可以通过BP进行更新。

根据结构参数，我们会展示：在给定Mixop i的N个路径的outputs下，如何获得Mixop $$i+1$$的N个outputs？如图3所示，Mixop i的路径表示为$$m_O^i = \lbrace O_1^i, O_2^i, \cdots, O_N^i\rbrace$$，我们会介绍N个real-valued结构参数$$\lbrace \alpha_j^{i+1} \rbrace_{j=1}^N$$。接着，Mixop $$i+1$$的第k个output计算如下：

$$
O_k^{i+1} = \sum_{j=1}^N p_j^{i+1} MLP_j^k(O_j^i) \\
= \sum\limits_{j=1}^N \frac{exp(\alpha_j^{i+1})}{\sum_{m=1}^N exp(\alpha_m^{i+1})} MLP_j^k(O_j^i)
$$

...(2)

其中，multi-layer perceptron $$MLP^k$$具有相同的units数目$$O_k^{i+1}, p_j^{i+1} := \frac{exp(\alpha_j^{k+1})}{\sum_{m=1}^N exp(\alpha_m^{i+1})}$$可以被看成是在Mixop i+1中的第j个operator。在这种continuous relaxation后，我们的目标是：在所有mixed op中联合学习结构参数以及weight参数。

**Latencey Constraint**

除accuracy外，当设计preranking系统时，latency（not FLOPs或embedding维度）是另一个非常重要的目标。为了让latency不同，我们会将一个网格的latency建模为一个关于neural network结构的continous function。在我们的场景中，存在两个因子：feature相关的latency和结构相关的latency。features可以被进一步从latency的角度划分成两个类别：从matching stage传来过的、以及从in-memory dataset中检索过来的，分别表示成 $$F_1$$和$$F_2$$。如上，我们有关于一个特定特征$$f_i$$的期望latency：

$$
E[latency_i] = \theta_i \times L_i
$$

...(3)

其中，$$L_i$$是返回时间（return time），它可以被服务器记录。接着，$$E[\latency_i]$$的随结构参数的梯度可以给定：$$\partial E[latency_i] / \partial \theta_i = L_i$$。接着，期望的feature相关latencey可以以如下方式计算：

$$
E[latency] = max_{f_i \in F_1, f_j \in F_2} (E[latency_i] + \beta \cdot |F_1|, E[latency_j] + \gamma \cdot |F_2|)
$$

...(4)

其中，$$F_k$$表示了在$$F_k, k=1, 2$$的features数目, $$\beta, \gama$$影响着底层系统的不同并发数，可以由经验决定。

我们将这种expected feature latency饮食到常规loss function中，乘以一个scaling因子$$\lamma$$，它会控制着在accuracy和latency间的tradeoff。对于feature selection的最终的loss function为：

$$
Loss_1 = Loss_{Ranking} (y, f(X; \theta, W_{Ranking})) + \lambda E[latency]
$$

...(5)

其中，f表示ranking network。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/e003492779a352b04588c7db45300c1b0701af31eb0ae6535e83779caf67ae0d0d6bdaf6c79f412045f2d22cd3657f15?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3

相似的，对于Mixop i+1的结构latency，我们可以通过递归来计算它的expected latency $$E[latency^{'i+1}]$$，如图3的右图所示。由于这些ops可以在inference期间按顺序执行，preranking network的expected latency可以被表示为last Mixop的expected latency：

$$
E[latency'] = E[latency'^{L}]
$$

**Ranking系统的监督**

知识蒸馏（KD），会将teacher model的泛化能力转移给student model，受广泛关注。而在监督学习中的常规的one-hot label被限定在0/1 label内，从teacher model的soft probability output会对student model的知识有贡献。记住，在preranking系统中当前KD方法的一个缺点是：如果它只能将teacher的知识转移给具有确定网络结构的student。受AKD的启发，我们提出添加一个distillation loss给结构搜索过程（architecture search）。特别的，我们会采用由ranking models产生的soft targets作为监督信号来指导每个Mixop的选择。因此对结构选择的final loss function：

$$
Loss2 = (1-\lambda_1) Loss_{pre-Ranking}(y, g(X; \theta, \alpha, W_{pre\-Ranking})) + \lambda_1 || r(x) - p(x)||_2^2 + \lambda_2 E[latency']
$$

...(7)

其中，g是preranking network，$$Loss_{pre\-Ranking}$$表示使用已知hard labels y的pre-ranking pure loss。r(x)和p(x)分别是关于ranking和preranking network的final softmax activation outputs。

我们会进一步讨论$$\lambda_1$$的效果和第4.5节中的distilation loss。$$\lambda_2$$是scaling factor，它控制着在accuracy和latency间的tradeoff。Loss1和Loss2会一起优化，产生最终的multi-task loss function：

$$
Loss = Loss1 + Loss2
$$

...(8)

在Loss1和Loss2间的超参数的权衡的缺失来自于：Loss1只会最优化feature mask参数，而Loss2会最优化preranking model中的结构参数和weights。我们选择该策略是因为，它在经验上要好于没有gradient block的模型，如表5所示。Loss1和Loss2相互相关，Loss2的输入是masked embedding，其中：mask参数会通过Loss1在训练期间持续优化。为了获得最终的preranking结构，我们会保留在每个Mixop中的最强的features和operators，从头到尾都保留它。AutoFAS的整个训练过程如算法1所示。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/e0ac3f0d77126ed1ff845babf454609fd3818fd30a636317b55dec2ce0cb30e906131432e8f508345dc50858397bc96d?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=a1.jpg&amp;size=750">

算法1

# 4.实验

略


- 1.[https://dl.acm.org/doi/pdf/10.1145/3534678.3539083](https://dl.acm.org/doi/pdf/10.1145/3534678.3539083)