---
layout: post
title: 延迟反馈建模MTDFM介绍
description: 
modified: 2022-4-23
tags: 
---


蚂蚁在《A Multi-Task Learning Approach for Delayed Feedback Modeling》提出MTDFM的方法使用多任务来解决延迟反馈建模问题。

# 摘要

转化率（CVR）预测是数字展示广告中最为关键的任务之一。在工业推荐系统中，在线学习因其能够捕捉数据分布的动态变化而备受青睐，这通常能显著提高转化率。然而，点击行为与相应转化之间的时间间隔可能从几分钟到几天不等；因此，**新鲜数据在被训练算法摄入时可能没有准确的标签信息，这被称为CVR预测的延迟反馈问题**。为解决这一问题，**先前的工作将延迟的正样本标记为负样本，并在其转化时间进行校正，然后通过重要性采样（importance sampling）在观察分布下优化实际转化分布的期望**。然而，这些方法将实际特征分布近似为观察到的特征分布，这可能会为延迟反馈建模引入额外的偏差。在本文中，我们证明了**观察到的转化率(observed conversion rate)是实际转化率（actual conversion rate）与观察到的非延迟正样本率(observed non-delayed positive rate)的乘积**。然后，我们提出了多任务延迟反馈模型（MTDFM），该模型由两个子网络组成：实际CVR网络和非延迟正样本率（NDPR）网络。我们通过同时优化观察到的转化率和非延迟正样本率来训练实际CVR网络。所提出的方法不要求观察到的特征分布与实际分布保持一致。最后，在公共和工业数据集上的实验结果表明，所提出的方法一致优于先前的最先进方法。

# 1 引言

转化率（CVR）预测是推荐系统中最为关键的任务之一，其目标是：**预测用户在点击某个商品后是否会下单的概率**。在数字展示广告中，一个稳健的CVR预测算法对于构建具有竞争力的广告系统至关重要。例如，为了实现平台和广告主的双赢，**CVR预测被用于调整每次点击的出价**。近年来，CVR预测在学术界和工业界都得到了广泛研究。

在展示广告中，由于特殊事件、新广告活动等因素，数据分布会动态变化，因此在线学习常被用于捕捉这些变化。然而，用户点击后通常不会立即发生转化，转化可能会延迟几分钟到几天不等。这种延迟反馈问题给在线学习模型带来了挑战：我们需要新数据来更新CVR模型以保持模型的新鲜度，但这些数据往往缺乏用户反馈。

最近，一些流式训练方法通过重新设计数据管道和损失函数来解决延迟反馈问题。Ktena等人[4]首先将每个到达的实例标记为负样本，并在其转化时进行校正，然后提出了**伪负样本加权损失函数（FNW）**，通过重要性采样(importance sampling)[6]来优化真实转化分布的期望。Yang等人[7]研究了在流式CVR预测中，等待更准确的标签与利用更新鲜的训练数据之间的权衡。在他们的工作中，训练管道设计为一个短时间窗口，当转化发生在这个窗口内时，这些实例被标记为正样本，而其他实例则被标记为负样本，直到它们发生转化。随后，他们提出了**基于流逝时间采样的延迟反馈模型（ES-DFM）**，这也是一种基于重要性采样的方法，用于在观察分布下学习实际的CVR模型。尽管这些工作取得了令人振奋的性能，但这些方法仍存在一些问题。首先，这些基于重要性采样的方法将实际特征分布近似为观察到的特征分布，我们在第2.2节中证明这一假设并不成立。其次，这些方法只能用于它们设计的数据管道。为了区分，我们将FNW使用的数据管道称为**实时管道(real-time pipeline)**，而将ES-DFM使用的数据管道称为**流逝时间管道(elapsed-time pipeline)**。

在本工作中，我们解决了这些问题，并提出了一种用于延迟反馈建模的多任务学习方法（MTDFM）。该方法不要求观察到的特征分布与实际分布保持一致，并且可以同时用于实时管道和流逝时间管道。与直接训练实际CVR模型不同，**所提出的方法将实际CVR率 $ p_{cvr} $ 视为一个中间变量，其与观察到的延迟正样本率 $ p_{dp} $ 的乘积等于观察到的CVR率 $ p_{ocvr} $**。具体来说，我们的模型由两个子网络组成：**实际CVR网络**和**非延迟正样本率（NDPR）网络**。通过充分利用观察分布与实际分布之间的关系，我们在两个辅助任务 $ p_{dp} $ 和 $ p_{ocvr} $ 的帮助下训练实际CVR模型。我们的主要贡献可以总结如下：

- 我们提出了一种用于延迟反馈建模的多任务学习方法，该方法不要求观察到的特征分布与实际分布保持一致。此外，我们给出了该方法的收敛性证明。
- 我们给出了在流逝时间管道和实时管道下，实际CVR分布与观察CVR分布关系的统一形式。因此，我们的方法可以同时适用于这两种管道。
- 我们在公开数据集和工业数据集上进行了实验，结果表明我们的方法优于之前的最先进方法。

# 2 方法  
## 2.1 背景  
我们专注于CVR预测任务，该任务可以形式化为：对数据集 $ D = \lbrace (x_i, y_i) \rbrace_{i=1}^N $ 的二分类概率预测，其中：

-  $ x $ 是由用户字段和商品字段组成的特征
- $ y \in \lbrace 0, 1\rbrace $ 表示转化label

在实际应用中，由于转化行为可能会延迟很长时间，真实标签通常是不可用的。为了解决CVR预测中的延迟反馈问题，常见的方法是等待一定时间间隔内的真实转化[7, 8]。**伪负样本加权（FNW）方法**[4]可以看作是等待时间窗口大小为0的特殊情况。尽管等待时间方法可以部分校正样本，但在等待时间窗口之外的样本仍会被错误地标记为负样本。  

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/33136952767077e63c0bd887c45f4798b90de1aa2feba38c97fa3d88ec35b473afae28b5e11665afe1f5d63adc52ad9d?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 在训练pipeline中不同类型样本的图示

总结来说，如图1所示，存在三种类型的样本：  
- **负样本（Negatives）**：在等待时间窗口内未发生转化的样本。  
- **延迟正样本（Delayed Positives）**：在等待时间窗口外发生转化，但在用户点击后立即被摄入训练管道的样本。  
- **正样本（Positives）**：在等待时间窗口内发生转化的样本。  

我们用：

- $p$ 表示真实数据分布
- $q$ 表示由上述三种样本组成的偏置观察数据分布。
- $p(y=1 \mid x)$ 是真实转化概率
- $q(y=1 \mid x)$ 是在偏置分布中观察到转化的概率
- $q(dp=1 \mid x)$ 表示在偏置分布中观察到延迟正样本行为的概率，其中 $ dp \in \lbrace 0, 1\rbrace $ 是延迟正样本的标签。 

## 2.2 真实转化分布与观察转化分布之间的关系  

随着延迟正样本的摄入，我们知道：

$$
q(dp=0) = \frac{1}{1 + p(dp=1)} \\
q(dp=1) = \frac{p(dp=1)}{1 + p(dp=1)}
$$

由于摄入过程不会影响等待时间窗口内的样本，因此可以得到：

$$
q(x \mid dp=0) = p(x) 
$$
 
此外，由于重复样本和转化样本的特征分布在真实分布和观察分布中是相同的，因此：

$$
q(x \mid dp=1) = p(x \mid dp=1) \\
q(x \mid y=1) = p(x \mid y=1) 
$$
 
最后，由于添加的延迟正样本和真实正样本最终在观察数据中都会被标记为正样本，因此可以得到： 

$$
q(y=1) = \frac{p(y=1)}{1 + p(dp=1)}.
$$  

基于上述概率方程和全概率公式，观察数据中的特征概率可以计算为：  

$$
\begin{aligned}
q(x) &= q(dp=0)q(x|dp=0) + q(dp=1)q(x|dp=1) \\
&= \frac{p(x)}{1 + p(dp=1)} + \frac{p(x|dp=1)p(dp=1)}{1 + p(dp=1)} \\
&= \frac{p(x) + p(x, dp=1)}{1 + p(dp=1)}
\end{aligned}
$$  
...(1)

## 2.3 多任务延迟反馈建模  

在本节中，我们详细介绍了所提出的方法——**MTDFM（多任务延迟反馈建模）**。图2展示了MTDFM的整体架构，它由两个子网络组成：左侧的**CVR（点击后转化率:post-click conversion rate）网络**和右侧的**NDPR（非延迟正样本率:Non-Delayed Positive Rate）网络**。我们采用多任务学习方法，同时预测：

- 观察到的转化概率 $ q(y=1 \mid x) $ 
- 非延迟正样本概率 $ q(dp=0 \mid x) $

此外，我们建模 $ p_{NDPR} $ 而不是 $ p_{OCVR} $（观察到的点击后转化率：Observed post-click Conversion Rate），因为除以 $ p_{CVR} $（通常是一个较小的值）会导致数值不稳定性。受**ESMM**[5]（由相同结构的CVR和CTR网络组成）的启发，我们在CVR和NDPR模块中采用全连接神经网络，并在它们之间共享嵌入查找表。  

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/b8a63a08fe1f0c2c9d36b50d317a757b040df69c9bf993b36fcbd0a3cc3916414e59bf32239c091b55febf43ce8b6d4e?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2

MTDFM的损失函数定义为：  
$$
L(\theta_{cvr}, \theta_{ndpr}) = \sum_{i=1}^N l(y_i, f_{\theta_{cvr}}(x_i)[f_{\theta_{ndpr}}(x_i)]) + \sum_{i=1}^N l(1 - dp_i, f_{\theta_{ndpr}}(x_i)),
$$  
(5)  

其中，$ \theta_{cvr} $ 和 $ \theta_{ndpr} $ 分别是CVR和NDPR网络的参数，$ l(\cdot) $ 是交叉熵损失函数，方括号内的项在计算损失对输入的梯度时不考虑。需要注意的是，MTDFM中的子网络采用全连接神经网络，但可以替换为其他更复杂的模型[2, 3, 10, 11]，这可能会获得更好的性能。由于篇幅限制，我们省略了这些内容，专注于解决实际应用中处理转化延迟反馈的挑战。  

### 2.4 收敛性证明  
在本节中，我们给出了理论证明，表明MTDFM中的 $ p_{CVR} $ 将通过在线梯度下降收敛到真实转化率。需要注意的是，$ \theta_{ndpr} $ 的梯度仅由公式(5)中损失函数的第二部分贡献，且标签 $ 1 - dp_i $ 是无偏的，因此 $ f_{\theta_{ndpr}}(x) $ 最终会收敛到真实的观察非延迟正样本概率。最后，$ L(\theta_{cvr}) $ 对 $ f_{\theta_{cvr}} $ 的梯度可以表示为：  
$$
\frac{\partial L}{\partial f_{\theta_{cvr}}} = \frac{\partial \lbrace q(y=1|x) \log(f_{\theta_{cvr}}(x)[f_{\theta_{ndpr}}(x)]) \rbrace}{\partial f_{\theta_{cvr}}} + \frac{\partial \lbrace (1 - q(y=1|x)) \log(1 - f_{\theta_{cvr}}(x)[f_{\theta_{ndpr}}(x)]) \rbrace}{\partial f_{\theta_{cvr}}}
$$
$$
= \frac{p(y=1|x)q(dp=0|x)}{f_{\theta_{cvr}}(x)} - \frac{(1 - p(y=1|x)q(dp=0|x))[f_{\theta_{ndpr}}(x)]}{1 - f_{\theta_{cvr}}(x)[f_{\theta_{ndpr}}(x)]}
$$
$$
\approx \frac{q(dp=0|x) \left( p(y=1|x) - f_{\theta_{cvr}}(x) \right)}{f_{\theta_{cvr}}(x) \left( 1 - f_{\theta_{cvr}}(x)q(dp=0|x) \right)}.
$$  
(6)  

当 $ f_{\theta_{ndpr}}(x) $ 在训练足够步数后收敛到 $ q(dp=0|x) $ 时，公式(6)成立。当 $ f_{\theta_{cvr}}(x) > p(y=1|x) $ 时，$ \partial L / \partial f_{\theta_{cvr}} < 0 $；当 $ f_{\theta_{cvr}}(x) < p(y=1|x) $ 时，$ \partial L / \partial f_{\theta_{cvr}} > 0 $。这表明CVR子网络的输出 $ f_{\theta_{cvr}}(x) $ 会收敛到真实转化分布 $ p(y=1|x) $，且梯度始终指向正确的方向。  

### 3 实验  
#### 3.1 数据集  
为了评估不同方法的有效性，我们在公开数据集**Criteo**[1]和来自支付宝应用在线环境的工业数据集上进行了实验。Criteo数据集广泛用于延迟反馈问题，包含超过1500万条样本，时间跨度为60天，我们使用其中7天的数据进行实验。支付宝数据集来自营销活动，我们对用户进行了2%的抽样，抽样后的数据集包含约200万条样本。  

#### 3.2 实验设置  
我们选择了最先进的延迟反馈模型作为基线进行效率比较。基线方法包括**Fake Negative Weighted (FNW)**[4]、**Fake Negative Calibration (FNC)**[4] 和 **Elapsed-Time Sampling Delayed Feedback Model (ES-DFM)**[7]。所有方法（包括基线和MTDFM）使用相同的模型架构。学习率设置为0.01，L2正则化强度设置为 $ 10^{-6} $。我们使用**AUC（曲线下面积）**和**PR-AUC（精确率-召回率曲线下面积）**作为评估指标。

### 3.3 流式实验协议  
我们遵循[7]中的流式实验设置，并使用观察到的标签构建流式数据。然后，在转化时间添加假负样本数据。流式数据根据训练时间划分为多个子集，每个子集仅包含一小时的数据。这些子集将按顺序输入模型。当使用第 $ t $ 小时的数据完成训练后，第 $ t+1 $ 小时的数据将用于评估。AUC指标通过所有子集的平均值计算。由于营销活动通常持续时间较短且不超过一个月，为了更好地评估不同模型在真实营销场景中的表现，我们省略了预训练阶段，仅使用流式训练数据训练所有模型。  

为了验证流逝时间的影响，我们在不同设置下训练MTDFM。MTDFM采用与FNW和FNC相同的实时流式训练设置。MTDFM-win采用15分钟的流逝时间窗口，与论文[7]中的ES-DFM设置相同。  

### 3.4 实验比较  
实验结果如表1和表2所示，最佳结果以粗体标记。除了基线方法外，我们还展示了**ORACLE∗模型**的性能。ORACLE∗模型使用带有真实标签的训练数据集，而不是观察到的标签。ORACLE∗模型的CVR预测不存在延迟反馈问题，其性能是其他方法的上限。  

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/72660366d86a8495f374ea833025c6a86246a4c35bd11bbddbee10517a92c82c88e824498c1f353cf03917f6f860c878?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=t1.jpg&amp;size=750">

表1

可以发现，MTDFM-win在Criteo数据集的AUC和PR-AUC指标上取得了最佳性能。在支付宝数据集上，MTDFM-win在AUC指标上表现最佳，而MTDFM在PR-AUC指标上优于MTDFM-win。实验结果表明，使用流逝时间窗口并不一定能获得最佳结果，这是对流逝时间窗口大小的权衡。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/fb584d1d5f2c9ecc0bd6153d5e52d2101c404d8f38e58f9207ad0adda998d2f617271426a5f26dd220cffeabf6062e47?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=t2.jpg&amp;size=750">

表2

### 4 相关工作  
Chapelle [1] 首次提出了延迟反馈模型（DFM），在延迟分布服从指数分布的假设下应用生存时间分析。Yoshikawa 和 Imai [9] 改进了 Chapelle 提出的模型，无需假设任何参数分布，并提出了一种非参数延迟反馈模型（NoDeF）来捕捉时间延迟。Yasui 等人 [8] 将延迟反馈形式化为数据偏移问题，其中训练和测试的条件标签分布不同，并提出了一种重要性加权方法（FSIW）来处理这一问题。这些方法的一个显著缺点是难以应用于连续训练场景。  

Ktena 等人 [4] 提出了伪负样本加权（FNW）和伪负样本校准（FNC）的损失函数，这些方法首次通过在线梯度下降应用于延迟反馈问题的在线训练。Yang 等人 [7] 提出了基于流逝时间采样的延迟反馈模型（ES-DFM），该模型建模了观察到的转化分布与真实转化分布之间的关系。

附录：

- 1.[https://dl.acm.org/doi/pdf/10.1145/3487553.3524217](https://dl.acm.org/doi/pdf/10.1145/3487553.3524217)