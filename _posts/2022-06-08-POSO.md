---
layout: post
title: POSO介绍
description: 
modified: 2022-06-08
tags: 
---

kuaishou在《POSO: Personalized Cold Start Modules for Large-scale Recommender Systems》中提出了POSO的方法：

# 1.介绍

大规模推荐系统每天面临着大量新用户。一个重要挑战是：如何为这些未见过的用户做出精准推荐。一方面，这些用户很难具有历史描述或初始数据。另一方面，他们要比常规用户更加敏感、不耐烦。**对他们来说，不够精准的推荐可能会失去吸引力，从而不会再返回平台。从而，我们可能会失掉这些新用户的潜在价值**。

该问题被称为“user cold-start问题”。不同于item cold start问题（我们可以利用内容features），**user cold start很难提供可选描述，需要系统去快速捕获用户兴趣**。基于【10，12】的meta-learning可以通过产生良好泛化的initialization来缓解该问题。另外，其它工作【14，26】尝试其余features来生成ID embedding，从而提供缺失线索（missing cues）。

然而，我们会讨论：存在另一个被忽略的问题：**个性化淹没（submergence of personalization）**。该问题描述了一个现象：**尽管个性化features被用来对不同的user groups（它们的分布非常不同）进行balance，但由于存在非常严重的不均衡样本（imbalanced samples），这些features会被淹没**。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/18af28e6a31fe7ca2a31cac4d38fcf9c045a39a9b8d163ec459aa99dc5b955de4ac7ebc014b37217552e1b94f15e8f77?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 a) 新用户后验行为的可视化（基于来自常规用户的动作 数/率的相对差异）。它展示了新用户会与常规用户具有非常不同的差异。 b) imbalanced和well-balanced features的敏感度，通过两个size=128的向量进行可视化。在每个vector中的Bins表示了当对imbalanced/balanced features进行mask时的activation差异。颜色越深表示差异越大

如图1(a)所示，我们会以常规用户的后验行为（观看时长/VV数/点赞率/完播率）作为原始点，来展示新用户的分布差异。该图展示了**新用户会遵循非常不同的分布。理论上，我们期望：个性化features是为了区分user groups。但在实际中，这样的features真的能帮助模型对不同分布进行平衡吗？该回答是NO**。我们发现：个性化input是被淹没的，如图1(b)所示。在两种case中，我们使用相同的well-trained模型，当一些features会mask为0，并将activation差异进行可视化（近网络end，跨多个batches进行平均）。前者我们会将新用户indicator进行mask（0表示常规则用户、1表示新用户）。令人吃惊的是，activation几乎是保持不变。原因是：这样的features会非常不均衡：**在所有样本中，新用户样本量少于5%。在训练过程中，该indicator在大多数时候几乎不会变更，因此该feature变得可有可无**。作为对比，我们会对一个well-balanced feature（user country）进行mask。不同于前者，activation会有大变化。以上的观察建议：一个普通模型结构对于维持个性化来说是不充分的。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/3b2612ff662e72b61f01ad1783ff30ab4479c6746674d6dbb290004e642e328e81d6fef44bd1e79678876673fafd7d46?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2 Kwai中的大规模推荐系统。有三个stages：embedding generation，序列型特征建模（MHA）、多任务优化（MMoE）

在本paper中，我们提出了一个有效的模型来解决上述问题：Personalized COld Start MOdules (POSO)。

- 首先，POSO会通过**分配独立的modules组合**来让不均衡样本相等，每个module只会关注于它分配的user groups。
- 接着，POSO会生成**个性化gates**，区别于原始个性化features。
- 最后，**gate和module outputs会组合来形成综合表示**。


它的有效性有两部分：

- 1) 样本实际上被分配给特定的子模块（sub-modules），不管是大多数还是少数
- 2) Gating network被选中的个性化features完全决定（称为："个性化码：Personalization Code"），它会避免它的“淹没”。POSO会强制个性化，对不同分布进行balance，并缓和冷启问题。POSO不会为作一个单独方法进行服务。它会集成到许多已经存在的modules中，比如：MLP、Multi-head Attention（MHA）、MMoE。通过进行合理近似和详细分析，我们会派生出它的个性化版本，它会带来引人注目的增长，同时计算开销很小。

POSO的一个优点是：它对大规模系统很有利：

- 1）它遵循标准的训练过程，不同于meta-learning-based方法（它会将训练数据split成support/query set，并可能减慢训练速度）
- 2）计算开销是可忽略的
- 3）它可以被用到其它数据不均衡问题，它可以广泛存在于users/items/countries/regions。

我们在大规模推荐系统Kwai上开展实验。在真实场景中，POSO(MLP)/POSO(MHA)/POSO(MMoE) 一致性提升该效果，并效果好于已存在方法。当部署到我们的在线系统，它对于新用户带来+7.75% Watch Time和+1.52% Retention Rate。除了user cold-start场景，提出的架构提升了item cold start（对于新视频带来+3.8% Watch Time），效果好于在MovieLens 20M dataset上的已存在方法。

该paper的贡献总结如下：

- 1) 展示了个性化淹没问题
- 2) 提出了一个称为POSO的新方法
- 3) 提出详细推导并展示了POSO可以被集成到许多modules中

# 4.个性化冷启模块（POSO）

推荐系统会存在对于新用户缺少初始数据。然而，我们会争论一个被忽略的问题：个性化淹没。由于数据不均衡，它意味着系统会对于平衡不同分布上失败，尽管提供了个性化features。

首先，我们展示了new users的行为分布与常规用户非常不同。在图1(a)中，我们会对新/常规用户的后验行为进行可视化。我们展示了新用户指标的相对差异。我们观察到：

- 1）新用户会生成更低的VV（Video View）
- 2）新用户具有更高的Finish-View Rate，但具有更低的pre-play Watch Time。他们会喜欢短视频，但在长视频上具有更少的耐性
- 3）新用户趋向于更高频的“like”，看起来对广泛的视频感兴趣。

所有观察暗示着：新用户的行为会与常规用户遵循非常不同的分布。

已经存在的模型暗示着：通过利用个性化features，比如：一个indicator来区分新/常规用户，对不同模型进行均衡。然而，由于数据不均衡，这样的features被淹没。在图1（b），我们利用一个 well-trained model，对个性化features进行mask，并将活跃度差异进行可视化。令人吃惊的是，对严重不均衡新用户的indicator进行masking几乎对活跃度不会有影响。作为对比，当对well-balanced user country feature进行masking时，活跃度极大变化。由于新用户只会占据5%的样本。大多数时间，该indicator会保持不变。该模型轻易关注于其它features来搜索解决方案，并“忘掉”新用户indicator，对于cold-start问题是很严重的。我们称该问题为“个性化淹没”。

在本paper中，我们从一个模型结构视角来增强个性化features。我们会通过分配单独的模型组合来将不均衡个性化features进行调平，来解决淹没问题。理想的，你可以为一个指定用户构建一个排它模型（exclusive model）：

$$
y^u = f^u (x^u)
$$

...(4)

其中：

- x, y, f分别表示inputs、outputs、以及模型
- 上标u表示一个指定用户

在这样的scheme中，个性化在相应的模型中完全保留。不幸的是，由于大量用户，上述是不可行的。一个可能的解决方案是：为每种类型的user group（比如：新用户、回流用户）确立一些单独模型。一个指定用户可以被看成是多种user groups的组合（例如：你可以是半活跃用户和半常规用户）。相应的，我们可以为每个指定用户将prediction解耦成关于user groups的预估组合：

$$
y^u = \sum\limits_{i=1}^N w_i f^{(i)}(x)
$$

...(5)

其中：

- i表示模型index
- 我们有N个模型

实验上，很难生成$$w_i$$。作为替代，我们使用gating networks来从个性化features中生成$$w_i$$：$$w_i = [g(x^{pc})]_i$$，其中：pc表示个性化编码（Personalization Code），例如：标识user group的关键特征。因此，我们仍必须准备N个独立模型来捕捉user group兴趣，它是计算敏感的。我们方法的一个关键点是：我们会在中间模块（intermediate modules）上进行分解，并保持剩余模块不变：

$$
\hat{x} = C \sum\limits_{i}^N [g(x^{pc})]_i f^{(i)}(x)
$$

...(6)

其中，f表示当前modules，$$\hat{x}, x$$是两相邻接layers的activations。注意，在g(x)的sum上没有约束，以便避免整体尺度漂移，会使用一个修正因子C。

等式6展示了提出方法的原型。它将个性化引入了中间模块中，我们将它命名为““Personalized COld Start MOdules （POSO）”。

POSO的设计会以下原则标记：Personalization。POSO会以两方面解决淹没问题：

- 1）Features会通过 分配多个modules和gates进行等化。尽管常规用户数据占主宰，由于 POSO会利用另一个集合的modules和gates来做出预估，因而新用户不会被忽略。
- 2）当应用任何一个layer时，POSO会通过原始features个性化、而非second-hand activations，它很难通过self-learning（比如：MoE）技术达到。

**灵活性（Flexibilit）**

注意，POSO是一个独立module，但是是对已存在技术进行个性化的通用方案。POSO可以很方便地集成中许多存在的方法中，来等化个性化。在以下中，我们会派生出MLP, MHA和MMoE的个性化。我们也相信，当应用其它未探索modules时，它具有好的预期。

**无后效性（Non-aftereffect）**

POSO的子模块会共享相同的input和它们的oututs，最终融合到单个综合结果中。这确保了结构独立。在上下游间没有引入依赖。

## 4.1 线性变换的POSO

我们从最基础的module开始：线性转换；它被公式化成：$$f(x) = Wx$$，其中：$$x \in R^{d^{in}}$$和$$\hat{x} \in R^{d^{output}}$$。将公式替换成等式(6)给出：

$$
\hat{x} = C \sum\limits_{i=1}^N [g(x^{pc})]_i W^{(x)} x
$$

...(7)

特别的，$$\hat{x}$$的第p个entry为：

$$
\hat{x}_p = C \sum\limits_{i=1}^N \sum\limits_{q=1}^{d^{in}} [g(x^{pc})]_i W_{p,q}^{(i)} x_q
$$

...(8)

其中：$$W_{p,q}^{(i)}$$指的是$$W^{(i)}$$在位置(p,q)的元素。尽管等式(8)引入了N倍的复杂度，足够自由的参数允许我们在灵活方法下进行简化。这里我们展示了一种简单但有效的方法。假设：$$N = d^{output}, W_{p,q}^{(i)} = W_{p,q} \forall p, q$$。。。我们有：

$$
\hat{x}_p = C \cdot [g(x^{pc})]_p \sum\limits_{q=1}^{d^{in}} W_{p,q} x_q
$$

...(9)

或等价的：

$$
\hat{x} = C \cdot g(x^{pc}) \odot Wx
$$

...(10)

其中：

$$\odot$$表示element-wise乘法。这种简单导致一个计算效率操作：通过个性化gates只在原始output上应用element-wise乘法。

## 4.2 MLP的POSO版

根据第4.1节中的相似派生，带activation funciton的个性化版本的FC设计如下：

$$
\hat{x} = C \cdot g(x^{pc}) \odot \sigma(Wx)
$$

...(11)

其中，$$\gisma$$表示activation function。它表示了与LHUC的一个相似形式，它的hidden unit贡献被通过个性化gates（personalized gates）替代。

天然的，MLPs的个性化版本，称为：POSO(MLP)，通过将personlized FCs进行stack来得到。它的框架如图3(a)所示。在表1中，我们描述了每个module的参数和FLOPs，并指出提出的modules是计算上高效的。


<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/682e06368df2388a8ab7caeb7e466c699be61ffa4bdcf3264ca247c1db2b85ff2f1e25dee38146b6167b2a08d49ef8b4?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3 使用POSO的个性化模块：(a) POSO(MLP)，会分别mask在每个layer中的每个activation  (b) 在POSO(MHA)中，Q不是个性化的，K是轻量级个性化，V是完全个性化 (c) 在POSO(MMoE)，个性化首先会被采纳，接着该output会feed特定的任务。POSO的所有modules通过黄色表示。

## 4.3 MHA的POSO版

在本部分，我们会生成Multi-Head Attention(MHA) module的POSO版本。我们首先考虑single head的公式：

$$
\hat{x} = softmax(\frac{QK^T}{\sqrt{d^h}})V
$$

...(12)

通过将等式(12)代入等式(6)作为$$f^{(i)}$$，我们有：

$$
\hat{x} = C \sum\limits_{i=1}^N [g(x^{pc})]_i (softmax(\frac{QK^T}{\sqrt{d^h}}) V^{(i)})
$$

...(13)

该naive实现引入了multi-fold Q, K, V。尽管提升了该效果，它的计算开销很大。为了减少开销，我们会重新考虑Q, K, V的角色。

首先，Q包含了除历史行为的所有user features，因此它已经是高度个性化的。因此，我们只设置：$$Q^{(i)} = Q, \forall i.$$。另一方面，$$V^{i}$$涉及很少用户信息。考虑到V直接决定了output，我们会在multi-fold $$V^{(i)}$$上不作任何简化。我们注意到，使用multi-fold K会引入冗余的自由参数，因为由K和Q生成的attention weight要比K本身具有更低维。可选的，对于element-wise乘法的一个个性化gate $$G^k$$对于调整attention weight来说是足够的，例如：$$K^{(i)} = G^k (x^{pc}) \odot K$$。

至今，Q、K同时变得与i不相关，因而可以从求和中移除。等式(13)接着被简化为：

$$
\hat{x} = C \cdot softmax( )
$$

...(14)

总之，我们会分别在三个levels上个性化components：对Q没有个性化，对K做轻量级个性化，对V做完全个性化。在三个tensors上的个性化也会遵循在 MHA中的角色。最终，对于multi-head的cases，每个head的outputs会concatenated一起来形成该representations。

提出的module被称为“POSO(MHA)”，它的framework如图3(b)所示。在我们的场景中，对比起原始版本的MHA，POSO(MHA)具有相当的复杂度（见表1），但有极好的效果。

## 4.4 MMoE的POSO版本

在本部分，我们描述了MMoE的POSO版本。将等式2代入等式6到：

$$
\hat{x}^t = C \sum\limits_{i=1}^N [g(x^{pc})]_i (\sum\limits_{j}^{N^e}[g^t(x)]_j e^{(j)}(x))
$$

...(15)

其中：

- i,j,t 分别索引了personalized gates、experts和tasks。

在等式15中，存在两个隐式约束：每个group的experts会共享个性化gate $$g^{(i)}$$，每个group的$$g^t$$会通过softmax进行归一化。我们将该约束进行放松来简化该实现。首先，我们允许每个expert具有它自己的personalized gate。接着，我们实现了在所有task gates上的normalization。我们有：

$$
\hat{x}^t = C \sum\limits_{i=1}^N \sum\limits_{j=1}^{N^e} [g(x^{pc})]_{ij} [g^t(x)]_{ij} e^{(ij)}(x)
$$

...(16)

其中：

- $$g^t$$会通过(i, j)的所有pair进行归一化。

注意在等式(16)中，索引i和索引j会联合索引 experts。假设：$$\hat{N} = N N^e$$，我们可以对modules进行re-index，并重写上述的等式：

$$
\hat{x}^t = C \sum_{i=1}^{\hat{N}} [g(x^{pc})]_i [g^t(x)]_i e^{(i)}(x)  \\
g^t(x) = softmax(W^t x)
$$

...(17)(18)

整体unit count $$\hat{N}$$实际上是一个超参数，它可以被人工调节。在我们的实验中，我们设置成$$\hat{N} = N$$来节约计算复杂度。

在等式（17）中，我们获得最终版本的personalized MMoE，称为：POSO（MMoE）。该实现相当轻量级（见表1）：你可以保持MMoE的所有结构，并只要通过它的personlized gate来将每个expert进行mask，如图3(c)所示。

POSO(MMoE)如何提升experts的效果呢？在MMoE中，experts是task-aware的，但在样本上具有模糊知识。在POSO(MMoE)中，experts是个性化激活的（personlized activated）：如果属于新用户的样本在$$g[\cdot]_i$$中生成更高的weight，相应的第i个expert会获得更高的学习权重，并变得对新用户更敏感，反之亦然。在这样的方式下，experts会变得specialized。我们可以说：experts不仅是task-aware，在user groups上也是field-aware的。在第5.6节中，我们会在MHA中对value矩阵的gating network outputs进行可视化。他们会被相似地进行larly speci

## 4.5 POSO对Cold start作用

现在，我们展示了如何POSO的知识，来缓解cold start问题。

**User Cold Start**

新用户被定义成：首个launch会发生在$$T_{du}$$个小时内的用户。对于user cold start，我们会利用一个细粒度feature来展示：对该用户有多少items会被曝光，例如： bucketized Accumulated View Count。该feature被feed到gating network g中作为PC。在每个module中，我们会为gating network保持相同的input，并增强个性化。

**Item Cold Start**

新item(video)的定义有两方面：

- 1) 在$$T_{dv}$$天内上传的
- 2）整体曝光数小于$$T_s$$

相似的，我们可以利用（exploit）video age来区分常规/新 视频。它仍能生成个性化，但从videos的视角。

在本paper中, gating network会由two-layer MLP组成，它的outputs会由sigmoid functions激活。

# 实验

略

- 1.[https://arxiv.org/pdf/2108.04690.pdf](https://arxiv.org/pdf/2108.04690.pdf)