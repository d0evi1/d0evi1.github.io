---
layout: post
title: 延迟反馈建模FNW介绍
description: 
modified: 2022-12-02
tags: 
---

twitter在《Addressing Delayed Feedback for Continuous Training with
Neural Networks in CTR prediction》提出了一种FNW的逻辑：

# 摘要

在展示广告中，一个挑战是特征分布和点击率（CTR）可能会因为季节性变化、广告活动的变化和其他因素而随时间发生大幅度变化。为了跟上这些变化，主要的策略是持续在新鲜数据上训练预测模型，以防止它们变得过时。然而，在许多广告系统中，**正向标签（postive label）只有在可能很长且随机的延迟之后才会被观察到**。这些延迟的标签对连续训练中的数据新鲜性构成了挑战：在它们被训练算法摄取时，新鲜数据可能没有完整的标签信息。

**naive策略是：将任何数据点视为负例，直到正向标签变得可用，往往会低估CTR，导致用户体验不佳和广告商的性能次优**。本文的重点是确定最佳损失函数和模型的组合，以便在存在延迟标签的情况下，从连续数据流中进行大规模学习。在这项工作中，我们比较了5种不同的损失函数，其中3种是首次应用于这个问题。我们在离线设置中使用浅层和深层模型架构，对公共和专有数据集进行了基准测试。我们还讨论了在生产环境中实现每种损失函数的工程成本。最后，我们对表现最佳的几种方法进行了在线实验，以验证它们在连续训练方案中的性能。在离线训练6.68亿内部数据点时，我们提出的方法比之前的最先进水平提高了3%的相对交叉熵（RCE）。在在线实验中，我们观察到每千次请求的收入（RPMq）比naive logloss增加了55%。

# 1.介绍

许多广告商会选择在用户执行了预定义动作(例如点击他们的广告或访问他们的网站)之前不支付任何曝光（impression）费用。这个问题在广告领域是众所周知的，并引入了诸如每次点击成本（CPC:cost-per-click）和每次转化成本（CPA:cost-per-conversion）等模型，允许广告商只对预定义的参与度（engagements）进行付费。这些基于绩效的付费模型需要**估计一次曝光能够产生的特定参与度(engagement)的概率**。

在展示广告中，由于特殊事件、新活动和其他因素，特征和点击率（CTR）分布可能会经历巨大的变化。图1和图2通过时间展示了这些变化。为了解决这个问题，Twitter的广告预测模型会不断在线训练新鲜数据，即它们接收连续的数据流，并在新数据到达时更新模型（见图3）。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/da361c2b0ff27680a5e1e43889f5bf8867d79e198e30acb386b8e9521ad5e91a52d85ee1690062a87bbf2d7eeaa4f3ae?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 在参照日之后每个小时的带有新广告活动ID(campaign ID)的流量百分比

在上述场景中遇到的主要挑战是**用户行为反馈的延迟**。一些参与度（engagements），例如广告上的一次点击或广告视频的一次MRC观看，可能会在广告展示后的1分钟、1小时甚至1天后发生。相应的挑战是，**是否要在为广告曝光分配label之前等待一个固定的时间窗口，随后在数据上进行训练，还是根据某些启发式规则来决定label**。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/7043544deeeefcd9877902d60656c2059d6d6914a635c9ae5c428d4ff1a2ca8882a20b8b5b9a8a02802300f578f9a64b?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2 连续特征值在3天内的分布情况。

早前方法的主要缺点是，在等待过程中模型可能会变得过时，以及维护数据缓存所需的额外基础设施成本。随后出现的实时方法中，训练涉及到错误地将示例标记为负例，导致负例数量比实际数据分布中更多。为了在模型训练的延迟和假负例（FN）率（即由于窗口太短而错误地将示例标记为负例）之间找到平衡，理想的窗口长度应该是多少，这一点也是未知的。

内部实证结果显示，即使模型更新延迟5分钟，也可能在性能方面造成极大的损害。在【naive的连续学习方法】中，训练样本的小批量立即被吸收并带有负标签，因此**模型始终是最新的，即使在时间上特征分布发生严重变化的情况下也是如此**。因为不需要存储尚未被点击的实例的额外快照，从技术上讲，这种方法允许我们无限期地等待，直到观察到正向标签。然后，它可以立即引入到模型中，如图3所示。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/3bfa599ca90d3b0b24986c50388988a4705c1af3dc0960ba7ad5302ea5a41f93a3b1e783e368326149b1d47ab208cca0?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3 连续学习框架

**这种方法的主要缺点是，所有样本最初都被标记为负例，尽管用户最终可能会消费（engage）它们**。或者，如果数据样本保持未标记状态（unlabeled），直到发生消费(engagement)，并且消费（engagement）概率被认为依赖于从曝光发生以来经过的时间，如[3]中所述，就需要定期收集和存储数据的快照，以捕捉消费延迟分布( engagement delay distribution)。尽管时间依赖性的假设是有效的，但鉴于需要多次存储数据点（每个快照一次）以批量模式训练模型，这将导致基础设施成本大幅增加，并且如果没有激进的下采样，训练数据会随着时间的推移而增长。最后但同样重要的是，**像[13]中提出的固定时间窗口将允许我们在训练之前获得大部分正向标签，但仍然会导致那些落在固定窗口之外进行消费的FN标签**。因此，处理假负例的问题仍然存在，并且模型还有变得过时的额外风险。

在这项工作中，我们设计了一个模型，用于预测特定用户在Twitter平台上点击视频广告的概率（pCTR）。通过这一努力，我们在两个不同的数据集上离线比较了两类不同的模型架构和五种不同的损失函数。随后，我们选择了表现最佳的架构和损失函数，并通过在线实验对它们进行评估。

- 第一种模型架构是一个简单的逻辑回归模型，由于其简单性、良好性能以及在线训练中容易摄取和处理新训练示例的特点，在展示广告行业中得到了广泛使用[3, 13]。
- 第二种模型采用了deep&wide的架构[5]，旨在应对推荐系统中使用的复杂和多样化的特征。

我们测试的五种损失函数，包括：

- 对数损失（log loss）
- 假负例加权损失（FN weighted loss）
- 假负例校准（FN calibration）
- 正未标记损失[7, 8]（positive unlabeled loss）
- 延迟反馈损失[3]（delayed feedback loss）

在这些中，对数损失通常用于CTR预测[14]。

在线实验中使用了连续学习，我们认为这在基础设施成本、生产化便利性方面提供了最佳权衡，并且具有显著优势，即模型始终在新鲜数据上进行训练。

虽然通过在线梯度下降的连续或在线训练在浅层（线性或基于核的）模型中得到了广泛应用[12]，但关于深度神经网络的连续学习的研究相对较少[21]。这尤其具有挑战性，因为目标函数是非凸的，并且已经提出了替代方法，如对冲策略[24]，来解决这个问题。据我们所知，这是第一次使用深度学习模型来估计展示广告中的pCTR，同时解决延迟反馈问题。鉴于在线训练对深度神经网络来说难以采用，这项工作旨在对延迟反馈问题进行基准测试，并提出可行的解决方案，而不增加额外的工程成本。我们考虑的三种损失函数，**正未标记（PU：positive unlabeled）、假负例加权（FN weighted）和假负例校准（FN calibration），是首次应用于这个问题，而后两种基于重要性采样**。我们的结果表明，线性模型和小数据集上的好性能并不一定能转化为深度模型的同等性能。例如，延迟反馈损失在使用公共数据集的线性模型上导致了最佳的相对交叉熵（RCE），但在Twitter数据上使用深度模型时，却被所有提出的损失函数超越（RCE增加了2.99%）。损失函数的有效性也随着可用数据量的变化而变化。我们希望这篇论文能作为在连续方式下训练深度学习模型进行广告点击预测任务时使用哪种损失函数的指南。

# 2 相关工作

为了确保模型始终在新鲜数据流上进行训练，一些示例被错误地标记为负例或保持未标记状态（unlabeled）。一旦用户对广告产生消费，相同的数据点将以正标签呈现给模型。在[13]中，**他们声称使用了一个足够长的时间窗口，以显著减少经验CTR与真实情况之间的偏差（由于一部分印象被错误地标记为负例）**。尽管大多数方法忽视了可用的时间延迟信息（即自曝光以来经过的时间以及用户与广告交互前的时间），但其中一些方法通过联合训练延迟模型以及CPC或CPA模型来利用时间延迟[3, 28]。在以下各节中，我们描述了五种不同的方法，这些方法构成了解决FN问题的潜在解决方案。我们进一步讨论了它们各自的挑战。

## 2.1 重要性采样（Importance Sampling）

模型相对于数据分布$ \mathbf{p} $的交叉熵由下式给出：

$$
L(\theta) = -\mathbb{E}_{\mathbf{p}}[\log f_{\theta}(y|x)] = -\sum_{x,y} \mathbf{p}(x, y) \log f_{\theta}(y|x) \quad (1) 
$$

其中：

- $ x $是与特定请求（与用户和广告相关）相关的特征，
- $ y $是表示参与度的二元标签，
- $ f_{\theta} $是试图估计$ \mathbf{p} $的模型。

如前所述，**在在线训练场景中，样本被引入为负例，直到观察到正标签**。这导致模型观察到一个有偏的分布$ \mathbf{b} $，而不是实际的数据分布。因此，我们不能从$ \mathbf{p} $中采样，只能访问来自不同分布$ \mathbf{b} $的样本。通过应用适当的加权方案，我们可以使用以下公式获得公式(1)中期望的无偏估计：

$$
\mathbb{E}_{\mathbf{p}}[\log f_{\theta}(y|x)] = \mathbb{E}_{\mathbf{b}}\left[ \frac{\mathbf{p}(x, y)}{\mathbf{b}(x, y)} \log f_{\theta}(y|x) \right] \quad (2)
$$

权重 $ w(x, y) = \frac{p(x,y)}{b(x,y)} $ 对应于重要性权重，旨在纠正在不同分布上进行平均的事实。使用来自不同、有偏的分布 $ b $ 的样本，可以通过以下方式估计等式(2)中的期望值：

$$
\frac{1}{N} \sum_{n} w(x_n, y_n) \log f_{\theta}(y_n | x_n)
$$


**使用一个分布中的样本来估计另一个分布的期望值这种方法称为重要性采样**。重要性采样已在不同情境中得到广泛使用，包括反事实分析，在[2]中作者讨论了涉及的假设以及如何将这种技术应用于计算广告中以估计任何量的反事实期望。在这种情况下使用重要性采样的最大挑战是我们需要估计权重 $ w(x, y) $。从这一点开始，我们使用 $ f_{\theta}(x) $ 来简洁地表示 $ f_{\theta}(y = 1 \mid x) $。

## 2.2 逆倾向性加权（Inverse Propensity Weighting）

逆倾向性加权在因果推断中得到了广泛应用，其中某些人口中的样本可能被低估。通过在估计器中的个别样本上使用适当的权重，可以调整实际人口与样本之间的差异[1]。当抽样概率已知时，就使用这个概率的倒数来加权观察结果。倾向性得分，记作 $ p(x) = P(T = 1 \mid X = x) $，是给定一组协变量时样本将被分配特定处理的概率。在假设处理不是随机分配的情况下，反事实相当于假设所有人口样本都以等概率被分配任何处理的等效估计。在点击率预测的背景下，可以采用类似的方法，其中处理相当于广告被赋予一个真实标签。在任何问题中应用这种技术时需要考虑的一个要求是，倾向性权重需要通过一个单独的参考模型来估计。


## 2.3 正-未标记学习

另一组方法并不明确识别带有负标签的数据，而只从正例（P）和未标记（U）样本中学习，这与传统的分类设置不同，在传统分类设置中，正例和负例都是可用的。当获取标记样本不可能或成本非常高时，就会出现这种设置，例如在文本分类[10]、分子生物学[9]中，但这种方法也被应用于异常值检测[25]和时间序列分类[23]。

在这种情况下，可用的训练数据由一组不完整但随机抽样的正例和一组未标记的样本组成，这些样本可能是正例或负例，导致需要一种不同的训练过程。关于训练数据的一个关键假设是，它们是从$p(x, y, s)$ 中随机抽取的，对于每个抽取的元组 <x,y,s>，只记录 <x, s>。这里 s 是观察到的标签，而 y 是实际标签，可能尚未发生。与此相伴的假设是，标记的正例是从所有正例中完全随机选择的，即 $ p(s = 1 \mid x, y = 1) = p(s = 1 \mid y = 1) $。在这种情况下，可以首先训练一个分类器 $ g(x) = p(s = 1 \mid x) $ 来估计一个样本被标记为正例（s = 1）的概率，假设它的原始标签是正的（y = 1）[9]，因为

$$
p(s = 1 | y = 1) = \frac{1}{n_P} \sum_{x \in P} g(x)
$$

其中：

- $ n_P $ 是正例 P 的基数。

接下来，每个未标记的样本可以被视为一个正例，其权重与 $ p(y = 1 \mid x, s = 0) $ 成比例，以及一个负例，其权重为补充权重 $ 1 - p(y = 1 \mid x, s = 0) $，而所有正例都有单位权重。这个权重可以表示为：

$$
p(y = 1 | x, s = 0) = \frac{1 - p(s = 1 | y = 1)}{p(s = 1 | y = 1) p(s = 1 | x)} \times \frac{p(s = 1 | x)}{1 - p(s = 1 | x)}
$$

最后，可以使用这些权重和标准训练过程在可用数据上训练分类器。
在之前的研究中，[19] 通过执行逻辑回归并优化线性函数的权重平方和以及加权逻辑损失的和，学习了给定输入观察到正标签的条件概率。在这种设置中，未标记样本具有单位权重，而正样本的权重由 $ n_U / n_P $ 的比值确定。PU问题也通过聚合分类器来解决，这些分类器被训练以区分 P 数据和 U 数据的随机子样本[22]。

在文献[8]和[7]中，du Plessis等人首次提出了一个无偏的非凸风险估计器，并分析了从数据中估计类先验时的超额风险。在标准二元分类设置中，分类风险由下式给出：

$$
R_{PN}^{\hat{}}(f_{\theta}) = p(y = 1)E_{p}(x|y=1)[l(f_{\theta}(x))] + p(y = 0)E_{p}(x|y=0)[l(1 - f_{\theta}(x))] 
$$

其中：

- $ l $ 是损失函数。

由于 $ p(x) = p(y = 1)p(x|y = 1) + p(y = 0)p(x|y = 0) $，最后一项可以表示为：

$$
p(y = 0)E_{p}(x|y=0)[l(1 - f_{\theta}(x))] = E_{p}(x)[l(1 - f_{\theta}(x))] - p(y = 1)E_{p}(x|y=1)[l(1 - f_{\theta}(x))]
$$

因此，分类风险可以用以下表达式近似：

$$
R_{PU}^{\hat{}}(f_{\theta}) = p(y = 1)E_{p}(x|y=1)[l(f_{\theta}(x))] - p(y = 1)E_{p}(x|y=1)[l(1 - f_{\theta}(x))] + E_{p}(x)[l(1 - f_{\theta}(x))] \quad (3)
$$

其中：

- $ p(x) $ 对应于所有未标记示例的边际分布。根据文献[18]，这个无偏风险估计器如果训练的模型过于灵活，可能会产生负的经验风险，这使得这个损失函数更难以用神经网络优化，并容易过拟合。

## 2.4 延迟反馈模型

文献[3]中提出的方法对CPA（每次行动成本）进行建模，并考虑了自广告点击以来经过的时间，并且不涉及匹配窗口。在这种情况下，延迟反馈问题的处理方式如下：只有当实际观察到正面标签时，训练样本才被标记为正面，否则被视为未标记，类似于PU（正未标记）方法。在模拟点击后归因的情况下，这意味着负标签不可能发生，因为转化可能在任何未来的时间内发生。大多数只从正面和未标记示例中学习的方法[9, 19]假设缺失标签的正面样本的概率是恒定的。然而，根据[3]的说法，最近的点击不太可能被赋予真实标签，因为经过的时间不够长，即正面样本的概率是与时间相关的。因此，他们使用第二个模型，该模型非常类似于生存时间分析模型[15]，以捕捉点击和转化之间的预期延迟。这与预测用户最终是否会转化的模型是分开的，但两个模型是联合训练的。在这种方法中，随机变量 $ Y \in \{0, 1\} $ 表示是否已经发生了转化，而另一个随机变量 $ C \in \{0, 1\} $ 表示用户最终是否会转化。一旦训练了两个模型，只保留预测转化概率的模型，即 $ P(c = 1|x) $，而转化延迟模型 $ P(d|x, c = 1) $ 则被丢弃。标准逻辑回归模型代表点击概率，而延迟则假设为指数（非负）分布，即：

$$
P(d|x, c = 1) = \lambda(x) \exp(-\lambda(x)d) \quad (4) 
$$


因此，$ y = 0 $ 可能发生在两种不同的情况下：要么是经过的时间 $ e $ 比转化时间 $ d $ 短，即 $ e < d $，要么是用户永远不会转化，即 $ c = 0 $。即使这个模型被应用于每次转化成本模型，它也适用于本文主要关注每次点击成本模型。图4说明了点击时间也遵循指数分布，这使得这个模型成为一个适当的解决方案。作为[3]中呈现模型的扩展，[28]建议了一个非参数延迟反馈模型（NoDeF），以在不假设任何参数分布（如指数或威布尔分布）的情况下捕捉时间延迟。该模型假设每个样本都有一个隐藏变量，这表明这个动作最终是否会导致转化。对于参数估计，使用了期望最大化（EM）算法[6]。然而，采用这些方法将需要用一个单独的模型来估计时间延迟，并显著增加基础设施成本和将这样一个系统投入生产的复杂性。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/c121feb5a77ecdd3f8978d3bd091d9293b8e6e05e2d1ac09ca92c3a3d7b3387d96a9589fe9d3d9392e8258682047043b?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=4.jpg&amp;size=750">

图4 训练广告的点击延迟时间分布（超过5分钟）。对应于在纠正了审查分布的累积分布函数（CDF）之后的分布

## 2.5 延迟强盗

延迟反馈在马尔可夫决策过程（MDPs）[16, 27]的背景下已得到广泛考虑，但当延迟不受限制时，其应用变得更加具有挑战性。在[26]中，作者提出了离散时间随机多臂老虎机模型来解决可能存在审查反馈的长延迟问题，即不可观察的反馈。他们涵盖了这两种模型的两个不同版本：未审查模型，允许在任意长的延迟后观察转化；以及审查模型，它在行动后施加了 $ m $ 个时间步长的限制，在此之后，转化不再可观察。在每一轮中，代理收到的奖励对应于在时间 $ t $ 观察到的转化数量。然而，与之前的方法不同，这些模型假设已知延迟分布。他们认为这是一个有效的假设，因为分布可以从历史数据中估计，并且还声称可以在线方式在不增加成本的情况下估计延迟分布，前提是它被所有行动共享。

# 3 提出的方法

在这项工作中，我们采用了一种连续训练方案，这表明我们可以潜在地无限期地等待，从广告展示到最终观察到积极的参与。从历史上看，这是通过摄取所有带有负标签的样本来处理的，直到用户记录了积极的参与。因此，有偏的数据分布，即观察到的分布，包含了所有从实际数据分布中标记为负的样本。相应地，在有偏分布中的正面样本对应于原始数据分布中的所有正面样本。

## 3.1 模型架构

本节描述了正在考虑的模型的架构细节。

### 3.1.1 逻辑回归

我们使用了一个标准逻辑回归模型，该模型在展示广告领域得到了非常广泛的应用[3, 13]：

$$
f_{\theta}(x) = \frac{1}{1 + \exp(-w_c \cdot x)} = \sigma(w_c \cdot x)
$$

其中：

- $ \sigma(\cdot) $ 对应于sigmoid函数，而输入 x 是与特定请求相关的用户和广告候选的成千上万个特征的稀疏表示。

### 3.1.2 宽与深模型。

这个深度模型由一个宽组件组成，对应于一个广义线性模型，以及一个深组件，对应于一个标准前馈神经网络。宽组件处理原始输入特征和转换后的特征，例如交叉乘积特征，为广义线性模型添加非线性。深组件将高维稀疏特征转换为嵌入向量，将分类特征转换为密集的、低维的表示形式。
与前一个模型类似，特征包括用户特征、上下文特征和广告特征。模型对CTR的预测由下式给出：

$$
f_{\theta}(x) = \sigma(w_{wide} \cdot [x, \phi(x)] + w_{deep} \cdot \text{deep}_\alpha(\text{lff}) + b)
$$

其中：

-  $ w_{wide} $ 对应于宽组件的权重，
- $ w_{deep} $ 对应于深组件的权重，
- $ \phi(x) $ 是交叉乘积变换，
- $ \alpha(\text{lff}) $ 是深分支的最终层激活

## 3.2 损失函数

### 3.2.1 延迟反馈损失。

在这个版本的损失函数中，假设时间延迟遵循指数分布，并且这个模型与逻辑回归模型或深度模型联合训练。假设:

- $ \lambda(x) = \exp(w_d \cdot x) $ 和 $ w_c $ 是pCTR模型的参数

我们针对参数 $ \theta $ 和 $ w_d $ 优化正则化对数似然：

$$
\text{arg min}_{\theta, w_d} L_{DF}(\theta, w_d) + \alpha (\| \theta \|^2_2 + \| w_d \|^2_2)
$$

其中：

- $ \alpha $ 是正则化参数，
- $ L_{DF} $ 是损失函数，
- $ \| \cdot \|_2 $ 表示L2范数。

其中：

- $ \alpha $ 是正则化参数，
- $ L_{DF} $ 是延迟反馈损失函数，定义如下：

$$
L_{DF}(\theta, w_d) = -\sum_{x,y=1} \log f_{\theta}(x) + \log \lambda(x) - \lambda(x)d - \sum_{x,y=0} \log[1 - f_{\theta}(x) + f_{\theta}(x) \exp(-\lambda(x)e)] \quad (5)
$$

- $ f_{\theta}(x) $ 对应于pCTR模型的输出，
- $ d $ 对应于正样本的点击时间，而 $ e $ 表示自广告展示以来经过的时间。

这个损失函数可以以更数值稳定的方式计算如下：

$$
L_{DF}(\theta, w_d) = -\sum_{x,y} \log f_{\theta}(x) - \sum_{x,y=1} w_d \cdot x - \lambda(x)d - \sum_{x,y=0} \log[\exp(-\theta \cdot x) + \exp(-\lambda(x)e)]
$$

### 3.2.2 正未标记loss

在这一部分中，我们考虑在假负例（FN）设定下使用PU损失，通过将有偏训练数据中的所有负样本视为未标记。根据等式(3)，可以推导出以下损失函数：

$$
L_{PU}(\theta) = -\sum_{x,y=1} [\log f_{\theta}(x) - \log(1 - f_{\theta}(x))] - \sum_{x,y=0} \log(1 - f_{\theta}(x)) \quad (6)
$$

从经验上看，这可以被视为对正样本和负样本都应用传统的对数损失。此外，每当观察到正例时，都会朝着负梯度的相反方向迈出一步。鉴于每个正样本都基于假负样本的梯度进行了参数更新，这个假设是合理的。

### 3.2.3 假负例加权

这种损失函数依赖于重要性采样。在我们的训练设置中，样本被标记为负例并被引入到训练流程中，然后在用户发生参与时立即用正面标签复制。为了制定这个损失函数，我们依赖以下假设：

$$
b(x|y = 0) = p(x) \\
b(x|y = 1) = p(x|y = 1)
$$

其中：

- $ b $：是有偏的观察到的分布
-  $ p $： 是实际的数据分布。

我们也知道：

$$
b(y = 0) = \frac{1}{1+p(y=1)} 
$$

因为所有样本最初都被标记为负例。

(1)中的损失函数可以写成：

$$
-\sum_{x,y} p(y = 1|x) \log f_{\theta}(x) + p(y = 0|x) \log f_{\theta}(y = 0|x) \\

 = -\sum_{x,y} \frac{b(y = 1|x)}{p(y = 1|x)} \log f_{\theta}(x) + \frac{b(y = 0|x)}{p(y = 0|x)} \log f_{\theta}(y = 0|x) \quad (7)
$$

在有偏分布中观察到正面用户参与的概率是：

$$
b(y = 1|x) = \frac{b(y = 1)b(x|y = 1)}{b(y = 1)b(x|y = 1) + b(y = 0)b(x|y = 0)}
$$

利用上述假设，并分配 $ w(x) = \frac{B}{1+p(y=1|x)} $，可以表示为：

$$
b(y = 1|x) = \frac{w(x)p(y = 1)p(x|y = 1)}{w(x)p(y = 1)p(x|y = 1) + w(x)p(x)} \\
= \frac{p(y = 1|x)p(x)}{p(y = 1|x)p(x) + p(x)} \\
= \frac{p(y = 1|x)}{1 + p(y = 1|x)} \quad (8)
$$

类似地，用户不会参与的概率是：

$$
b(y = 0|x) = 1 - b(y = 1|x) = \frac{1}{1 + p(y = 1|x)} \quad (9)
$$

通过将(8)和(9)替换到等式7中，我们得到以下表达式：

$$
L_{IS}(\theta) = -\sum_{x,y} b(y = 1|x) (1 + p(y = 1|x)) \log f_{\theta}(x) + b(y = 0|x)p(y = 0|x) (1 + p(y = 1|x)) \log f_{\theta}(y = 0|x) \quad (10)
$$

因此，我们可以用 $ (1 + p(y = 1|x)) $ 来衡量正样本，并用 $ (1 - p(y = 1|x)) \cdot (1 + p(y = 1|x)) $ 来衡量负样本。由于我们不能直接获取 $ p $，我们可以用模型估计 $ f_{\theta} $ 来替代它，只要 $ f_{\theta} $ 收敛于 $ p $，这在以下段落中将得到证明。

依赖于(8)和(9)，并通过在重要性权重中用 $ f_{\theta} $ 替代 $ p $，(10)可以重写为：

$$
L_{IS}(\theta) = -\sum_{x,y} \frac{p(y = 1|x)}{(1 + p(y = 1|x))(1 + f_{\theta}(x))} \log f_{\theta}(x) + \frac{1 - f_{\theta}(x)}{(1 + p(y = 1|x))(1 + f_{\theta}(x))} \log(1 - f_{\theta}(x))
$$

括号内的项在计算损失相对于输入的梯度时不予考虑。最后，$ L_{IS}(\theta) $ 相对于 $ f_{\theta} $ 的梯度可以写成：

$$
\frac{\partial L_{IS}}{\partial f_{\theta}} = -\frac{p(y = 1|x)}{(1 + p(y = 1|x))(1 + f_{\theta}(x))} \frac{f_{\theta}(x)}{(1 + f_{\theta}(x))} + \frac{1 + f_{\theta}(x)}{(1 + p(y = 1|x))} \frac{1 - f_{\theta}(x)}{(1 + f_{\theta}(x}) \\
= \frac{(1 + f_{\theta}(x))(f_{\theta}(x) - p(y = 1|x))}{(1 + p(y = 1|x))f_{\theta}(x)} \quad (11) 
$$

注意，

- 当 $ \frac{\partial L_{IS}}{\partial f_{\theta}} = 0 $ 时，那么 $ f_{\theta}(x) = p(y = 1|x) $，即只要 $ f_{\theta}(x) > 0 $，$ f_{\theta}(x) $ 就收敛于 $ p(y = 1|x) $。
- 当 $ f_{\theta}(x) > p(y = 1|x) $ 时，$ \frac{\partial L_{IS}}{\partial f_{\theta}} > 0 $，
- 当 $ f_{\theta}(x) < p(y = 1|x) $ 时，$ \frac{\partial L_{IS}}{\partial f_{\theta}} < 0 $，对于 $ p(y = 1|x) \in (0, 1] $。这表明FN加权损失导致 $ f_{\theta}(x) = p(y = 1|x) $，梯度始终指向正确的方向。

### 3.2.4 假负例校准。

在这种方法中，模型估计有偏的分布 $ b $，然后，在解等式8求 $ p(y = 1|x) $ 后使用以下变换：

$$
p(y = 1|x) = \frac{b(y = 1|x)}{1 - b(y = 1|x)}
$$

这总是一个有效的分布，因为在有偏的分布中对于每个正例都观察到一个FN，即 $ b(y = 1|x) \leq 0.5 $ 且 $ p(y = 1|x) \leq 1 $。为了简洁起见，我们称这种方法为FN校准。


















附录：

- 1.[https://arxiv.org/pdf/2012.03245](https://arxiv.org/pdf/2012.03245)