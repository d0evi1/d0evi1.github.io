---
layout: post
title: AdaptDHM介绍
description: 
modified: 2023-1-4
tags: 
---

菜鸟网络在《AdaptDHM: Adaptive Distribution Hierarchical Model for Multi-Domain CTR Prediction》提出了AdaptDHM：

# 摘要

大型商业平台通常涉及众多业务领域以实现多样化的商业策略，并期望其推荐系统能够同时为多个领域提供点击率（CTR）预测。现有的有前景且被广泛使用的多领域模型通过**显式构建特定领域的网络**来发现领域之间的关系，但随着领域数量的增加，计算和内存开销显著增大。为了降低计算复杂度，在工业应用中通常手动将具有特定业务策略的领域进行分组。然而，这种预先定义的数据划分方式严重依赖于先验知识，并且可能会**忽略每个领域的底层数据分布**，从而限制模型的表示能力。针对上述问题，我们提出了一种优雅且灵活的多分布建模范式，名为**自适应分布分层模型（AdaptDHM）**，它是一种**由聚类过程和分类过程组成的端到端优化分层结构**。具体而言，我们设计了一个带有**定制化动态路由机制的分布适配模块**。该路由算法并非通过引入先验知识来进行预定义的数据分配，而是自适应地为每个样本提供一个分布系数，以确定其所属的簇。**每个簇对应一种特定的分布**，从而使模型能够充分捕捉这些不同簇之间的共性和差异。在公开数据集和大规模阿里巴巴工业数据集上的大量实验验证了AdaptDHM的有效性和高效性：我们的模型实现了令人瞩目的预测准确性，并且在训练阶段的时间成本比其他模型低50%以上。

# 1 引言

点击率（CTR）预测在在线推荐系统中至关重要，因为其性能影响用户体验，并且与平台的收入密切相关。尽管在CTR预测任务中已经取得了巨大的进展[4, 5, 24]，但大多数方法都集中在单领域预测上，并假设数据来自同质领域。这里，业务领域被定义为应用程序或网站上向用户展示商品的具体位置[18]。在现实情况下，大型商业公司（如阿里巴巴、亚马逊）通常涉及多个业务领域。以阿里巴巴的淘宝应用为例，作为全球领先的在线购物应用之一，排名模型已广泛应用于数百个领域，如首页、购物车页面等。

最近，一些最先进的工作在多领域推荐任务中取得了令人瞩目的成功[2, 12, 18]。受到多任务学习（MTL）[15, 19]的启发，它们通过显式构建特定领域的网络来发现领域之间的关系。值得注意的是，随着业务领域的快速增长，这种建模方法由于显著的计算和内存成本而变得不切实际。在工业应用中，**通常手动将具有特定业务策略的领域进行分组以降低计算复杂度**。然而，这种预先定义的数据划分方式严重依赖于先验知识，并且可能会忽略每个领域的底层数据分布，从而限制模型的表示能力。此外，这种方式对于自定义模式建模也不够灵活。具体来说，**不同视角下的分布是不同的**：数据分布在不同用户群体（如男性用户与女性用户、活跃用户与冷门用户）、推荐商品的不同类别（如电子产品与化妆品）等之间存在差异。

针对上述问题，本任务的关键在于开发一种有效的多分布学习策略，以促进模型学习。一种直观的方法是将聚类过程引入深度CTR模型，使其能够**将相似的样本分组到同一个表示空间**中。然后，模型可以全面学习这些空间之间的区别和共性。为此，我们提出了一种优雅且灵活的多分布建模范式，名为自适应分布分层模型（AdaptDHM），它是一种由聚类过程和分类过程组成的端到端优化分层（多级）结构。我们设计了一个带有定制化动态路由机制的分布适配模块，以**自适应地将多源样本分配到不同的簇中**。每个簇对应一种特定的分布。最后，当每个簇中可以保证分布一致性时，模型可以进一步有效地学习这些簇之间的共性和差异。

总结来说，本工作的主要贡献如下：

- 据我们所知，这是首次在多领域CTR预测中提出自适应分布建模范式，而不是通过引入先验知识进行手动预定义的领域感知表示分配。此外，这种建模框架具有很强的灵活性，可以应对多样化的分布建模需求。
- 我们设计了一种新颖的分布适配模块，带有定制化动态路由机制。该路由算法为每个实例提供一个分布系数，以确定其所属的分布。
- 我们在公共数据集和阿里巴巴工业数据集上进行了广泛的实验，结果表明，我们提出的模型在消耗更少内存空间和训练时间的情况下，优于以往的工作。

# 2 相关工作

## 多领域学习
一些开创性的工作[2, 12, 20]将多领域学习表述为多任务学习（MTL）[13, 19]的一种特殊形式，在这种形式中，底层共享通用知识，而特定任务的知识则在独立的分支网络中学习。STAR [18] 提出了一种星型拓扑结构，由共享的中心参数和特定领域的参数组成，用于显式地挖掘领域之间的关系。

## 动态路由
我们的方法受到一种称为**动态路由机制的类聚类方法**的启发，该方法首次由Hinton [16] 在他的胶囊网络中提出，用于迭代学习部分-整体关系。后来，Hinton等人通过期望最大化（EM）算法[17]改进了**动态路由过程**。最近，动态路由机制已被应用于许多领域[9, 10, 22]。MIND [11] 在推荐系统中利用动态路由对用户的历史行为进行聚类，获得了多样化的兴趣表示。

# 3 提出的方法

## 3.1 问题形式化

我们将多领域CTR预测形式化为这样一个问题：

给定一组具有共同特征空间 $X$ 和标签空间 $Y$ 的业务领域 $\lbrace D_m\rbrace _{m=1}^M$。目标是：构建一个统一的CTR预测函数 $f: X \to Y$，该函数能够同时为 $M$ 个领域（$D_1, D_2, ..., D_M$）准确提供CTR预测结果。

与以往的工作不同，在本文中，我们通过定义一个投影函数 $G: X \to \theta$，将 $M$ 个给定领域匹配到几个具有不同分布的潜在固有领域 $\lbrace D_k\rbrace _{k=1}^K$。然后，给定输入数据 $X$ 和潜在领域 $\theta$，我们尝试找到函数 $f: X, \theta \to Y$，以提供CTR预测。

## 3.2 架构概述
我们提出了一种名为自适应分布分层模型（AdaptDHM）的新颖多分布建模范式。如图1所示，它是一种由聚类过程和分类过程组成的端到端优化分层（多级）结构。具体来说，一批具有各种特征（例如，用户画像、用户的历史行为等）的多源实例通过动态路由过程进行处理。动态路由过程的算法如算法1所示。给定当前批次步骤 $b$（$b \in \lbrace 1, ..., B\rbrace $），一批嵌入向量 $e_i^b$（$i \in \lbrace 1, ..., n\rbrace $），簇的数量 $K$，簇中心向量 $c_j^b$（$j \in \lbrace 1, ..., K\rbrace $），迭代次数 $I$，它返回分布系数 $r_{ij}$，该系数决定了输入向量 $e_i^b$ 属于特定簇 $j$ 的概率。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/7edfc1f974d0c1ed5d0999c2f31e894ce03c688882e5c4778e3eacc9829642800fa029e013fa651c03f47b6889cbb796?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1

在训练开始时，我们以服从高斯分布 $N(0, \sigma^2)$ 的单位向量形式初始化簇中心向量 $c_j^0$。在当前批次的每次迭代中，我们首先基于余弦相似度度量计算每个嵌入向量 $e_i^b$ 和簇中心向量 $c_j^b$ 的相似度得分 $s_{ij}$

$$
s_{ij} = \frac{|c_j^b||e_i^b|\cos\theta}{|c_j^b||e_i^b|} = c_j^b \cdot e_i^b,
$$

其中 $\theta$ 是两个向量之间的角度。接下来，通过对相似度得分进行softmax操作获得分布系数

$$
r_{ij} = \text{softmax}(s_{ij}) = \frac{\exp(s_{ij})}{\sum_{j=1}^K \exp(s_{ij})},
$$

其中分布系数的和等于1。然后，通过分布系数的加权和更新簇中心向量 $c_j^b$，并通过L2归一化将其转换为单位向量，表示为

$$
c_j^b = \text{norm2}\left(\sum_{i=1}^n r_{ij} e_i^b\right),
$$

$$
\text{norm2}(c_j^b) = \frac{c_j^b}{\|c_j^b\|}, \quad \|c_j^b\|^2 = \left(\sum_{j=1}^K |c_j^b|^2\right)^{\frac{1}{2}}.
$$

在每次批次训练中，所有簇中心向量都继承前一批次的值。为了使 $c_j^b$ 的值在训练阶段稳定更新，我们在算法中应用了指数加权移动平均（EWMA）方法

$$
c_j^b = \text{norm2}\left(\beta * c_j^{b-1} + (1 - \beta) * c_j^b\right),
$$

其中 $\beta$ 表示更新率，设置为0.9 [6]。值越大，更新越平滑。通过这种方式，簇中心向量 $c_j^b$ 可以平稳更新，同时考虑当前批次的值和前一批次的信息。

训练完成后，簇中心向量被继承并在推理阶段使用，以便模块可以指导样本流向分布最相似的簇。

## 3.4 多分布网络

有许多可能的方法[13, 18, 19]可以用来利用簇关系。本文采用了一种常见的多分支结构，由一个共享的多层感知机（MLP）层和 $K$ 个特定于簇的MLP层组成。具体来说，共享MLP层中的参数由所有样本更新，但特定于簇的MLP层的参数仅由其对应的样本更新。我们将共享MLP层的权重和特定于簇的MLP层的权重分别表示为 $W_s$ 和 $W_j$。第 $j$ 个簇的最终权重 $W_m$ 为：

$$
W_m = W_s \otimes W_j,
$$

其中 $\otimes$ 表示逐元素乘积。实例 $i$ 的预测结果通过sigmoid函数生成：

$$
\hat{y}_i = \text{sigmoid}((W_m)^T x_i).
$$

我们模型中应用的目标函数是交叉熵损失函数，定义为：

$$
L = -
\frac{1}{N}
\sum_{i=1}^N \left(
y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)
\right),
$$

其中 $y_i$ 是实例 $x_i$ 的真实标签。

# 4.实验

## 4.1 实验设置

### 4.1.1 数据集
我们在公共和工业数据集上进行了广泛的实验。这两个数据集均收集自推荐系统的真实流量日志。

**公共数据集**：Ali-CCP [14] 是一个公共数据集，其训练集和测试集的大小分别为超过4230万和4300万。由于样本来源较少，仅有三个源领域，我们附加了更多特征（领域指示器、用户性别、用户城市）来划分样本，最终得到33个领域。

**工业数据集**：我们从阿里巴巴在线广告系统中收集了60亿个样本，涵盖10个业务领域。这些业务领域是基于先前的业务知识手动预定义的，每个领域包含数十个子领域。我们按照时间顺序将样本按60%和40%的比例划分为训练集和测试集。

### 4.1.2 对比模型
我们使用DNN [3] 作为所有模型的骨干网络。

• **Shared Bottom**：我们调整了Shared Bottom模型 [1] 以适应多领域学习，其中任务塔的数量设置为领域数量（$M$），并共享嵌入层。
• **PLE**：PLE [19] 融合了从共享专家和特定领域专家学到的表示。
• **STAR**：STAR [18] 使用由中心网络和 $M$ 个特定领域网络组成的星型拓扑结构。对于每个领域，通过将共享网络的权重与特定领域网络的权重逐元素相乘，得到一个统一的模型。

### 4.1.3 实现细节
为了公平比较，所有模型中的每个MLP隐藏层的深度均为5层（512-256-128-64-32）。激活函数设置为ReLU。对于动态路由过程，我们将迭代次数设置为3 [16]，更新率 $\beta$ 设置为0.9。基于模型性能，簇的数量设置为3（生产环境）和9（公共数据集）。对于优化器，我们使用Adam [8]，批量大小为2048（生产环境）和16384（公共数据集）。学习率设置为 $1 \times 10^{-3}$。所有实验均在基于分布式TensorFlow的框架 [21] 上实现。

### 4.1.4 评估指标
在公共数据集中，我们使用AUC作为评估指标。对于工业数据集，我们采用了一种AUC的变体，称为Group AUC (GAUC) [18, 23]，因为它更适合比较推荐系统中的在线性能。GAUC计算了相应展示下不同会话的AUC的平均值。计算公式如下：

$$
\text{GAUC} = \frac{\sum_{i=1}^n (\# \text{impressions}_i \times \text{AUC}_i)}{\sum_{i=1}^n \# \text{impressions}_i},
$$

其中 $n$ 是会话数量，$\# \text{impressions}_i$ 和 $\text{AUC}_i$ 分别是第 $i$ 个会话的展示次数和AUC。

## 4.2 有效性验证
从表1和表2的结果中，我们得出几个重要观察：

1. AdaptDHM在公共和工业数据集上的性能均提升了超过1‰。注意，CTR任务中0.1%的AUC提升被认为是一个很大的进步。
2. DNN在公共数据集上表现优于其他多领域模型，但在工业数据集上表现较差。这两个数据集的主要区别在于，工业数据集中的数据是基于先前的可靠业务知识手动划分的，而公共数据集则是通过一些随机挑选的领域感知特征进行划分的。这表明显式建模方式严重依赖于有效的数据划分以进行特定领域的学习。
3. AdaptDHM在10个业务领域上展示了令人印象深刻的泛化能力，在大多数领域中表现优于其他模型。

## 4.3 超参数影响
我们分析了簇数量 $K$ 对AdaptDHM预测性能的影响。如图2所示，当 $K$ 等于9时，AdaptDHM在公共数据集上获得了最佳的AUC。随着 $K$ 的增长，性能变差。这表明过小或过大的 $K$ 都无法产生最佳性能。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/779e83cdcfd06ca563d6b61419f7934f01b70603bea4420ab53b462e72df4e015d13614eb441eb58df2a2cc209e01d16?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

## 4.4 效率分析

### 内存和计算复杂度
由于框架优雅，我们的模型在参数上非常高效。我们将特定领域的MLP参数表示为 $P_{\text{mlp}}$（约数百万参数）。领域数量、共享MLP层（或称为PLE中的共享专家）的数量和簇的数量分别用 $M$、$S$ 和 $K$ 表示。每个模型的内存和计算成本如表3所示。

### 训练效率
图3显示，AdaptDHM在时间成本上明显优于其他模型，在训练阶段的时间比其他模型少50%，这有助于更频繁的模型优化和在线交付。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/b8e66899eb32ed69e30e03d80a8e205df678c41f10e42da6db57252179eb6adfdd5f2215a0c1b4e6777ac13f01b8d28f?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

# 

[https://arxiv.org/pdf/2211.12105](https://arxiv.org/pdf/2211.12105)