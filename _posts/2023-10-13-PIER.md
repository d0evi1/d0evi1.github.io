---
layout: post
title: PIER重排建模介绍
description: 
modified: 2023-10-13
tags: 
---

美团在《PIER: Permutation-Level Interest-Based End-to-End Re-ranking
Framework in E-commerce》 提出了PIER的方式建模：

# 摘要

Reranking在学术界和工业界引起了越来越多的关注，它通过建模物品之间的相互影响重新排列ranking list，以更好地满足用户需求。许多现有的re-ranking方法直接将初始ranking list作为输入，并通过精心设计的contextwise模型生成最优排列，这带来了(evaluation-before-reranking)问题。同时，在实际中评估所有候选排列会带来不可接受的计算成本。因此，为了更好地平衡效率和效果，在线系统通常采用两阶段体系结构：**首先使用一些启发式方法，如beamsearch，生成适量的候选排列**，然后将其送到评估模型中以获得最优排列。然而，现有的两段式方法可以通过以下两方面进行改进：

- 对于生成阶段，启发式方法仅使用点预测分数，缺乏有效的判断。
- 对于评估阶段，大多数现有的上下文评估模型仅考虑物品上下文，缺乏更精细的特征上下文建模。

本文提出了一种新颖的端到端reranking框架PIER，以解决上述挑战，仍然遵循两阶段体系结构，并包含两个主要模块FPSM和OCPM。

- 受长期用户行为建模方法的启发，我们**在FPSM中应用SimHash以高效地从全排列中选择前K个候选items**，这些候选items基于用户在排列级别上的兴趣。
- 然后，在OCPM中设计了一种**新颖的全向注意力（omnidirectional attention）机制**，以更好地捕捉排列中的上下文信息。
- 最后，我们通过引入一个**可比的learning loss**来端到端地共同训练这两个模块，该loss使用OCPM的预测值来指导FPSM生成更好的排列。离线实验结果表明，PIER在公共和工业数据集上均优于基线模型，并且我们已成功将PIER部署在美团外卖平台上。

# 1.介绍

略

# 4.方法

我们在图2中呈现了PIER（基于排列级别兴趣的端到端reranking：Permutation-level
Interest-based End-to-End Re-ranking）的概述结构。


<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/610b40636ed111d8ca41cb3c9f7ed5228d0e11f479616c1d7455756674afda32f903ea26b27145c7f5aa8d5260191274?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2

- 首先，我们将ranking list $C = \lbrace a_i \rbrace_{𝑖=1}^{N_o}$和用户的permutation-level点击行为序列$B = \lbrace b_i \rbrace_{i=1}^{N_o}$作为PIER的输入。
- 然后，我们通过完全排列算法（full permutation algorithm：图中为方便将每个排列的items数设为3）在C上生成候选排列（candidate permutations）：$G = \lbrace p_i \rbrace_{𝑖=1}^T$。
- 接下来，我们使用细粒度排列选择模块（FPSM：Fine-grained Permutation Selection Module）从大量候选排列中选择前K个排列。
- 最后，我们使用全向上下文感知预测模块（OCPM：Omnidirectional Context-aware Prediction Module）计算每个排列的分数，并选择最佳排列$𝑝^∗$作为re-ranking list来进行显示。

在FPSM中，我们提出了基于SimHash [5, 8, 19]计算的**时间感知汉明距离（ time-aware hamming distance）**。通过对用户的permutation-level点击行为和候选排列之间的距离进行排序，选择topK个排列。在OCPM中，我们设计了一种新的**全向注意力单元（omnidirectional attention unit）**，用于建模每个排列中的上下文信息，并输出关于在该排列中每个item的list-wise pCTR。基于输出得分，即list-wise pCTRs之和，选择最佳排列。FPSM和OCPM之间的关系类似于推荐系统中的matching和ranking阶段。我们将两者合并成一个框架，生成最优重新排名列表。接下来，我们将分别详细介绍FPSM和OCPM。

## 4.1 FPSM: 细粒度排列选择模块

出于时耗考虑，一些re-ranking方法利用启发式方法，如beam-search[11] (PRS)生成候选排列，并使用精心设计的预测模型选择最优排列，但这些启发式方法与建模目标不一致，导致次优效果。受ETA和SDIM [4]等长期用户行为建模方法的启发，我们提出了FPSM通过SimHash选择topK个候选项。这里，**我们以用户的历史点击行为为目标，然后计算它与所有候选排列之间的距离**。如果距离更近，我们认为排列可以更好地匹配用户的兴趣，从而可以带来更大的收益。通过这种方式，我们不仅可以减少时间复杂度，还可以通过端到端训练FPSM和预测模型来做出一致的选择。接下来，我们将介绍如何通过FPSM选择topK个排列。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/4721ac894897d8c6e14b7d1369913e8d6497411744dac33abe05115132ca7c235e91eb3b4bebea920211cb698f7d42dc?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3 FPSM和OCPM的结构。FPSM会采用用户的permutation-level点击行为和一个candidate permutation作为input，并输出该permutation的distance score。OCPM会采用用户的permutation-level 点击行为和一个由FPSM选中的top-k permutation作为input，并输出在permutation中的每个item的predicted list-wise pCTR。通过颜色区分

如图3左侧所示，我们首先使用底部共享的嵌入层从原始输入中提取嵌入。对于排列$𝑝_𝑘$，我们将嵌入矩阵$M_{𝑝_𝑘}$表示为：

$$
M_k^p = \left[
\begin{array}{c}
  E_{0;}^{p_k} \\
  E_{1;}^{p_k} \\
  \cdots \\
  E_{N_d;}^{p_k}
\end{array}
\right]
= 
\left[
\begin{array}{cccc}
E_{;0}^{p_k} E_{;1}^{p_k} \cdots E_{;N_f}^{p_k} 
\end{array}
\right]
= 
\left[
\begin{array}{cccc}
e_{0;0}^{p_k} e_{0;1}^{p_k} \cdots e_{0;N_f}^{p_k} \\
e_{1;0}^{p_k} e_{1;1}^{p_k} \cdots e_{1;N_f}^{p_k} \\
\cdots \cdots \cdots \cdots \\
e_{N_d;0}^{p_k} e_{N_d;1}^{p_k} \cdots e_{N_d;N_f}^{p_k} 
\end{array}
\right] \in R^{N_d \times N_f \times D}
$$

...(1)

其中:

- $𝑁_𝑑$是每个排列中的项目数
- $𝑁_𝑓$是每个项目中的特征字段数（例如ID、类别、品牌等）
- 𝐷是嵌入变换特征字段的维度
- $e_{𝑖;j}^{p_k} \in R_𝐷$是排列$𝑝_𝑘$中第𝑖个item的的第𝑗个feature字段的embedding
- $E_{𝑖;}^{𝑝_𝑘} \in R^{𝑁_𝑓 × 𝐷}$是排列$𝑝_𝑘$中第𝑖个项目的embedding矩阵
- $E_{;𝑗}^{𝑝_𝑘} \in R^{𝑁_𝑑 × 𝐷}$是排列$𝑝_𝑘$中第𝑗个特征字段的embedding矩阵。
- $M_𝑚^b \in R^{𝑁_𝑑 \times 𝑁_𝑓 \times D}$：表示用户排列级别历史点击行为中第𝑚个排列的嵌入矩阵

接下来，我们为每个排列生成位置编码矩阵$PE \in R^{𝑁_𝑑 \times 𝐷}$，如下所示：

$$
PE_{(𝑖,2𝑑)} = sin(𝑖/10000^{2𝑑/𝐷}), \\
PE_{(𝑖,2𝑑+1)} = cos(𝑖/10000^{2𝑑/𝐷}), \\
PE = \left[
\begin{array}
PE_{(0,0)} PE_{(0,1)} \cdots PE_{(0,D)} \\
PE_{(1,0)} PE_{(1,1)} \cdots PE_{(1,D)} \\
\cdots \cdots \cdots \cdots \\
PE_{(N_d,0)} PE_{(N_d,1)} \cdots PE_{(N_d,D)} 
\end{array}
\right]
$$

...(2)

然后，各个特征字段的嵌入矩阵分别与位置编码矩阵PE相乘，然后通过average pooling合并为相应的排列representation $h_𝑘^p$，如下所示：

$$
h_k^p = \frac{1}{N_f} \sum\limits_{i=1}^{N_f} Avg-Pool(E_{;i}^{p_k} \odot PE), \forall k \in [N_o]
$$

...(3)

类似地，用户排列级别历史点击行为中第𝑚个排列的representation为$h_𝑚^b$。

在我们的场景中，用户更有可能点击与其兴趣更接近的排列。我们使用用户的排列级别历史点击行为来表示用户的兴趣，并计算用户兴趣与每个候选排列之间的距离。具体而言，我们利用随机投影模式（SimHash）[5, 8, 19]来计算用户点击排列的representations和候选排列的表示之间的相似度。我们首先生成𝑀个不同的哈希函数，对应于𝑀个用户的permutation-level行为。对于每个候选排列$𝑝_𝑘$，我们使用𝑀个不同的哈希函数来对它们的表示$h_𝑘^p$进行hash，并计算它与每个用户的排列级别行为之间的汉明距离，如下所示：

$$
Sim(p_k, b_m) = Hash_m(b_k^p, h_m^b), \forall m \in [M], \forall k \in [N_o]
$$

...(4)

同时，越近期的行为越能反映用户当前的兴趣，因此在相似度计算中会给予更高的权重。因此，我们根据每个行为的发生时间对这些距离进行加权，以获得时间感知的汉明距离，如下所示：


$$
d_k = \sum\limits_{m=1}^M w_m \cdot Sim(p_k, b_m), \forall k \in [N_o]
$$

...(5)

其中：

- $w_m$是第m个行为的time-aware weight。

最后，我们根据它们的距离得分对候选排列进行排序，并选择距离得分最小的前K个排列$P^{𝑡𝑜𝑝−𝐾} = {𝑝_𝑖^{𝑡𝑜𝑝}}_{𝑖=1}^𝐾$作为FPSM的输出。

由于FPSM与OCPM共享底部embedding layers，并固定住哈希函数（hash functions）和位置编码（position encoding）的随机向量，因此它没有需要训练的独立参数。为了确保训练期间选择的前K个排列的质量，我们提出了对比损失（contrastive loss）来提高FPSM的性能。对比损失（contrastive loss）的详细内容将在第4.3.2节中讨论。

## OCPM（全向上下文感知预测模块）

略

# 

- 1.[https://arxiv.org/pdf/2302.03487.pdf](https://arxiv.org/pdf/2302.03487.pdf)
- 2.[https://github.com/Lemonace/PIER_code](https://github.com/Lemonace/PIER_code)