---
layout: post
title: SATrans介绍
description: 
modified: 2024-12-2
tags: 
---

tx在《https://dl.acm.org/doi/pdf/10.1145/3580305.3599936》提出了一种在序列建模中考虑场景信息的方法：SATrans。

# 一、摘要

传统的点击率（CTR）预测模型通常在单一场景下进行训练和部署。然而，大规模的商业平台通常包含多个推荐场景，其流量特征可能非常不同。最近的研究证明，学习一个统一的模型来服务于多个场景可以有效地提高整体性能。然而，大多数现有方法都各自存在各种限制，例如区分度建模不足、随着场景增加效率低下、以及缺乏可解释性。更重要的是，据我们所知，现有的多场景建模方法在建模场景差异时没有考虑显式的特征交互（explicit feature interaction），这限制了网络的表现力，从而影响效果。在本文中，我们提出了一个名为SATrans的新型场景自适应特征交互框架（Scenario-Adaptive Feature Interaction framework），将场景差异（scenario discrepancy）建模成特征相关性（feature correlations）模式的区别。具体而言，SATrans建立在Transformer架构上，以学习高阶特征交互，并在**自注意力建模中涉及场景信息，以捕捉场景之间的分布变化**。我们提供了各种实现我们的框架来提高性能，并在公共和工业数据集上进行实验，结果表明SATrans:

- 1）显著优于现有的最先进方法进行预测
- 2）参数效率高，随着场景增加而空间复杂度略微增加
- 3）在实例级别和场景级别都具有良好的可解释性

我们已经将该模型部署在微信公众号平台上，在三个主要场景中平均在线CTR增加了2.84％。

# 三、问题公式化

点击率（CTR）预测数据集可以表示为：

$$
D = \lbrace (𝑥_𝑗，𝑦_𝑗) \rbrace_{j=1}^{|D|}
$$

其中：

- $𝑥_𝑗$和$𝑦_𝑗 \in \lbrace 0,1 \rbrace$：表示第j个样本的特征集和点击label

在现实世界的推荐中，通常存在多个业务场景，这意味着数据集D可以分为多个特定场景的子集 $D^s$（例如：$D = U_s D^s$），其中场景𝑠的子集$D^s= \lbrace（𝑥_𝑖^s，𝑥_i^a，𝑦_𝑖）\rbrace_{𝑖=1}^{\mid D^s \mid}$根据$𝑥_i^s$获得。这里将整个特征集$𝑥_𝑖$分为特定场景的特征集$𝑥_𝑖^s$和未知场景的特征集$𝑥_𝑖^a$。

$𝑥_𝑖^s$中的特定场景特征可以是业务ID或展示位置ID等上下文特征，也可以扩展为用户配置文件特征（例如，性别，年龄组）或项目特征（例如，类别，品牌），这可能会导致不同的行为或曝光分布。将每个场景子集$D^𝑠$拆分为：训练集$D_{train}^s$和测试集 $D_{test}^s$，我们有：$D_{train} = U_s D_{train}^s$和$D_{test} = U_s D_{test}^s$。MS-CTR预测的目标是基于$D_{train}$构建一个统一的CTR模型，可以为$D_{test}$中的所有场景子集提供准确的CTR预测。

# 4.方法

## 4.1 架构总览

为了建模多个场景下特征交互的特殊性，对于MS-CTR预测问题，我们提出了SATrans。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/9683c3c01004cfdd712cc7c536d49be38c8fb4c66ec145eb8c7c0ad265411131ca4afc7612601871a2038a09c18cadbb?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1

如图1所示，SATrans将基于自注意力的交互层堆叠作为backbone，并由两个特定场景组成：

- (1) 场景编码器（Scenario Encoder）：将特定场景特征转换为固定长度的嵌入向量
- (2) 场景自适应交互层（Scenario-Adaptive Interaction: SAI layers）：通过场景自适应自注意机制进行高阶特征交互。

给定输入特征集${𝑥_𝑖^s，𝑥_𝑖^a}$，我们首先将其转换为稀疏特征向量：

$$
x = [x^s; x^𝑎] = [x_1^s; \cdots; x_𝑀^s; x_1^a; \cdots; x_{𝑁-𝑀}^a]
$$ 

... (1) 

其中：

- 𝑀是场景特定特征（scenario-specific features）的数量
- 𝑁是所有特征的数量

之后，我们首先将场景特定特征$x^s$ feed到场景编码器（scenario encoder）中以获取场景嵌入（scenario embedding）s，然后使用嵌入层（embedding layer）将所有特征x投影到相同的低维空间，并获得dense embedding $e = [e_1; \cdots; e_𝑁]$，接着进行多个场景自适应交互层（scenario-adaptive interacting layers），其中在场景嵌入的指导下，通过自注意机制将高阶特征组合在一起。通过堆叠𝑙个交互层，可以建模多达（𝑙+1）阶的场景自适应特征交互。最终交互层的输出被连接，然后经过线性层和sigmoid函数来估计CTR。SATrans的关键在于如何设计有效的场景编码器和场景自适应交互模块。在接下来的部分中，我们将介绍我们提出的方法的详细信息。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/0b17d9b211999b7913a52ffa37fe930bc3c4607b43082c7b1a7ef3ca7dea7a063db2146c1b07b0b791e3202469c3e0e3?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2

## 4.2 Scenario Feature Encoder

给定场景特定特征$x^s=[x_1^s;\cdots;x_𝑀^s]$，我们使用一个场景自适应编码器（scenarioadaptive encoder）将场景特征编码为固定长度的场景embedding $s \in R^L$，以指导在每个SAI层中的特征交互，其中维度𝐿取决于SAI层的具体实现。为了提高场景嵌入的质量，我们考虑三个信息来源：

- 1）场景特殊性信息，区分不同的场景；
- 2）共享知识，编码场景之间的共性；
- 3）结构位置，表示场景嵌入在自注意网络中涉及的位置（例如，当前层的深度，查询或键嵌入）。

我们针对不同的信息来源提出了三种实现方式。

- 独立嵌入（IE）：该方法首先将场景特征的拼接稀疏向量x𝑠转换为一个独热稀疏特征x𝑜，然后使用嵌入矩阵将其投影到低维向量s中。这种做法将所有场景特征字段的每种可能组合视为一个场景，并使用独立嵌入来表示每个场景，这意味着场景之间没有共享知识。更糟糕的是，当特征组合数增加时，嵌入矩阵可能会很大，这将导致参数效率低下和不灵活。

- 编码网络（EN）：为了更灵活地编码场景特征并涉及共享知识，我们考虑利用共享编码网络来转换场景特征。对于每个场景特征字段，首先使用嵌入矩阵E𝑠𝑖将稀疏特征向量x𝑠𝑖投影为低维向量e𝑠𝑖。我们将每个字段的嵌入向量连接起来，得到e𝑠=[e𝑠1; e𝑠2;...; e𝑠𝑀]，然后通过非线性激活层（例如ReLU [1]）将其馈送到共享编码网络𝑓𝑒（·）中，以获取最终的场景嵌入s。在我们的实验中，我们发现一个简单的矩阵变换已经足够，即s=W𝑠ReLU(e𝑠)。

- 带有结构位置ID的编码网络（ENP）：由于场景嵌入在不同的交互层和骨干自注意力网络中的不同位置（例如，查询或键）上操作，因此生成位置感知的场景嵌入以提高网络的表达能力是合理的。为此，除了场景特征外，我们还将位置ID作为额外特征馈送到网络中，以为SAI层中的每个结构位置生成唯一的场景嵌入。具体而言，我们有 s𝑙,ℎ = W𝑠ReLU(Concat(e𝑠, p𝑙,ℎ))，(2) 其中p𝑙,ℎ是位置嵌入，𝑙是层深度ID，ℎ∈{𝑄,𝐾}。

在EN和ENP方案中，每个场景（或场景特征）的单独网络参数只是低维度（在我们的实验中为32）的嵌入向量，与每个场景具有独立门网络、特定专家网络或输出塔的MTL方法相比，这是非常参数有效的，使得SATrans可用于大量场景。我们在实验中比较参数复杂度。在接下来的部分中，我们省略下标𝑙，并使用sQ和sK分别表示查询和键表示的场景嵌入，以简化表示。请注意，对于IE和EN策略，sQ=sK。

## 4.3 Scenario-Adaptive Interacting Layer

一旦我们在相同的低维空间中拥有特征嵌入$e=[e1;...;e𝑁]$，和每个交互层中每个位置的场景嵌入$s_{𝑖,𝑗}$，我们就开始建模场景自适应高阶组合特征。假设第𝑖个特征的输入表示为$h_𝑖$，并且在第一个交互层中$h_𝑖=e_𝑖$。

我们首先引入多头自注意机制来确定每个特征组合的重要性。以第𝑖个特征为例，首先，在特定的注意力头ℎ下，第𝑖个特征与第𝑗个特征（𝑖,𝑗∈{1,...,𝑁}）之间的相关性定义为：

$$
𝛼_{𝑖,𝑗}^{(ℎ)}=\frac{exp(𝜙(ℎ)(h_𝑖,h_𝑗))}{\sum_𝑘^N exp(𝜙(ℎ)(h𝑖,h𝑘))}
$$ 

...(3)

$$
𝜙(ℎ)(h_𝑖,h_𝑗)=⟨W_Q^{(ℎ)} h_𝑖, W_K^{(ℎ)} h_𝑗⟩
$$

...(4) 

其中：

- $𝜙(ℎ)(·,·)$是一个attention函数，它定义了在头ℎ下第𝑖个特征和第𝑗个特征之间的未归一化相关性。它可以是一个神经网络或者简单的内积，即⟨·,·⟩。 $W_Q^{(h)}, W_K^{(h)} \in R^{𝑑′\times 𝑑}$是变换矩阵，将原始的嵌入空间$R^𝑑$投影到一个新的空间$R^{𝑑′}$。其中$𝑑′=𝑑/𝐻$，𝐻是注意力头的数量。然后，通过系数$𝛼_{𝑖,𝑗}$聚合其他特征，第𝑖个特征在子空间ℎ中的表示被更新为：

$$
hˆ_𝑖^{(ℎ)} = ∑︁_l^M 𝛼_{𝑖,𝑗}^{(ℎ)} (W_V^{(ℎ)} h_𝑙)
$$
...(5)

其中$W_V^{(ℎ)} \in R^{𝑑′×𝑑}$。因此，$hˆ_𝑖^{(ℎ)}是在头ℎ下第𝑖个特征及其相关特征的组合。方程式4中的相关函数将所有场景的实例视为相同，忽略了不同场景之间的分布差异。为了建模场景之间的分布转移，我们在特征之间的相关系数计算中引入了场景嵌入。我们首先将sQ、sK的场景嵌入分成𝐻个部分，即sQ=[s(1)Q,...,s(𝐻)Q]，sK=[s(1)K,...,s(𝐻)K]，其中s(ℎ)K，s(ℎ)Q∈R𝐿/𝐻，然后在头ℎ下改进场景自适应注意力函数，如下所示： 𝜙(ℎ)𝑠𝑎(h𝑖,h𝑗,s(ℎ)Q,s(ℎ)K)。 (6) 现在的问题是如何设计场景自适应注意力函数𝜙(ℎ)𝑠𝑎(·,·,·,·)，它会显著影响交互质量。基于计算复杂度从低到高的顺序，我们考虑了三种方法，如图3所示。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/93db365a438a7827a37e0ffd7c8185869222f5c2a8b0bff77dee1ddb96159921160bd12e9d38d5464204c39b477c4ae1?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3

SA-Gate（按位）：一种直接使用按位转换来引入场景嵌入的策略是门控机制。具体而言，我们基于场景嵌入生成门控模块，以过滤特征嵌入： 

$$
𝜙(ℎ)𝑠𝑎(h𝑖,h𝑗,s(ℎ)Q,s(ℎ)K)=⟨𝜎(s(ℎ)Q)◦(W(ℎ)Qh𝑖),𝜎(s(ℎ)K)◦(W(ℎ)Kh𝑗)⟩
$$
...(7) 

其中:

- $𝜎(𝑥)=1/(1+𝑒^(−𝑥))$表示Sigmoid函数
- ◦表示逐元素乘积

SA-Bilinear（双线性）：这种方法对特征嵌入进行双线性变换，由场景感知矩阵S参数化。注意力分数计算为：

$$
𝜙(ℎ)𝑠𝑎(h𝑖,h𝑗,s(ℎ)Q,s(ℎ)K)=(W(ℎ)Qh𝑗)⊤S(W(ℎ)Kh𝑖)
$$
...(8) 

$$
S=Reshape(s(ℎ)Q)∈R𝑑×𝑑
$$
...(9) 

在这种策略中，每层中的s(ℎ)Q和s(ℎ)K是相同的。

SA-MetaNet（非线性）：前两种策略采用按位和双线性变换来引入场景特征，其表达能力有限，可能无法建模场景信息与交互特征之间的复杂关系。为此，我们考虑通过MetaNet机制进行非线性变换，类似于动态权重单元[30]。以s(ℎ)Q为例，首先将其分成𝑃个槽[s(ℎ)Q,1;...;s(ℎ)Q,𝑃]，生成一个𝑃层Meta Network 𝑓m s(ℎ)Q(·)的投影参数： 𝑓m s(ℎ)Q=W1𝛿(W2𝛿(...𝛿(W𝑃x)...)) 其中W𝑝=Reshape(s(ℎ)Q,𝑝)，W𝑝∈R𝑑𝑝−1×𝑑𝑝，𝑑𝑝是第𝑝+1层的输入维度，𝛿是非线性激活函数（例如ReLU）。我们使用相同的过程构建𝑓m s(ℎ)K(·)来处理场景嵌入s(ℎ)K。生成的MetaNet用于在成对交互之前转换输入特征嵌入。然后，我们通过对变换后的嵌入进行点积来计算特征之间的相关性得分：

$$
 𝜙(ℎ)𝑠𝑎(h𝑖,h𝑗,s(ℎ)Q,s(ℎ)K)=(W(ℎ)Qh𝑗)⊤(W(ℎ)Kh𝑖)⊤𝑓m s(ℎ)Q(s(ℎ)Q)⊤𝑓m s(ℎ)K(s(ℎ)K)
$$ 
...(10) 

其中：

𝑓m s(ℎ)K(·)是场景嵌入s(ℎ)K的MetaNet函数，⊤表示转置。这种策略可以更好地捕捉场景信息和交互特征之间的非线性关系，提高了模型的表达能力。直观地说，sQ和sK的不同槽位以及激活函数可以被视为从低层到高层的场景感知滤波器，对特征嵌入进行处理，赋予网络捕捉场景之间隐含差异的能力。现在，场景自适应注意力得分计算如下：

$$
𝜙(ℎ)𝑠𝑎(h𝑖,h𝑗,s(ℎ)Q,s(ℎ)K)=⟨LN(ℎ)Q(𝑓m s(ℎ)Q(W(ℎ)Qh𝑖)),LN(ℎ)K(𝑓m s(ℎ)K(W(ℎ)Kh𝑗))⟩
$$ 
...(10) 

其中：

- LN(ℎ)Q(·)和LN(ℎ)K(·)是层归一化层，用于归一化嵌入分布，具有独立的层参数。

我们发现归一化层是必不可少的，因为经过多层非线性变换后，嵌入的方差会显著放大，这会严重影响收敛。在实践中，我们将MetaNet与LN层一起移动到多头分区之前，这允许跨不同头部进行信息交互，并在经验上实现了更好的性能。因此，注意力头ℎ下的注意力得分表示为：

$$
 𝜙(ℎ)𝑠𝑎(h𝑖,h𝑗,sQ,sK)=⟨[LNQ(𝑓m sQ(WQh𝑖))]ℎ,[LNK(𝑓m sK(WKh𝑗))]ℎ⟩
$$ 
...(11) 

其中：

- WQ和WK∈R𝑑×𝑑是变换矩阵，[·]ℎ表示分区操作和选择第ℎ个子空间。

根据公式5，我们更新注意力头ℎ下第𝑖个特征的表示为hˆℎ𝑖，然后将不同子空间的特征聚合如下： 

$$
hˆ𝑖=hˆ1𝑖⊕hˆℎ2𝑖⊕...⊕hˆℎ𝐻𝑖
$$

... (12) 

其中：

- ⊕是连接运算符。

接下来，我们使用投影矩阵WAgg将学习到的特征进行转换，并添加标准的残差连接以保留以前学习到的组合特征，包括原始的个体特征（即一阶特征），接着是一个层归一化层。形式上，第𝑖个特征的输出表示为： 

$$
hO𝑖=LN(WAhˆ𝑖+h𝑖)
$$
...(13) 

通过这样的交互层，每个特征表示将被更新为一个新的特征空间，其中包含在场景信息的指导下来自其他领域的信息。我们可以堆叠多个这样的层来模拟任意阶的组合特征。我们将最后一层的输出嵌入串联起来以获得hOut=hOut1⊕hOut2⊕...⊕hOut𝑁，并使用带有Sigmoid函数𝜎的线性层来获得最终预测：

$$
pCTR=𝜎(WOhOut+bO)
$$
...(14) 

其中：

- WO∈R1×𝑁𝑑和bO∈R。

整个网络通过交叉熵损失进行优化。空间和时间复杂度的分析详见附录A。






略

[https://dl.acm.org/doi/pdf/10.1145/3580305.3599936](https://dl.acm.org/doi/pdf/10.1145/3580305.3599936)