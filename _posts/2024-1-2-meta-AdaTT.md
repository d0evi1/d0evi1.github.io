---
layout: post
title: Meta AdaTT介绍
description: 
modified: 2024-1-2
tags: 
---

meta在《AdaTT: Adaptive Task-to-Task Fusion Network for Multitask Learning in Recommendations》提出了AdaTT的多任务建模方法。

# 摘要

多任务学习（MTL）旨在通过同时在多个任务上训练机器学习模型来提高它们的性能和效率。然而，MTL研究面临两个挑战：

- 1）有效地建模任务之间的关系以便实现知识共享，
- 2）共同学习任务特定（task-specific）知识和共享知识

本文提出了一种名为自适应任务融合网络（AdaTT：Adaptive Task-to-Task Fusion Network）的新模型，以解决这两个挑战。AdaTT是一个深度融合网络，具有多个levels上的专有任务单元（task-specific unit）和可选共享融合单元。通过利用一个**残差机制（residual）**和一个**门控机制（gating）**来进行**任务间融合（task-to-task fusion）**，这些单元可以自适应地同时学习共享知识和专有任务知识。为了评估AdaTT的性能，我们使用各种任务组在公共基准和工业推荐数据集上进行实验。结果表明，AdaTT明显优于现有的最先进基线。此外，我们的端到端实验表明，与替代方案相比，该模型表现更好。

# 1.引言 

在线推荐系统旨在为用户生成个性化的高质量推荐。这些系统的有效性通常取决于它们准确学习用户偏好的能力，这通常需要同时优化多个目标。例如，一个短视频推荐系统应该考虑用户**观看视频（watch）**的可能性（likelihood）和他们**喜欢视频（like）**的可能性（likelihood）。多任务学习（MTL）是这些用例的典型解决方案。通过在单个框架内联合训练多个任务，MTL提供了几个好处：

- 首先，它增加了**计算效率**，这对于大规模在线推荐系统非常重要
- 此外，它通过**跨任务正则化（cross-task regularization）**和**知识共享（knowledge sharing）**，增强了模型表现

然而，MTL也面临着独特的挑战。其中一个主要挑战是**建模任务之间的关系**。由于每个任务可能与其他任务**具有不同程度的相关性**，仅仅建模所有任务的一般共性是不够的。这个问题的**复杂性随着任务数量的增加而增加**。有效的任务关系建模是实现任务自适应知识共享（task-adaptive knowledge sharing）的关键。例如，“分享视频（share）”任务共享的知识可以在类似于“喜欢视频（like）”的任务中得到很大的权重，同时也可以从具有丰富示例的其它任务中吸取不同方面的知识，例如“观看视频（watch）”。另一方面，它会最小化与高度不相关的任务的共享学习(shared learning)。

- 先前的工作[2、19]通常采用**静态共享表示(static shared representations)**。
- 其他工作，如cross-stitch network[24]（如图2（c）所示），**学习矩阵**来建模多个子网络之间的关系。然而，权重对于所有样本保持不变，子网络只是松散的特定任务。
- 最近的方法，如MMoE[22]（如图2（b）所示）和PLE[29]（如图2（e）所示），**使用专门的门控网络（gating networks）**来动态组合共享的子模块以实现灵活的共享，但是这些方法建模的**任务之间的关系是模糊和间接**的。 

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/39b41e9e3d0e4b08f800b15148d5b2753632a092f27387e345be503358892aa0d9f12ea6c0c1a544412f149b55d3b693?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2 我们实验中使用的MTL模型。在多级MTL模型中，使用两个融合级别来说明它们的设计。模块用不同的颜色表示：共享模块为蓝色，任务A特定模块为黄色，任务B特定模块为紫色

除了共享学习，**专有任务学习（task-specific learning）**也是多任务学习的一个重要组成部分。在两者之间取得适当的平衡对于解决任务冲突（task conflicts）和实现跨任务正则化（cross-task regularization）非常重要。

- 一方面，MTL可能会遇到，**负迁移（negative transfer）的问题：其中对一个任务的优化会对另一个任务的性能产生负面影响**，特别是当任务具有冲突的目标时。在这种情况下，MTL模型应该自适应地强调专有任务学习。
- 另一方面，过度的特定任务学习和共享不足可能会导致过拟合，降低跨任务正则化的效益。每个任务的训练数据的数量和分布也会影响学习的重点：具有更多数据的任务可以更多地依赖于它们的特定学习，而那些具有较少数据或高度倾斜数据的任务可以更多地集中于共享学习。

考虑到样本之间的差异可以使两者之间的权衡更加动态。因此，自动学习平衡这两种类型的学习非常重要。许多**软参数共享模型（soft parameter sharing）**可以在不需要繁琐的手动调整[2]或学习所有样本的静态结构。然而，进一步的研究是 
需要理解：如何建模在共享任务学习与专有任务学习间的交叉，以便提升效果。


# 3.模型结构

为了共同学习自适应共享表示并增强任务特定学习，我们提出了一个新模型：**自适应任务融合网络（AdaTT）**。AdaTT利用**门控和残差机制**来自适应地融合多个融合层中的专家（experts）。考虑一个具有两个预测任务的多任务学习场景。我们使用两个融合层在图1中说明了AdaTT的架构。AdaTT由**多层融合网络（multi-level fusion network）**和**任务塔（task towers）**组成。融合网络（fusion networks）由任务特定和可选共享融合单元构成，而任务塔建立在融合网络之上，并与最终融合层中的任务特定单元相连。我们的框架是通用的，支持灵活选择专家模块、任务塔网络、门控模块和可配置数量的专家和融合层。 在接下来的章节中，我们首先介绍AdaTT的一个特殊情况，称为AdaTT-sp，它仅使用任务特定融合单元（如图1（a）所示）。然后，我们将描述通用的AdaTT设计，如图1（b）所示。 

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/c9add741332a5969c331be0c3bf8277a7b9fc686e9a87ac94f4d5038451669a07e8fbed7666bff6f2795a6e01f33921c?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 

## 3.1 AdaTT-sp

AdaTT-sp的详细设计如下所示。给定输入𝑥用于𝑇个任务，任务𝑡（𝑡=1,2,...,𝑇）的预测被公式化为：

$$
y_t=h_t(𝑓_𝑡^L(𝑥))
$$

...(1) 
 
其中：
 
- L：是融合层数量
- $h_t$：表示任务𝑡的任务塔
- $𝑓_t^L$：表示在第𝐿个融合层产生任务𝑡的融合单元的函数
 
这里，𝑓 𝐿 𝑡 （𝑥）通过使用方程2和3从底部到顶部应用融合层来计算：
 
$$
𝑓_1^0(𝑥)=𝑓_2^0(𝑥)=\cdots=𝑓_T^0(𝑥)=𝑥
$$

...(2) 
  
$$
𝑓_𝑡^l(𝑥)=𝐹𝑈_𝑡^l(𝑓_1^{(𝑙−1)}(𝑥), 𝑓_2^{𝑙−1}(𝑥), \cdots, 𝑓_𝑇^{l-1}(𝑥)), 𝑙=1 \cdots L
$$

...(3)

这里，FU表示融合单元。

### 3.1.1 融合单元(fusion unit)

下面我们详细介绍引入等式3中的$𝐹𝑈_𝑡^l$的构造。对于任务𝑡，在接收到前一个融合层（fusion level）的所有输出后，我们首先为该任务构造$𝑚_𝑡$个本地专家(naive experts)，表示为$𝐸_{𝑡,𝑖}^l$。使用函数$e_{𝑡,𝑖}^l$，和输入$𝑓_t^{l-1}(𝑥)$，即:

$
𝐸_{𝑡,𝑖}^l=e_{𝑡,𝑖}^l(f_𝑡^{l-1}(𝑥))
$

...(4)

其中：

- $i=1,2,\cdots,𝑚_t$
- $𝐸_{𝑡,𝑖}^l \in R^{1×𝑑^𝑙}$

在第𝑙层，每个专家网络(expert network)会产生长度为$𝑑^𝑙$的向量。为了简化表示，在第𝑙层，我们使用$𝐸_𝑡^l$和$𝐸^𝑙$分别来表示：属于任务𝑡的experts的所有垂直拼接（）、以及跨任务的所有experts的所有垂直拼接。具体而言，$𝐸_𝑡^l$ 和$𝐸^𝑙$表示为：

$
𝐸_𝑡^l=[𝐸_{𝑡,1}^l, 𝐸_{𝑡,2}^l,\cdots,𝐸_{𝑡,𝑚_t}^l]
$

...（5） 

$
𝐸^𝑙=[𝐸_1^l,𝐸_2^l, \cdots, 𝐸_𝑇^l]
$

...（6） 

其中：

- $𝐸_𝑡^l \in R^{𝑚_t \times 𝑑^𝑙}$
- $𝐸^𝑙 \in R^{(𝑚_1+𝑚_2+...+𝑚_𝑇)×𝑑^𝑙}$

在上述等式中，$[,]$表示将向量或子矩阵垂直堆叠成较大矩阵的操作。 

由于任务可能与其他任务具有不同的相关性，$𝐹𝑈_𝑡^l$直接使用门控模块𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹_𝑡^l 结合所有任务的专家𝐸^𝑙来模拟任务间的知识融合。此外，我们利用轻量级线性组合𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹_𝑡^l来融合任务𝑡的本地专家，即𝐸_𝑡^l。概念上，门控模块模拟共享学习，本地专家的线性组合模拟任务特定学习。具体而言，任务𝑡在第𝑙层的特定单元的输出被公式化为： 

$$
𝑓_𝑡^l(𝑥) = AllExpertGF_𝑡^l(𝐸^𝑙 ,𝐺_𝑡^l) + NativeExpertLF_t^l(𝐸_𝑡^l)
$$

...(7)

在公式7中，专家被融合如下： 

$$
𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹_t^l(𝐸_𝑡^l)=(𝑣_𝑡^l)^T 𝐸^{𝑡^l} 
$$

...（8）

其中，在𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹中，$𝐸^𝑙$ 乘以由一个函数$𝑔_𝑡^l$生成的门控权重$𝐺_𝑡^l \in R^{(𝑚_1+𝑚_2+\cdots+𝑚_𝑇)\times 1}，而在𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹中，相似的，$𝐸_𝑡^l$仅由一个可学习的向量$v_𝑡^l \in R^{𝑚_𝑡 \times 1}$组合在一起。

当$𝑚_1=𝑚_2=\cdots=𝑚_𝑇=1$时，即所有融合单元仅有一个专家时，为了简化起见，$𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡 𝐿𝐹_𝑡^l(𝐸_t^l)$回退到$𝐸_𝑡^l$，将一个单位权重分配给本地专家。有许多设计选项可用于$𝑔_𝑡^l$。常见的一种是使用由softmax激活的单层MLP：

$$
𝑔_𝑡^l(𝑓_𝑡^{𝑙−1}(𝑥))=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊_𝑡^l 𝑓_𝑡^{𝑙−1}(𝑥)^T)
$$

...（10） 

这里：

$𝑊_𝑡^l \in R^{(𝑚_1+𝑚_2+\cdots+𝑚_𝑇)} × 𝑑^{𝑙−1}$是一个学习的矩阵。 

### 3.1.2 简化

为了实现效率，考虑到公式8和公式9，我们实际上可以用零填充$(𝑣_𝑡^l)^T$以匹配$(𝐺_t^l)^T$的大小，加权并执行单个乘法来组合所有专家。因此，公式7可以简化为：

$
𝑓_𝑡^l(𝑥)=(𝑝𝑎𝑑(𝑣_𝑡^{lT} )+𝐺_𝑡^{lT}) 𝐸^𝑙 
$ 

... （11） 

正如我们所看到的，包含线性融合模块会导致计算量的最小增加。

## 3.2 通用AdaTT

在其一般形式中，如图1(b)所示，AdaTT采用可选的共享融合单元（fusion units）。从概念上讲，任务特定模块对之间的融合模拟了细粒度共享(fine-grained sharing)，而任务特定模块和共享模块之间的融合则传递了适用于所有任务的广泛知识。这导致了高效灵活的任务间知识共享。通用AdaTT的计算方式与AdaTT-sp类似，除了最后一个融合级别，共享融合单元不执行任何融合操作，只为任务特定融合单元产生专家输出进行处理。 

总之，AdaTT明确地学习任务特定知识并自适应地与共享知识融合。融合是任务自适应的，因为：

- 1.门控模块学习与任务本地专家相关的残差。
- 2.每个任务特定单元使用特定的门控模块融合专家，该门控模块以输入为条件（从第二个融合级别开始是唯一的）。

通过允许每个任务直接而灵活地从其他任务中学习共享知识，AdaTT相比于仅依赖于共享专家作为媒介的PLE具有更大的灵活性。此外，AdaTT可以选择仅使用任务特定专家。与PLE不同，它在每个融合单元内的不同线性融合模块中单独融合本地专家，而不是在单个门控模块中处理所有选定的专家。这种设计增强了每个融合级别后任务特定学习的鲁棒性。尽管它很简单，但我们的实验表明，它胜过了PLE，后者将选择应用于不同的融合单元中的专家，并使用不同的路由路径来区分这些专家。

# 4.实验

略

[https://arxiv.org/pdf/2304.04959.pdf](https://arxiv.org/pdf/2304.04959.pdf)