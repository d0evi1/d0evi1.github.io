---
layout: post
title: DTS介绍
description: 
modified: 2021-01-02
tags: 
---

youku在《Deep Time-Stream Framework for Click-Through Rate Prediction by Tracking
Interest Evolution》提出了一个兴趣演进的框架。

# 摘要

CTR预测在像视频推荐等工业应用中是一个必要的任务。最近，deep learning模型被用来学习用户的整体兴趣表示（overall interests），从而忽略兴趣可能会随时间动态变化的事实。我们认为：有必要在CTR模型中考虑上连续时间信息（continuous-time information）来从丰富的历史行为中跟踪用户兴趣。在本paper中，我们提出了一个新的Deep Time-Stream framework（DTS），它会通过一个常微分方程（ODE: ordinary differential equation）来引入time information。DTS会使用一个neural network来持续建模兴趣的演化，它可以来解决用户兴趣会随它们的历史行为动态表征带来的挑战。另外，我们的框架可以通过利用额外的Time-Stream Module，无缝地应用到任意deep CTR模型上，对原始CTR模型不会做任何变改。在公开数据集的实验、以及工业数据集的表现看，可以达到很好的效果。

# 介绍

CTR预测目标是估计一个用户在一个给定item上的概率，在学习界和工业界这是一个备受关注的问题。以在线视频为例，一个CTR算法会提供给用户数千个不同类目的视频，因此，精准捕获用户的兴趣很重要，可以提升用户的留存和收益。

为了达到该目标，基于用户历史点击进行建模用户兴趣会影响用户偏好。为了抽取用户兴趣的表示，提出了许多传统模型、以及deep模型。尽管这些模型在建模用户整体兴趣时达到了极大成功，它们会忽略用户兴趣的动态变化。为了进行一个更精准的结果，RNN-based方法提出捕获在user-item interaction序列中的依赖。然而，这些方法只考虑用户行为的顺序，忽略在行为间的时间间隔（time interval），它对于预测用户行为是很重要的信息。在图1中，作为示例，Mike通常会在白的天观看关于Donald Trump的视频，在晚上享受Taylor Swift的音乐视频，根据他的行为的timestamps。因而，将Mike的playlog看成一个点击视频序列，会忽略他的潜在兴趣随时间的变化。不幸的是，现有的CTR模型不能建模在连续时间上的模式，因为大多数模型不知道时间间隔（time interval）。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/e445ee6cbf48aaffe3daf6702d1ca8ecf002d1f13c439c60821e446ce88a29bf36a4606ab0470ed78fe246aeb0d547a9?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=1.jpg&amp;size=750">

图1

另外，在inference阶段，只预测下一次点击（next click）而不考虑执行action时的时间会有问题。将用户行为的时间合并进去，比如：建模在行为间的逝去时间间隔（elapsed time interval）的效果，这对于精准建模用户兴趣非常重要。例如，在图1中，如果Mike在9 p.m.(下午)观看了Taylor的视频，很可能他会在几小时内观看另一个Taylor的视频（而非Donald），而观看Donald的视频概率在半天后会更大些。然而，传统方式总是获得在任意时刻上的精准相同预测。

基于前面的观察，我们认为在CTR模型上考虑上time-stream信息（比如：连续时间信息：constinous-time info）很重要。因此，我们提出了一种新的Deep Time-Stream framework(DTS)，它会将time-stream信息引入到CTR模型中。因此，我们提出了一种新的Deep Time-Stream框架（DTS）。Time-stream信息可以通过常微分方程（ODE）进行公式化，它指的是一个描述在依赖变量的导数和独立变量间的关系的函数。特别的，DTS会使用ODE来建模用户潜在兴趣的演化，它会将用户举在兴趣状态随时间进行求导参数化，比如：ODE的解会描述用户兴趣的动态演化。另外，DTS会具有以下能力：统一在time-stream（通过点击的timestamp进行）上的用户历史行为（已点击什么）和target items（将点击什么），因而根据给定的下一时间（next time）做出inference，并提供一个更加精准的CTR预测。为了达到最小的模型变更代价（model-altering cost），ODE会被打包成一个Time-Stream Module，它可以应用到任意的deep CTR模型上。该paper的贡献如下：

- 提出了一个新的DTS框架，会将用户的latent interest evolution建模成一个ODE，它会极大提升模型的表达能力，可以更好地捕获用户兴趣的演进
- DTS可以在任意时间生成用户的feature，因而对于适配评估很灵活
- Time-Stream Module可以轻易地转成已存在的CTR模型，无需对原始框架做变化

# 1.背景

在机器学习中，有效管理一类hypotheis（线性或非线性），可以表示data patterns。ODEs可以被以用于一个hypothesis。考虑到$$R^d$$中的微分方程：$$\frac{dz}{dt} = f(z, t), z(0)=z_0$$，z在time t上的解被定义成$$z(t)$$。在监督学习中的ODE方法背后的基本思想是，调整f，使得z(t)可以生成拟合该数据所需的非线性函数。

实际上，Chen 2018的DNN被看成是discrete ODE，他们的迭代更新可以被看成是关于一个连续转换(continuous transformation)的Euler discretization。在另一方面，neural ODEs是一组DNNs模型的family，可以被解释成一个关于ResNets或RNN的contious等价。为了观察该现象，我们会将在ResNets或RNNs中的一个layer t到t+1的hidden state看transformation看成是：

$$
h_{t+1} = h_t + f_t(h_t)
$$

...(1)

在ResNets中，$$h_t \in R^d$$是在layer t和$$f_t$$的hidden state：$$R^d \rightarrow R^d$$，是一些差函数(differentiable function)，会保留$$h_t$$的维度。在RNNs中，$$h_t \in R^d$$是第t个RNN cell上的hidden state，它更新时会抛出一个函数$$f_t: R^d \rightarrow R^d$$。$$h_{t+1} - h_t$$的差可以看成是一个在timestep $$\Delta t = 1$$上的导数$$h'(t)$$的离散化（discretization）。假设：$$\Delta t \rightarrow 0$$，我们可以看到：动态的hidden state可以通过一个ODE进行参数化：$$lim_{\Delta t \rightarrow 0} \frac{h_{t+\Delta t} - h_t}}{\Delta t} = f(h, t)$$。

z(t)的解或h(t)可以使用一个ODE solver进行求解，会使用许多复杂数值方法来选择：比如：linear multi-step方法、RUnge-kutta methods或adaptive time-stepping。以上方法在deep learning中很有用，因为他们可以自适应地选择network的layers。这里要注意的不是solver本身，而是数据的表示。因此我们将solver看成是一个黑盒的differential equation solver：

$$
z_{t_1}, ..., z_{t_N}.= ODE_{solver}( z_{t_0}, f, \theta_f, t_1, \cdots, t_N)
$$

...(2)

其中，$$\theta_f$$是关于f的参数。

在下一节中，我们会展示，ODEs是如何被用来建模用户兴趣演化的动态性的，以及如何让ODEs在训练时能够稳定。

# 2.Deep Time-Stream Framework

在本节中，我们会描述DTS。首先将CTR公式化成一个二分类问题。给定数据样本 $$x = (x^U, x^V, x^P) \in X$$，其中：$$(x^U, x^V, x^P)$$分别表示来自User behavior、target Video以及user Profiles这些不同字段的one-hot vectors的concatenate。再者，每个字段包含了一个关于点击行为的列表，$$x^U = [(v_1, c_1); (v_2, c_2); \cdots; (v_N, c_N)]$$，其中：$$x_i^U = (v_i, c_i)$$表示发生在time $$t_i$$的第i个行为上，video $$v_i$$以及相应的category $$c_i$$，其中N是user的历史行为的数目；$$x^V$$表示target video和它的category $$x^V = (v_{N+1}, c_{N+1})$$，等式的成立是因为：target video会随着第(N+1)的用户点击而发生，potential click的预测时间被看成是next time $$t_{N+1}$$。因而，我们会统一在time stream上的用户历史行为和target video，通过timestamps来表示为t，$$t = [t_1, t_2, \cdots, t_N, t_{N+1}]$$。User Profile $$x^P$$包含了有用的profile信息，比如：gender、age等。Label $$y \in Y$$表示用户是否点击是指定的视频，$$y=1$$表示点击，$$y=0$$表示未点击。CTR的目标是学习一个从X到Y的mapping $$h \in H$$，其中，$$H$$表示hypothesis space，$$h: X \rightarrow Y$$表示预测用户是否将点击该视频。预测函数h可以通过以下objective function进行最小化学到：

$$
\underset{h}{min} \sum\limits_{(x,y) \in X \times Y} L(h(x;t), y)
$$

...(3)

其中，L是epmirical loss，它会在以下子部分引入。

## 2.1 通用框架

我们提出的框架DTS可以看成是一个Base-Model加上Time-Stream Module，如图2所示。BaseModel被看成是一个已经存在的deep CTR模型，比如：DNN，PNN，DIN等。除了base model外，Time-Stream Module会收集所有events的timestamps，包括：一个用户在过去的历史点击时间、以及在预测时的用户潜在点击时间。注意，后半部分在已存在的CTR模型中会被忽略。另外，Time-Stream Module会通过一个ODE来跟踪潜在兴趣演进，来计算一个增强型输入（enhanced input），它会引入continuous-time信息，并保留base inputs的维度。因此，在DTS框架中，任意的deep CTR模型可以被用于BaseModel，无需做任何更改。对比BaseModel，它会输入在用户点击item事件上的一个点击概率，DTS可以通过在给定时间上用户点击item事件的点击概率，从而对output做出提升。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/66bd49b8772f5ab283dbb17823c1280e723326b9ad96b22cd0567924b2cc7dac01e0dc4679dcb5dbf01f1a9655260cb0?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=2.jpg&amp;size=750">

图2

在面，我们会介绍BaseModel，并引入Time-Stream Module来捕获兴趣，并建模兴趣演进。

## 2.2 BaseModel

略

## 2.3 Time-Stream Module

用户兴趣会随时间动态变化。BaseModel会通过一个在点击item feature上的pooling操作获取一个表示向量，但会忽略时间信息。动态pattern的缺失会限制用户行为特征的能力，这对于建模用户兴趣很重要，因为用户点击items是一个用户在对应时间上对兴趣的表示。对于BaseModel，如果对continous pattern的能力缺失会导致在建模动态用户兴趣时的inaccuracy。

是否存在优雅的方式来表示一个用户的real-time兴趣，并建模动态兴趣演化的pattern？continous-time evolving激发我们设计了一个称为Time-Stream Framework的方法，它会利用ODE来建模动态兴趣。ODE在物理、生物、化学、工程和电子领域被广泛应用，如果ODE可解，会给出一个初始点（initial point），它可以决定所有它的future posiitons，这点points被称为“trajectory或orbit”。本文中我们使用ODEs作为hypothesis class，其中trajectory表示一个潜在的兴趣演化轨迹（lantent interst evolution trace）。在等式1中，ODE可以是通用的RNNs形式，RNNs可以被认为是continuous ODE的一个离散版本。continous ODE具有一些优点，比如：评估很灵活，相应的可以自适应地选择RNN的长度。另外，我们也可以使用高级数值方法来训练，比如：multi-grid方法、parallel shooting方法。图3展示了Time-Stream Module的架构。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/2f0c41a6b521bfef4baa13a889b460a90b78899957a969b051ce3a959ab571e6b7a3380d20a5aff49e3202323c714e5d?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=3.jpg&amp;size=750">

图3

为了通过ODE的一个latent trajectory来表示兴趣演进，会使用一个可微函数，$$\frac{d z(t)}{dt} = f(z(t), t; \theta_f)$$来表示兴趣演化率，其中：$$\theta_f$$是关于f的参数。因此，给定一个initial state $$z_{t_0}$$，ODE的trajectory可以使用等式(2)提到的一个solver来进行求解：

$$
z_{t_1}, \cdots, z_{t_N}, z_{t_{N+1}} = ODE_{solver}(z_{t_0}, f, \theta_f, t_1, \cdots, t_N, t_{N+1})
$$

...(5)

其中，$$z_{t_1}, \cdots, z_{t_N}, z_{t_{N+1}} $$是ODE的解，它可以描述dynamics f在每个观察时间$$t_1, \cdots, t_N, t_{N+1}$$的latent state。由于相似的人可能会有相近的兴趣兴趣演进pattern，我们会构建一个mapping g，它可以将user profile embedding $$e^P$$转化成latent time-stream space来获取initial value：$$z_{t_0} = g(e^P; \theta_g)$$，mapping g是一个具有参数$$\theta_g$$的线性转换，它会当成是一个将profile embedding space转化latent time-stream space的encoder。

另一方面，$$\phi$$是一个decoder，它可以将latent time-stream feature $$z_{t_i}$$转成video embedding-spaned space。$$\phi(z_{t_i}; \theta_{\phi}$$是behavior feature的adujstment或supplementary，它可以携带额外的行为演化patterns。 对于user behavior feature的adujstment，我们有：$$\bar{e_i} = e_i + \phi(z_{t_i}; \theta_{\phi})$$，其中：$$i=1, 2, \cdots, N$$。fuse operation可以被设置成像concatenation的operation，但在本工作中，add操作会被用来保证adujstment以及original feature具有相同贡献。对于target video feature，我们有：$$\bar{e}^V = e_{N+1} + \phi(z_{t_{N+1}; \theta_\phi)$$

增强行为特征（enriched behavior feature） $$\bar{e}^U = (\bar{e}_1, \bar{e}_2, \cdots, \bar{e}_N)$$，video vector $$\bar{e}^V$$和profile feature $$e^P$$会接着被发送到Base CTR模型的其余部分。

使用ODE作为一个generative model，允许我们在任意时间做出预测，不管是过去或是将来，因为在timeline上是连续的。ODE的output可以通过一个黑盒的差分等式solver进行计算，它会来评估hidden unit dynamics是否需要来决定有期望的accuracy的solution。

**function f的选择**

latent function f需要被指定，使用不同类型的函数来满足不同需求。接着，我们会引入一些方法来利用不同类型的ODE function f来建模intrest evolution的过程。

**Simple form**

function f的最简单形式是，f是一个关于独立变量t的函数：

$$
f(z, t) = \frac{dz}{dt} = A(t), z(t)=\int_{t_0}^t A(\lambda) d{\lambda} +C
$$

...(6)

其中，A是control function，C是一个constant。该类型的问题可以通过直接计算z(t)具有一个解析解。如果这样，数值形求解ODE不存在额外开销。一个特例是具有常系数的linear differential equation $$f(z, t) = A(t) = \alpha$$，它意味着在rate $$\alpha$$时有latent state discount。因此，对于所有的t会有$$z_{t_i} = \alpha (t_i -t_0) + z_{t_0}$$。这里的看法是，f的单调trajectory会模拟用户兴趣的特性：主要被最近兴趣所影响，因此会减小较早兴趣的影响，并增加用户最近行为的影响。特例相当简单，但在实验中达到很好的效果。

**复杂形式**

f的简单形式不能表达用户diverse的time-searies的pattern。为了解决该限制，另一个选择是：使用一个neural network参数化dynamics f的导数，它可以极大提升模型的表示能力。在本paper中，会使用一个带sogmoid activation unit的双层neural network：$$f(z) = \sigmoid(w_2 \cdot \sigmoid(w_1 \cdot z + b_1) + b_2)$$

其中：$$w_1, w_2, b_1, b_2$$是线性参数，$$\sigmoid(\cdot)$$是activate unit。在该形式下的f很难获得一个解析解 ，在$$z_{t_1}, \cdots, z_{t_N}, z_{t_{N+1}}$$下的解可以使用一个数值形ODE solver来计算。

**Guide Loss**

前面的函数在单次调用ODE toolbox上可以被求解，现代ODE solvers会在approx error的增长上会有保障。然而我们有以下需要注意的事项：

1) 当function形式变得复杂时，ODE的行为可能会遇到expolodes的情形，收敛到稳态或者展示混乱行为。这可以解释一些难点：比如：在DNN训练中遇到的梯度vanishing或explosion。

2) 另一方面，由于target item的行为会由用户兴趣演进所触发，该label只表示$$z_{t_{N+1}}$$的最后点击行为，而历史state $$z_t$$不会获得合适的监督（supervision）。

为了缓解这些问题，我们提出了guide loss，它会使用behavior embedding $$e_i$$来监督latent function的学习。为了这样做，受word2vec的启发，我们构建了一个小网络，它会将decoded hidden state $$\phi(z_{t_i})$$推至更接近下一行为$$e_{i+1}$$，而非一个随机负采样实例$$e^{rand}$$。Guide loss可以公式化为：

$$
L_{guide}(p,v,n)=- \frac{1}{N} \sum_i (v_i \cdot p_i + v_i \cdot n_i - log(\frac{v_i \cdot p_i}{v_i \cdot n_i})) \\
p_i = FC(e_{i+1}), v_i = FC(\phi(z_{t_i})), n_i = FC(e^{rand})
$$

其中，FC(x)是一个将PRelu作为activation的fully connected layer。模型的整个loss如下：

$$
L = L_{target} + \lambda L_{guide}
$$

...(7)

其中，L是overall loss function，$$L_{target}$$由等式(4)引入，$$\lambda$$是hyper-parameter，它会对兴趣表示和CTR预测进行balance。

整体上，guide loss的引入有一些优点：

- 1) 从兴趣学习的角度，guide loss的引入会帮助ODE的每个hidden state更丰富地表示兴趣
- 2) 对于ODE的最优化，当ODE会建模长历史行为序列时，guide loss会减小BP的难度
- 3) 对于embedding layer的学习，Guide loss会给出更多语义信息，这会产生一个更好的embedding matrix

**training和inference**

在训练阶段，我们的模型会具备重新加载BaseModel参数的能力。接着，所有weights会进行finetuned来获得一个快速收敛。我们会通过初始化f的参数以及初始值为0来达到一个safe-start，比如：ODE的trajectory是一个0常数。这样，在训练的开始，整个模型会与original CTR base model保持相同。

在inference阶段，我们可以在任意的推荐时间$$t_{N+1}$$来预测用户兴趣演进，因为我们会利用ODE solver来在下一时间$$t_{N+1}$$来集成f的函数。在工业界，DTS会更有效：当预测在$$t_{N+1}, t_{N+2}, t_{N+n}$$的多个CTR时，没有必要从头计算hidden trajectory。很容易集成从$$t_N$$到$$t_{N+n}$$的function，它们的计算很cheap。


# 4.实验

略

# 参考


- 1.[https://arxiv.org/pdf/2001.03025.pdf](https://arxiv.org/pdf/2001.03025.pdf)