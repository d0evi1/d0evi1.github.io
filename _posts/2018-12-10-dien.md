---
layout: post
title: DIN介绍
description: 
modified: 2018-12-01
tags: 
---

阿里在KDD 2018上开放了它们的方法:《Deep Interest Evolution Network for Click-Through Rate Prediction》, 我们来看下：

# 背景

# 2.相关工作

由于deep learning在特征表示和特征组合上具有很强的能力，最近的CTR模型已经从传统的线性或非线性模型转换成深度模型。大多数深度模型都使用embedding和多层感知器（MLP）的结构。基于这种基本范式，越来越多的模型关注**特征交叉**：Wide&Deep，deepFM，PNN。然而这些方法不能很明显地影响数据背后的兴趣。DIN引入了一个attention机制来为给定目标item激活局部的历史行为，可以成功捕获用户兴趣的多性化特性。然而，DIN在捕获**序列行为间的依赖关系**上很弱。

在许多应用领域，user-item交互会随时间顺序进行记录。许多最近研究表明，该信息可以被用于构建更加丰富的独立用户模型，并能发现额外的行为模式。在推荐系统中，TDSSM(song.2016)会联合优化长期用户兴趣和短期用户兴趣来提升推荐质量；DREAM(Yu et.al 2016)使用RNN的结构来探索每个用户和它的历史购买item全局序列行为的动态表示。He和McAuley(2016)会构建视觉感知(visually-aware)推荐系统，它可以使产品与用户的兴趣和社群的兴趣更匹配。Zhang et al.(2014)基于用户兴趣序列来衡量用户的相似度，并提升协同过滤推荐的效果。Parsana et al.(2018)通过使用关于recurrent网络的大规模的event embedding和attentional output来提升native ads的ctr预测。ATRank(Zhou et al.2018a)使用基于attention的序列框架来建模异种行为。对比起序列独立（sequence-independent）的方法，这些方法可以极大提升预测的accuracy。

然而，这些传统的RNN-based模型有些问题。一方面，它们中的大多数会直接将顺序结构(sequential structure)的hidden states看成是隐兴趣(latent interests)，而这些hidden states对于兴趣表示来说缺乏特别的监控。另一方面，大多数已经存在的RNN-based框型可以连续地、等价地处理邻近行为(adjacent behaviors)间的依赖。正如我们所知，并非所有的用户行为在其每个邻近行为上是严格有依赖关系的。对于任意的target item，这些模型只可以获取一个固定的兴趣演进轨迹（interest evolving track），因此这些模型可能会受兴趣漂移的干扰。

为了将序列结构的hidden states来有效表示隐兴趣，我们需要为hidden states引入额外的监控。DARNN(Ren et al.2018)使用click-level的序列化预测，它会在每次广告被曝光给用户时建模点击行为。除了点击行为，可以进一步引入ranking信息。在推荐系统中，ranking loss在ranking任务（Rendel 2009; Hidasi 2017）上被广泛使用。与其它ranking losses相类似，我们为兴趣学习提出了一个auxiliary loss。在每一step上，auxiliary loss会使用连贯的点击item，而非无点击item来监控兴趣表示的学习。

对于捕获与target item相关的兴趣演化过程，我们需要更灵活的序列学习框架。在AQ领域，DMN+(xiong 2016)使用attention-based GRU （AGRU）来处理输入facts的位置和顺序。在AGRU中，update gate的vector可以通过attention score来进行简单替换。该替换会忽略在update gates的所有维度间的不同之处，其中update gates包含了从前一序列转换而来的丰富信息。受在QA中使用的新的序列结构的启发，我们提出了使用attentional gate的GRU (AUGRU)来派生活在兴趣演化中的相关兴趣。不同于AGRU，在AUGRU中的attention score扮演着从update gate中计算得到的信息。update gate和attention score的组合，可以更专注、更敏感地推进演化过程。

# 3.DIEN

在本节中，我们会详细介绍了DIEN. 首先，我们回顾了基础的DeepCTR模型，称为BaseModel。接着全面展示DIEN结构，并引入相应的技术来捕获兴趣以及建模兴趣演化过程。

## 3.1 BaseModel

**特征表示**：在我们的在线广告展示系统中，我们使用了4种类型的特征类别：User Profile, User Behavior, Ad, Context。注意ad也就是item。对于生成阶段（generation），在本paper中我们**将ad称为target item**。特征的每个类型(category)都有多个fields，User Profile的fields有gender、age等；User Behavior的fields是一个关于用户访问过的goods_id的列表；Ad的fields有：ad_id, shop_id等；Context的fields有：time等。每个field中的特征可以被编码成one-hot vector，例如：User Profile的category的性别(female:女性)特征可以编码成[0, 1]。关于上述4种类型的特征的不同fields的one-hot vector进行拼接(concat)构成：$$x_p, x_b, x_a, x_c$$。在sequential CTR模型中，值得注意的是，每个field包含了一个行为列表，每个行为对应一个one-hot vector，它可以通过$$x_b = [b_1; b_2; \cdots; b_t] \in R^{K \times T}, b_t \in \lbrace 0, 1 \rbrace ^K $$进行表示，其中，$$b_t$$被编码成one-hot vector，并表示第t个行为，T是用户的历史行为的数目，K是用户可点击的商品总数。

**BaseModel的结构**：大多数deep CTR模型可以基于embedding&MLR来构建。基本的结构有：

- embedding
- MLP

**Loss function**：deep CTR模型常使用的loss function是负log似然函数，它会使用target item的label来监控整体的预测：

$$
L_{target} = -\frac{1}{N} \sum\limits_{(x,y) \in D}^N (y log p(x) + (1-y) log(1-p(x)))
$$

...(1)

其中，$$x=[x_p, x_a, x_c, x_b] \in D$$，D是size=N的训练集。$$y \in \lbrace 0, 1 \rbrace $$表示用户是否会点击target item。p(x)是网络的output，它是用户点击target item的预测概率。

## 3.2 DIEN

在许多电商平台中的在线展示广告，用户不会很显确地展示它们的意图，因此捕获用户兴趣和他们的动态性对于CTR预测很重要。DIEN致力于捕获用户兴趣，并建模兴趣演化过程。如图1所示，DIEN由许多部分组成。首先，的所有类别(categories)的特征都使用embedding layer进行转换。接着，DIEN会使用两个step来捕获兴趣演化：兴趣抽取层（interest extractor layer）会基于行为序列抽取兴趣序列；兴趣演化层（interest evolving layer）会建模与target item相关的兴趣演化过程。接着，最终兴趣的表示会和ad、user profile、context的embedding vectors进行拼接(concatenated)。concatenated vector被feed到MLP中来进行最终预测。在本节其余部分，我们会引入关于DIEN两个核心的模块详细介绍。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/e80b631251269cfc059a096a4465910ccf1871beb9449dc10544dd3399e66f7457cb54387b8e8c21b93d91ca3ee3bab8?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=1.jpg&amp;size=750">

图1: DIEN的结构。在behavior layer上，behaviors会按时间顺序，embedding layer会将one-hot representation $$b[t]$$转换成embedding vector $$e[t]$$。接着，interest extractor layer会使用auxiliary loss来抽取每个interest state h[t]。在interest evolving layer上，AUGRU会建模与target item相关的interest evolving process。final interest state $$h'[T]$$和其余feature的embedding vectors拼接在一起，并feed到MLR中进行最终的CTR预估。

**Interest Extractor Layer**：在电商系统中，用户行为是隐兴趣的携带者，在用户发生该行为后兴趣会发生变更。在该interest extractor layer上，我们会从序列形用户行为上抽到一系列表兴趣状态。

用户在电商系统中的点击行为是很丰富的，其中历史行为序列的长度在一个较短周期内（比如：两周）会很长。出于效率和性能的权衡，我们会采用GRU来建模行为间的依赖，其中GRU的输入可以通过它们的出现时间顺序排列的行为。GRU可以克服RNN的梯度消失问题，它比LSTM更快（1997），它对于电商系统更适合。GRU的公式如下所示：

$$
u_t = \sigma(W^u i_t + U^u h_{t-1} + b^u), & (2) \\
r_t = \sigma(W^r i_t + U^r h_{t-1} + b^r), & (3) \\
\cap{h}_t = tanh(W^h i_t + r_t \odot U^h h_{t-1} + b^h), & (4) \\
h_t = (1-u_t) \odot h_{t-1} + u_t \odot \cap{h}_t, & (5)
$$

其中，$$\sigma$$是sigmoid激活函数，$$\odot$$是element-wise乘法，$$W^u,W^r,W^h \in R^{n_H \times n_I}$$, $$U^z, U^r, U^h \in n_H \times n_H$$，其中$$n_H$$是hidden size，$$n_I$$是input size。$$i_t$$是GRU的input，$$i_t = e_b[t]$$表示第t个行为，$$h_t$$是第t个hidden states。

然而，hidden state $$h_t$$只捕获行为间的依赖，不能有效表示兴趣。随着target item的点击行为通过最终兴趣触发，在$$L_{target}$$中使用的label只包含了ground truth，它可以监控最终兴趣的预测，而历史的state $$h_t(t < T)$$不能包含合适的监控（supervision）。正如我们所知，每个step上的兴趣状态(interest state)会直接导致连续的行为(consecutive behavior)。因此，我们提出了auxiliary loss，它使用行为$$b_{t+1}$$来监控interest state $$h_t$$的学习。除了使用真实的下一行为作为正例外，我们也会从未点击的item集合中抽样作为负例。有N对(pairs)行为embedding序列：$$\lbrace e_b^i, \hat{e}_b^i \rbrace \in D_B, i \in 1, 2, \cdots, N$$，其中$$e_b^i \in R^{T \times n_E}$$表示了点击行为序列，$$\hat{e}_b^i \in R^{T \times n_E}$$表示负样本序列。T是历史行为的数目，$$n_E$$是embedding的维度，$$e_b^i[t] \in G$$表示用户i点击的第t个item的embedding vector，G是整个item set。$$\hat{e}_b^i[t] \in G - e_b^i[t]$$表示item的embedding，它会从item set（除去用户i在第t个step点击的item）中抽样。auxiliary loss可以公式化为：

$$
L_{aux} = -\frac{1}{N} (\sum\limits_{i=1}^N \sum\limits_t log sigma(h_t^i, e_b^i[t+1]) + log(1-sigma(h_t^i, \hat{e}_b^i[t+1])))
$$

其中，$$\sigma(x_1,x_2) = \frac{1}{exp(-[x_1, x_2])}$$是sigmoid激活函数，$$h_t^i$$表示对于用户i的GRU的第t个hidden state。全局loss（global loss）为：

$$
L = L_{target} + \alpha * L_{aux}
$$

...(7)



其中，$$\alpha$$是hyper-parameter，它可以对interest representation和CTR prediction进行balance。

有了auxiliary loss的帮助，每个hidden state $$h_t$$是足够表示用户在发生行为$$i_t$$后的interest state。所有T个interest points的concat $$[h_1, h_2, \cdots, h_T]$$组成了interest sequence，兴趣演化层（interest evolving layer）可以建模演化的兴趣。

总之，auxiliary loss的介绍具有以下优点：从interest learning的角色看，auxiliary loss的引入可以帮助GRU的每个hidden state表示interest。对于GRU的optimization，当GRU建模长历史行序列(long history behavior sequence)时，auxiliary loss会减小BP的难度。最后，auxiliary loss会给出更多语义信息来学习embedding layer，它会导至一个更好的embedding matrix。

**Interest Evolving Layer**

由于从外部环境和内部认知的联合影响，不同类型的用户兴趣会随时间演进。例如，对于衣服的兴趣，随着流行趋势和用户品味的变化，用户对衣服的偏好也会演进。用户在衣服上兴趣的演进过程会直接决定着对候选衣服的CTR预测。建模该演进过程的优点如下：

- Interest evloving module可以为最终的interest表示提供更多的相关历史信息
- 根据兴趣演进趋势来预测target item的CTR更好

注意，在演化期间兴趣有两个特性：

- 由于兴趣多样性，兴趣会漂移。在行为上的兴趣漂移的效果是用户可能在一段时间内对许多书（books）感兴趣，在另一段时间内可能又需要衣服(clothes)。
- 尽管兴趣可以相互影响，每个兴趣都具有它自己的evolving process，例如：books和clothes的evolving process几乎独立。我们只关注那些与target item相关的evloving process。

在第一阶段，有了auxiliary loss的帮助，我们可以获得interest sequence的丰富表示。通过分析interest evloving的特性，我们会组合attention机制的local activation能力，以及来自GRU的sequential learning能力来建模interest evolving。GRU的每个step的local activation可以增强相对兴趣的效果，并减弱来自interest drifting的干扰，这对于建模与target item相关的interest evolving process很有用。

与等式(2-5)的公式相似，我们使用$$i_t^'$$和$$h_t^'$$来表示在interest evolving module上的input和hidden state，其中第二个GRU的input是在Interest Extractor Layer所对应的interest state：$$i_t^' = h_t$$。最后的hidden state $$h_T^'$$表示final interest state。

在interest evolving module中使用的attention function可以公式化成：

$$
a_t = \frac{exp(h_t W e_a)}{\sum_{j=1}^T exp(h_j W e_a)}
$$

...(8)

其中：

- $$e_a$$是在category ad中fields的embedding vectors的concat
- $$W \in R^{n_H \times n_A}$$中，$$n_H$$是hidden state的维度，$$n_A$$是广告(ad)的embedding vector的维度。
- Attention score可以影响在advertisement $$e_a$$和input $$h_t$$间的关系，并且强相关性会导致一个大的attention score。

接着，我们会引入一些方法来将attention机制和GRU进行组合，来建模interest evolution的过程。

- $$带attentional input的GRU （AIGRU）$$：为了激活在interest evolution间的相对兴趣，我们提出了一个naive方法，称为："GRU with attentional input(AIGRU)"。AIGRU会使用attention score来影响interest evolving layer的输入。如等式(9)所示：

$$
i_t^' = h_t * a_t
$$

...(9)

其中，$$h_t$$是在interest extractor layer上的第t个hidden state，$$i_t'$$是第二个GRU的input，它用于interest evolving，其中“*”表示scalar-vector product。在AIGRU中，相关度低的interest的scale可以通过attention score减小。理想情况下，相关度低的interest的输入值可以被减小到0. 然而，AIGRU并不会很好运作。因为zero input可能改变GRU的hidden state，因此，相关度低的interests也会影响interest evolving的学习。

- **Attention based GRU（AGRU）**

在QA(question answering)领域，attention based GRU(AGRU)首先被提出来[Xiong, 2016]。通过将attention机制的信息进行embedding修改GRU架构后，AGRU可以有效地在复杂queries中抽取关键信息。受QA系统的启发，我们将AGRU移植用来在interest evolving期间捕获相关兴趣。详细的，AGRU使用attention score来替代GRU的update gate，并直接变更hidden state。正式的：

$$
h_t^' = (1-a_t) * h_{t-1}^' + a_t * \bar{h}_t^'
$$

...(10)

其中，$$h_t^', h_{t-1}^', \bar{h}_t^'$$是AGRU的hidden state。

在interest evolving场景中，AGRU会利用attention score来直接控制hidden state的更新。AGRU会弱化在interest evolving期间相关度低兴趣的影响。attention的embedding会嵌入到GRU中来提升attention机制的影响，并帮助AGRU克服AIGRU的缺点。

- **GRU with attentional update gate (AUGRU)**

尽管AGRU可以使用attention score来直接控制hidden state的更新，它会使用一个scalar(attention score $$a_t$$）来替代一个vector（update gate $$u_t$$），其中它会忽略不同维度间的不同影响。我们提出了GRU with attentional update gate (AUGRU)来无缝组合attention机制和GRU：

$$
\bar{u}_t^' = a_t * u_t^'
$$

...(11)

$$
h_t^' = (1 - \bar{u}_t^') \prod h_{t-1}^' + \bar{u}_t^' \prod \bar{h}_t^'
$$

...(12)

其中，$$u_t^'$$是AUGRU的original update gate，$$\bar{u}_t^'$$是我们专为AUGRU设计的attentional update gate，$$h_t^', h_{t-1}^', \bar{h}_t^'$$是AUGRU的hidden states。

在AUGRU中，我们会保留update gate的original dimensional信息，它会决定每个维度的重要性。基于不同的信息，我们会使用attention score $$a_t$$来将update gate的所有维度进行缩放，这会导致低相关度的兴趣会在hidden state上影响小。AUGRU会更有效地避免来自interest drifting的干扰，并将相关兴趣更平滑地推向evolve。

# 实验

略


# 参考

- 1.[Deep Interest Evolution Network for Click-Through Rate Prediction](https://arxiv.org/pdf/1809.03672.pdf)
