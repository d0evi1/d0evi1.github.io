---
layout: post
title: PU Learning介绍
description: 
modified: 2018-11-15
tags: 
---

MIT在《Learning with Positive and Unlabeled Examples Using Weighted Logistic Regression》提出了一种PU learning的方法：

# 0.介绍

学习使用正例和未标记样本的问题经常在检索应用中出现。我们将问题转化为带有噪声的学习问题，通过将所有未标记的样本标记为负例，并使用线性函数从噪声样本中学习。为了学习带有噪声的线性函数，我们在加权样本后进行逻辑回归，以处理噪声率大于一半的情况。通过适当的正则化，逻辑回归问题的代价函数是凸的，允许问题有效解决。我们还提出了一种可以从正例和未标记样本中估计的性能度量，用于评估检索性能。该度量与精确度和召回率的乘积成比例，可以与验证集一起使用，选择逻辑回归的正则化参数。在文本分类语料库上的实验表明，所提出的方法有效。

# 1.引言 

在检索应用中，通常会出现这样的情况：可以获取正例和未标记样本，但获取负例则需要支付额外的成本。例如，在尝试学习用户对网页的偏好分类器时，用户的书签可以被视为正例，而未标记样本可以从网页中采样。在直接营销中，我们希望有一个分类器能够从客户档案中识别出未来的客户。公司当前的客户名单可以被视为正例，而与获取负例的成本相比，可以以较低的成本购买新的未标记样本数据库。

在本文中，我们使用以下简单的模型来学习使用正例和未标记样本：正例以概率 \( p \) 被随机标记为正，以概率 \( 1-p \) 保持未标记状态（见(Denis, 1998)）。在这种假设下，如果我们将所有未标记的样本标记为负，我们将永远不会在负例上出错，但将以概率 \( p \) 随机地将正例标记为负。

这种表述的一个问题是 \( p \) 的值是未知的。Blum 和 Mitchell (Blum & Mitchell, 1998) 观察到，给定 \( p \)，函数 \( f \)，噪声观察到的标签 \( y_{obs} \)，实际标签 \( y_{act} \) 和输入 \( x \)，表达式 \( E[(y_{obs} - f(x))(1 - y_{obs})|x] \) 是线性相关的。目标函数具有零实际误差，因此当目标函数在所使用的函数类中，并且样本量足够大时，最小化观察到的假阳性和假阴性频率之和将给出目标函数的良好近似。这避免了需要知道 \( p \) 的值。

最小化假阳性和假阴性错误频率的预期总和可以证明等同于最小化预期加权误差，其中假阳性乘以 \( \frac{1}{p} \)，假阴性乘以 \( \frac{1}{1-p} \)。不幸的是，对于线性函数，最小化加权误差是 NP-hard 的 (Hoffgen 等人，1995)。在本文中，我们不是最小化加权误差，而是通过执行逻辑回归来学习给定输入时观察到正标签的真实条件概率。我们通过形成成本函数来执行正则化，该函数从线性函数权重的平方和加权逻辑损失的总和中优化。最终的成本函数是凸的，我们使用简单的梯度下降进行优化。

在实践中，我们所使用的函数类可能不是用于学习的正确函数类。即使已知正确的目标函数类，当训练样本较小时，我们可能希望使用一个更简单的近似函数（例如通过正则化），以获得更好的泛化能力。在本文中，我们展示了 \( F_{\beta} = \frac{\beta^2 \cdot \text{precision} \cdot \text{recall}}{(\beta \cdot \text{recall}) + \text{precision}} \)，其中 \( \text{precision} \) 是精确度，\( \text{recall} \) 是召回率，可以从正例和未标记样本中估计。这个函数由目标函数最大化，通常我们希望在检索情况下精确度和召回率都很高。能够从正例和未标记样本估计该函数使我们能够使用验证集上的性能来选择用于学习的适当正则化参数。我们使用验证集来选择文本分类任务中逻辑回归的正则化参数进行了实验。结果表明所使用方法是有效的。

本文有两个主要贡献。第一是使用真实值输出代替加权样本的线性函数的阈值二元输出，用于正例和未标记样本的学习。这允许使用最大似然，为优化提供了一个凸的代价函数。第二是引入了一个可以从正例和未标记样本估计的性能度量。当只有正例和未标记样本可用时，这个性能度量可以用来从验证集中选择正则化参数。

在第2节中，我们讨论了相关工作。第3节详细描述了我们学习线性函数的算法。我们在第4节中使用正例和未标记数据推导出 \( F_{\beta} \) 的估计，并在Se节给出了实验结果。（注：最后一部分似乎不完整，可能需要更多的上下文来完成翻译。）

# 2.相关工作 

略

# 3. 学习线性函数

形式为 \( f(x) = w^T x + b \) 的线性函数，其中 \( w \) 是输入向量 \( x \) 的分量，\( b \) 是偏置项，在机器学习中是实际有效且常用的。

为了模拟生成正例和未标记样本的过程，我们假设正例以一定的概率 \( p \) 被随机留作未标记，而负例总是保持未标记。通过将所有未标记的样本标记为负，正例以概率 \( p \) 被错误标记，而负例则永远不会被错误标记。设 \( X \) 为代表输入向量的随机变量，\( y_{act} \) 为实际标签，\( y_{obs} \) 为观察到的噪声标签。对于任何函数 \( f \)，我们定义其预期观察到的假阳性和假阴性误差频率之和为 \( E[(y_{obs} - f(X))(1 - y_{obs})|y_{act}, X] \)，以及预期实际的假阳性和假阴性误差频率之和为 \( E[(y_{obs} - f(X))y_{act}|X] \)。Blum 和 Mitchell (Blum & Mitchell, 1998) 展示了，如果正例具有恒定的噪声率 \( p \)，而负例具有恒定的噪声率 \( q \)，则 \( E[(y_{obs} - f(X))(1 - y_{obs})|y_{act}, X] = \frac{p}{p + q} \) 和 \( E[(y_{obs} - f(X))y_{act}|X] = \frac{q}{p + q} \)。如果我们将未标记的样本标记为负，正例将具有噪声率 \( p \)，而负例将具有噪声率 \( q \)。

最小化 \( E[(y_{obs} - f(X))(1 - y_{obs})|y_{act}, X] \) 也将最小化 \( E[(y_{obs} - f(X))y_{act}|X] \)。观察到最小化 \( E[(y_{obs} - f(X))(1 - y_{obs})|y_{act}, X] \) 等同于最小化预期加权误差，其中假阴性的权重为 \( \frac{1}{p} \)，假阳性的权重为 \( \frac{1}{q} \)。然而，最小化加权误差是 NP-hard 的 (Hoffgen 等人，1995)。我们不是最小化假阳性和假阴性误差频率，而是假设函数类是一个足够强大的实值函数类，能够表示给定输入时标签为正的条件概率。我们展示了，如果我们将标记为正的样本乘以 \( \frac{1}{p} \)，将标记为负的样本乘以 \( \frac{1}{q} \)，则给定样本是正例时标签为正的条件概率大于 0.5，给定样本是负例时标签为正的条件概率小于 0.5。这允许我们将实值条件概率在 0.5 处设阈值以获得正确的分类。

设 \( p \) 为正例被标记为正的概率，\( q \) 为正例被标记为负的概率。被标记为正的样本预期比例是 \( \frac{p}{p + q} \)。同样地，被标记为负的样本预期比例是 \( \frac{q}{p + q} \)。

我们首先考虑一个正例 \( x \) 的行为。它被标记为正的概率是 \( p \)。每个被标记为正的样本乘以权重 \( \frac{q}{p} \)，得到 \( x \) 上的预期正权重是 \( \frac{pq}{p + q} \)。同样地，\( x \) 上的预期负权重是 \( \frac{p}{p + q} \)。

为了将权重与概率等同，我们可以看到正标签的条件概率已经被转换为：
\[ \frac{\frac{pq}{p + q}}{\frac{pq}{p + q} + \frac{p}{p + q}} = \frac{pq}{pq + p} \]
\[ = \frac{p}{p + 1} \]
这个值只要 \( q > 0 \) 和 \( p > 0 \) 就大于0.5。

因此，在加权之后，我们可以看到如果我们将阈值设为0.5，我们将获得正确的分类。由于负例被标记为正的概率为零，将阈值设为0.5也将为负例提供正确的分类。

为了学习条件概率，我们将线性函数 \( f(x) \) 与 Sigmoid 函数组合，得到：
\[ \sigma(f(x)) = \frac{1}{1 + e^{-(w^Tx + b)}} \]
然后我们在加权的正例和负例上执行最大似然估计，其中加权可以被解释为相同样本的多份副本。对于每个未加权样本，我们得到对数损失 \( -\log(\sigma(f(x))) \)。对加权样本求和，我们得到：

\[ \text{Cost} = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(\sigma(f(x_i))) + (1 - y_i) \log(1 - \sigma(f(x_i)))] \]
其中 \( N \) 是样本总数，\( y_i \) 是第 \( i \) 个样本的真实标签，\( x_i \) 是第 \( i \) 个样本的特征。

这等同于最小化成本函数 \( \text{Cost} \)。最后，为了防止过拟合，我们将权重的平方和作为正则化项添加到成本函数中，得到最终的成本函数：
\[ \text{Cost}_{\text{final}} = \text{Cost} + \lambda \sum_{j=1}^{M} w_j^2 \]
其中 \( \lambda \) 是正则化参数，可以调整以防止过拟合。这个成本函数是凸的。


# 4. 使用正例和未标记样本估计性能

在使用噪声数据学习时，防止过拟合至关重要。这通常可以通过使用验证集来选择正则化参数 \( \lambda \) 来实现。尽管目标函数最小化了正误差和负误差频率之和，但当函数类不能准确表示目标函数时，这个和并不一定适合选择正则化参数。

从正例和未标记样本中学习的需求通常出现在检索情况中，我们有一组正例，并希望从未标记样本的来源中检索出更多的正例。在这些场景中，正例与负例的比例通常非常小。在检索情况下常用的性能度量是 \( F_\beta \) 分数，其中 \( F_\beta = (1 + \beta^2) \cdot \text{precision} \cdot \text{recall} / (\beta^2 \cdot \text{precision} + \text{recall}) \)，精度为 \( \text{precision} \)，召回率为 \( \text{recall} \)。\( F_\beta \) 分数是精度和召回率的调和平均数。要获得高的 \( F_\beta \) 分数，精度和召回率都必须高。不幸的是，我们不知道如何从正例和未标记样本中估计 \( F_\beta \) 分数。相反，我们提出了一个性能标准，用于比较模型（或正则化参数）\( \phi \)，它可以不作额外假设直接从验证集中估计。看到这一点，注意：
\[ \text{precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} \quad \text{and} \quad \text{recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} \]
其中，\( \text{TP} \) 是真正例的数量，\( \text{FP} \) 是假正例的数量，\( \text{FN} \) 是假负例的数量。将两边乘以 \( \text{recall} \)，我们发现 \( \phi = \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}} \)。注意，召回率可以从验证集中正标记样本的假设性能估计，而精度可以从验证集中估计，为我们提供了所需的模型选择标准的估计。这个性能度量与精度和召回率的几何平均数的平方成比例。它与 \( F_\beta \) 分数的行为大致相同，即当精度和召回率都很大时它是大的，如果精度或召回率中的任何一个很小，它就是小的。

# 5.实验

略

# 参考

- 1.[https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=956a244c580388b4bab0990f024f859a10aa4df6](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=956a244c580388b4bab0990f024f859a10aa4df6)
