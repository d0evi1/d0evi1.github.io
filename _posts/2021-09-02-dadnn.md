---
layout: post
title: Domain-Aware DNN介绍
description: 
modified: 2021-09-02
tags: 
---

JD在《DADNN: Multi-Scene CTR Prediction via Domain-Aware Deep Neural Network》提了一种domain-aware DNN介绍。

# 1.介绍

# 2.模型结构

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/6f02494909effe20958b94e7ce417c60a26da2f0ceb612dc45e3bbe4de7447fbdf4966c8d999b1cf17897505591354e2?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图2 模型结构展示（fts-features）。(a) DNN model，它仅会考虑单个场景 (b) DADNN-MLP model，它会进一步考虑对于每个单独场景裁减出的差异特性。routing layer会使用关于scene id的一个wide input来区分场景。KT表示在多个场景间的内部知识迁移（internal knowledge transfer） (c)DADNN-MMoE model，它引入了multi-gage mixture-of-experts来替换hard shared-bottom block。gate的weights允许为每个单独scene进行差异化representations 

# C.Routing & Domain Layer

如果遵循相同的分布，独立场景的数据很少。为了减小跨场景的domain shift，routing layer会将通过场景来将划分样本给各自的domain layer，这样，对于对于每个独立的场景可以进行裁减出差异的representations。routing layer会通过一个scene id的wide input来区分场景。当在线进行serving时，对于每个场景来说只有一个domain layer会激活。routing和domain layer如图2(b)和图2(c)所示。更特别的，每个场景具有一个domain layer，它只会使用它自己的数据来调整模型参数。为了这个目的，domain layer可以来缓解引入多个数据分布带来的效果退化。给定一个dataset $$D = \lbrace (x_i, y_i) \mid i = 1,2,\cdots, N \rbrace$$，我们的模型的objective function定义如下：

$$
argmin_{W_d} L_d (W_d; D)
$$

...(5)

其中，$$L_d$$是在training set的total loss。它的公式为：

$$
L_d(W_d; D) = \sum\limits_{k=1}^K \alpha_k L_{d_k}
$$

...(6)

其中：

- $$L_{d_k}$$是第k个场景的loss
- $$\alpha_k$$是它相应的weight
- K是场景号

通过我们的探索，我们发现，当将$$\alpha_k$$动态地设置为第k个场景的样本百分比时效果最好。特别的，$$L_{d_k}$$通常定义为cross-entropy loss function：

$$
L_{d_k} = - \frac{1}{N_k} \sum\limits_{i=1}^{N_k} (y_i log p(x_i) + (1-y_i) log(1-p(x_i)))
$$

...(7)

其中：

- $$N_k$$是第k个场景样本的size
- $$y_i$$是第i个实例的ground truth
- $$p(x_i)$$是第k个domain layer的output，它表示样本$$x_i$$被点击的概率

# D. Knowledge Transfer

尽管routing和domain layer可以缓和domain shift，domain layer对于流量有限的场景可能会训练得不够充分。另外，在我们的实验中，这些场景都是特定比较相似的feeds。为了这个目的，我们提出了一个knowledge transfer模块，它位于每两个场景间，允许综合知识交互（knowledge interactions）和信息共享（information sharing），如图2(b)和图2(c)所示。一旦这些来自teacher domain classifier的knowledge被生成，它可以通过其它cross-entropy loss来指导其它domain layers。另外，我们会描述我们提出的knowledge transer方法。给定一个dataset $$D = \lbrace i=1, 2, \cdots, N \rbrace$$，我们的模型的objective function如下所定义：

$$
\underset{argmin}{W_d, w_{kt}} L_d(W_d; D) + L_{kt}(W_{kt}; D)
$$

...(8)

特别的，$$L_{kt}$$是knowledge matching loss，它表示由[14]扩展而来的pairwise probabilistic prediction mimicking loss，它的定义如下：

$$
L_{kt} = \sum\limits_{p=1}^K \sum\limits_{q=1, p \neq q}^K u_{pq} L_{pq}
$$

...(9)

$$
L_{pq} = - \frac{1}{N_p} \sum\limits_{k=1}^{N_p} (p(x_i) logq(x_i) + (1 - p(x_i)) log(1-q(x_i)))
$$

...(10)

其中，$$p(x)$$和q(x)分别表示teacher network和student network。$$u_{pq}$$是classifier p到q的weight，$$N_p$$是teacher样本的size。在我们的实验中，我们设置$$u_{pq}$$为0.03 。特别的，我们只会使用在teacher network中的场景数据来更新student network。我们会开发gradient block scheme来阻止teacher net恶化，它在【16】中有使用。

# 4.实验

在本节中，我们会详细描述我们的实验。我们会在从公司中的在线广告系统中收集到的数据集来进行实验。另外，我们设计实验来验证routing和domain layer，MMoE模块和knowledge transfer的的效果。最后，我们会共享在线serving的结果和技术。

## A.Metrics

AUC是在线CTR预估领域广泛使用的metrics。它表示：一个CTR predictor对于随机选择一个postive item高于一个随机选择negative item的概率。由于私有场景的数据分布通常是多样的，我们会使用一个派生自GAUC的metric，它表示了一个通过将每个场景的样本group计算而来的weighted average AUC。一个基于GAUC的impression如下计算：

$$
GAUC = \frac{\sum\limits_{i=1}^K impresseion_i \times AUC_i}{\sum\limits_{i=1}^K impression_i}
$$

...(11)

其中，weight是每个场景的曝光数。该metric会measures intra-scene order的好坏，并表明了在广告系统中的在线效果更相关。特别的，我们使用calibration metric来measure模块稳定性，因为CTR的accurate prediction对于在线广告的成功来说是必要的。它是average estimated CTR和empirical CTR之间的ratio：

calibration = pCTR / CTR 

...(12)

calibration与1的差异越小，模型越好。

## B.datasets和实验setup



# 参考



- 1.[https://arxiv.org/pdf/2011.11938.pdf](https://arxiv.org/pdf/2011.11938.pdf)