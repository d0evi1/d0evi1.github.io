---
layout: post
title: 小红书SSD介绍
description: 
modified: 2022-06-10
tags: 
---

xiaohongshu在《Sliding Spectrum Decomposition for Diversified Recommendation》中提出了SSD的多样性方法：

# 摘要

内容feeds流，作为一种向用户推荐一系列浏览和消费(engage)的item的产品，在社交媒体平台上非常流行。在本文中，我们提出从item序列的角度，使用时间序列分析技术来研究这种场景下的多样性问题。我们推导出一种称为滑动频谱分解（SSD）的方法，它捕捉用户在浏览长item序列时对多样性的感知。我们还分享了我们在设计和实现一种合适的item embedding方法方面的经验，以便在长尾效应下进行准确的相似性测量。综合起来，这些方法现在已经完全实现并部署在小红书App的生产推荐系统中，为每天数千万用户提供主要的探索feeds产品。我们通过理论分析、离线实验和在线A/B测试展示了该方法的有效性和效率。

# 1 引言

内容feeds流，或在本文中简称为feeds，是一种非常流行的社交媒体产品，它为用户推荐了一系列浏览和参与的item序列。Instagram的探索feeds和TikTok的为你feeds是这类产品的典型例子。在本文中，我们报告了我们在小红书探索feeds产品中的工作。小红书1（中文意思是小红书）是一个拥有超过1亿月活跃用户的社交媒体平台。用户在平台上分享他们关于时尚、美食、旅行、阅读、健身等日常生活体验，以获得乐趣和灵感。每篇帖子都包含文本和视觉内容。**在推荐系统（RecSys）的术语中，每篇帖子都是一个item。平台通过其探索feeds产品向用户推荐这些item，如图1所示**。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/5ff6a9d43e01964d8eaf31799605c1208ab431fbf75c4a5c49f0ad1104376258d01271342d8adf25f9f33741691d07c5?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=1.jpg&amp;size=750">

图1 小红书探索供给产品的截图。左侧：用户可以滑动选择的两列推荐item列表。右侧：用户点击某个item后进入的item详情页面。

我们确定了这些feeds产品的两个常见特征，这些特征与推荐中的多样性问题密切相关。首先，它们允许用户通过手机当前的视窗持续下滑item列表。尽管当前视窗中的item pair对用户对多样性的感知有最直接的影响，但我们认为，**由于用户的记忆，用户已经查看过的视窗外的item仍然对用户的感知有持久的影响**。通过类比，我们发现许多现有的多样性方法[8, 9, 37]使用基于滑动窗口的实现忽略了视窗外的item，因此没有完全捕捉到用户的多样性感知。尽管**扩大滑动窗口可能可以解决这个问题**，但它增加了计算时间，并且在实践中阻碍了其在具有非常严格的延迟要求的生产系统中的部署。**在feeds场景中，这个问题更加严重，因为用户倾向于在feeds应用程序上查看许多item**。图2（左）显示，在过去1.5年中，小红书探索feeds的用户查看item序列的平均长度增加了约50%。具有滑动窗口实现的现有多样化推荐算法将在这个长item序列场景中忽略许多item。为了解决这个问题，我们提出从item序列的角度使用时间序列分析技术来研究多样化推荐问题。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/54895e86a1a24060a132e84d9045f64a9cbb67d03678f4d3dd7d66fb48e242f18b2f550a56668e754e439b7ddde105ac?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=2.jpg&amp;size=750">

图2 关于小红书探索供给的统计数据。左侧：过去1.5年中用户平均项目序列长度的增长。右侧：项目数量相对于用户点击次数的分布，这清楚地展示了长尾效应。

我们推导出了一个称为滑动频谱分解（SSD）的方法。它将多个滑动窗口堆叠到轨迹张量中。分解张量可以得到一个**考虑了视窗外item和整个item序列的多样性的广义定义**。设计了一个贪婪推理过程来计算多样性项，并且被证明比现有最先进方法[9]更有效率。

第二，正如许多推荐系统中所出现的，长尾效应在这些feeds产品中也显现出来。少数item获得了大多数用户参与，而大量item几乎没有或很少有用户互动。图2（右）显示了小红书探索feeds中的效果。多样性算法中的一个关键组成部分是item相似性的测量。**长尾效应使得基于协同过滤（CF）[20, 22, 27]的相似性测量由于许多item上用户参与的稀疏性而变得不够有效。一种替代方案是依赖基于内容的方法（CB）**。然而，纯粹基于内容的相似性测量也有一些缺点。为**基于内容的相似性模型收集大量训练数据非常耗时，而且训练数据往往会偏向于注释者对item相似性的看法**，而不是最终用户的看法[11]。受到CB2CF工作[5]的启发，我们设计了一种类似的策略，迫使模型从item内容中泛化，学习用户在其item参与中隐含表达的对item相似性的看法。我们也称这种策略为CB2CF，尽管实际方法与[5]不同。遵循这一策略，我们设计并训练了一个并联网络[6]来学习item embedding。然后将这些嵌入适应并用于SSD方法中的相似性计算。

我们的贡献如下：

- 与许多先前的方法[8, 9, 37]不同，我们从item序列的角度使用**时间序列分析技术**研究推荐多样性问题。我们认为这种视角更符合feeds场景，即向用户推荐一系列item。
- 沿着这个方向，我们推导出了一种称为滑动频谱分解（SSD）的方法。它将视窗外的item和整个item序列纳入对多样性的考虑。此外，与现有最先进方法[9]相比，它在计算上更有效率。
- 我们分享了使用CB2CF策略获得能在长尾效应下准确测量item相似性的item embedding的经验。我们描述了如何适配嵌入向量以与SSD方法一起工作，以及嵌入向量在我们的生产数据中的表现。
- 我们通过理论分析、离线实验和在线A/B测试展示了所提方法的有效性和效率。

# 2 相关工作

## 2.1 多样化推荐

在推荐系统中，多样性主要有两个视角：聚合（aggregation）和个体（individual）。聚合考虑所有用户之间的多样性，其目标通常是提高推荐系统的覆盖率[14, 15]。另一方面，个体，也是我们在这项工作中研究的视角，侧重于给定用户的多样性，通常我们希望在质量和多样性之间实现最佳权衡[1, 2, 8, 37]。

在个体视角下，多样化推荐通常通过一个优化问题来表述，目标是同时考虑质量和多样性。一些研究讨论了如何构建和解决这个优化问题。

- 在[8]中的工作提供了一种基于边际的贪婪算法，也称为**最大边际相关性（MMR）**，其中一项的分数是检索质量项减去表示其与先前选定item相似性的惩罚项。
- [26]提出最大化相关性加上一个类似熵的多样性项。
- 最近，许多工作将**行列式点过程（DPP）**应用于多样化推荐。DPP是一个概率框架，最初用于描述热平衡中的分布，特征是某些函数的行列式[24]。在推荐上的应用通常使用L-集合DPP，其中函数是一个对称矩阵，也称为核矩阵，代表质量和成对相似性。在本文中，DPP总是指L-集合DPP。
    - 在[9]中，作者提供了一个**快速贪婪算法**来解决DPP的计算复杂性问题。
    - 在[37]中的工作提出了一种实用的方法，从**过去的交互中学习核矩阵，并与近似贪婪推理相结合**。

为了在实践中提高效率，**滑动窗口**是这些方法中的一个关键组件[17, 37]。
在使用滑动窗口的贪婪推理过程中，所有这些工作完全**忽略了视窗外的item**。然而，保持这些item的信息更符合用户的感知。这项工作将推荐序列建模为用户观察到的时间序列。通过利用时间序列分析技术，我们的方法能够考虑多个窗口来模拟整个序列的多样性。

## 2.2 item相似性

在推荐系统中，item到item的推荐是一个关键组件，其中展示了用户喜欢item的最相似item。旨在为此计算item相似性的技术通常被归类为**协同过滤（CF）或基于内容（CB）**。

- 基于协同过滤（CF）的算法，它根据用户的隐式反馈构建相似item表，在各种个性化任务中常用[22, 30]。
- 基于内容（CB）的方法，忽略了用户的历史行为，基于内容信息（如item描述、图像等）计算item相似性。

在多样化推荐方面的现有工作中，已经探索了CB和CF技术来测量item相似性。例如：

- 在[37]中的工作建议使用item标记之间的**jaccard距离**作为距离函数。
- 在[9]中，作者从用户反馈中使用矩阵分解（MF）技术创建item表示。
- 一般来说，CF方法比CB方法提供更准确的相似性测量[29]。然而，当对item没有或很少有反馈时，即长尾或新item时，CF算法受到限制，这构成了社交媒体平台item的主要部分。因此，许多人尝试使用基于内容的功能来解决这个问题。
- 在[5]中，作者提出了一种**CB2CF方法**，从内容特征学习映射到协同过滤嵌入，以解决冷启动item推荐。
- 在[4]中，作者通过使用多视图神经注意力机制改进了模型。然而，注意力模型不适合用于多样化推荐任务中的item相似性测量，因为它是成对模型，并且在需要评估大量配对item时计算上非常昂贵。

在本文中，受到[5]中工作的启发，我们提出了一种适合与SSD配合使用的CB2CFitem embedding。我们的方法与之前的方法不同，我们没有将item内容映射到CF向量。相反，我们迫使模型从item内容中学习，推断出由ItemCF方法[22]产生的加强相似性信号。

# 3 问题设置

图3展示了工业推荐系统的典型结构[36, 37]。系统首先从item数据库中检索候选item，然后通过排序（ranking）模块来衡量点质量，即预测特定item将为用户提供的效用有多少，对每个item进行预测。最后，高质量的item将被发送到策略模块进行进一步选择和重新排序，以构建最终的推荐。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/7140ad158c6e2c49eeb05f484fa8d2288d30934d6ec7d5a7cc9f11a880cc386e4e8dc48c31930d03eacd02ce385fcf5d?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=3.jpg&amp;size=750">

图3 工业推荐系统的典型结构

在本文中，我们考虑多样化feeds推荐问题，其中：策略模块需要从排序模块生成的候选item集合 $ Z =\lbrace 1, 2, ..., N \rbrace  $ 中选择一个item序列 $\lbrace i_1, ..., i_T \rbrace  $。选择过程应考虑item之间的多样性以及它们的质量。在我们的设置中，对于每个item $ i $，排序模块提供了对其质量的估计 $ r_i $，策略模块可以访问其 $ d $ 维嵌入 $ \mathbf{v}_i \in \mathbb{R}^d $。我们要求两个item embedding的内积代表它们的相似性。此外，如今，检索和排序模块通常使用复杂的深度神经网络，对我们策略模块的解决方案提出了严格的延迟要求。

# 4 SSD

在这一部分，我们首先为我们提出的多样化feeds推荐方法——**滑动频谱分解（SSD：Sliding Spectrum Decomposition）**——进行公式化。然后我们为SSD引入了一种高效的贪婪推理方法，以满足生产系统中策略模块的低延迟要求。最后，我们对SSD进行了深入分析，并展示了它与DPP方法[9]的深刻联系。

## 4.1 公式化

在feeds推荐中，用户浏览一长串item并与它们互动。我们的目标是在这种情况下，在RecSys的策略模块中构建一个高质量和多样化的item序列。我们通过回答两个问题来解决问题：

- 1）如何在这样长的序列中测量多样性；
- 2）如何构建一个考虑整体质量和多样性的目标。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/3fa82c809508bb79ad0a7135bc28215f429bb5fb148b6612a16b2d76c14dcdea6656f19b168f95f25c92de63165dcadb?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=4.jpg&amp;size=750">

图4 从用户观察到轨迹张量的过程

对于第一个问题，为了与用户的感知保持一致，让我们从用户的角度分析item序列。由于feeds推荐器通常提供一长串item，用户的当前视窗只能占据整个序列的一部分。随着用户连续浏览item，很自然地将feeds视为用户观察到的时间序列。在时间序列分析中，通常涉及一个滑动窗口来表示时间分辨率。同样，在推荐系统中，用户的滑动窗口出现在手机的当前屏幕上或用户心中的一个缓存区域。**假设这个窗口有一个固定的大小，标记为$w$**，我们可以通过图4中的三个步骤处理用户的观察：

- 首先，一个窗口在整个原始item序列上**滑动（slide）**。
- 然后，多个窗口的item以item矩阵的形式**堆叠（stack）**在一起。
- 最后，我们将每个item映射到其**d维item embedding**，获得以下轨迹张量 $ X \in \mathbb{R}^{L \times w \times d} $：

$$
X = 
\begin{bmatrix}
\mathbf{v}_{i_1} & \mathbf{v}_{i_2} & \cdots & \mathbf{v}_{i_w} \\
\mathbf{v}_{i_2} & \mathbf{v}_{i_3} & \cdots & \mathbf{v}_{i_{w+1}} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{v}_{i_L} & \mathbf{v}_{i_{L+1}} & \cdots & \mathbf{v}_{i_T}
\end{bmatrix}, \quad (1) 
$$

其中：

- $ L = \max(1, T - w + 1) $。

当 $ d = 1 $ 时，X 刚好是单变量时间序列的奇异谱分析（SSA）中的轨迹矩阵[7]。**在时间序列分析中，SSA是一种强大的技术，已经广泛应用于各个领域，例如，多变量统计、非线性动力学系统和信号处理[35]**。

在传统时间序列分析中，一个复杂的时间序列通常由几个规律性组成部分构成。例如，随着农业的持续发展，粮食生产呈现上升趋势，但也受到季节的影响，即粮食生产的时间序列是趋势和季节性的总和。**SSA就是这样一种技术，它可以将时间序列分解为各种正交分量，其中这些分量的权重通过轨迹矩阵的奇异值分解来表示**。

在推荐场景中，通过**将d维item embedding视为多变量观测（multivariate observations）**，我们将轨迹矩阵(trajectory matrix)推广到三阶情况。按照SSA，我们对X执行奇异值分解[19, 34]：

$$ X = \sum_{\sigma_{ijk} > 0} \sigma_{ij}^k \mathbf{u}^{(1)}_i \otimes \mathbf{u}^{(2)}_j \otimes \mathbf{u}^{(3)}_k, \quad (2) 
$$

其中:

- $ \mathbf{u}^{(1)}_i \in \mathbb{R}^L $，$ \mathbf{u}^{(2)}_j \in \mathbb{R}^w $，$ \mathbf{u}^{(3)}_k \in \mathbb{R}^d $ 是X的正交分解矩阵的列，
- $ \otimes $ 表示外积。

在RecSys中，**用户观察到的正交分量可以被视为item内容呈现的正交方向，而奇异值因此指这些方向在用户对多样性感知中的权重**。

经过上述处理后，剩下的问题是如何从这种分解中定义多样性。让我们**首先考虑一个简单的情况，即没有任何一对窗口之间有重叠**，也就是说，在计算多样性时，窗口彼此独立。因此，我们可以只关注X的单行，将轨迹张量退化为矩阵。假设item embedding在内积空间中，即一**对item之间的内积可以代表它们的相似性**。很自然地，我们可以通过这些**item所跨越的超平行六面体的体积来定义多样性(diversity)**，其中多样化的item跨越更大的体积，因为它们的嵌入更正交。注意，计算矩阵体积的一种方法是使用**奇异值的累积乘积**[33]。因此，我们推广这种方法来定义三阶张量X的体积如下：

$$
\prod_{\sigma_{ijk} > 0} \sigma_{ijk} \quad (3) 
$$

注意，在三阶张量X中，SSD从用户浏览整个序列的感知中组合了多个窗口。**X的体积因此代表了基于整个序列以及滑动窗口的多样性**。因此，我们通过公式(3)定义了整个序列的多样性。

一个剩下的问题是如何在优化中组织多样性和质量，我们提议直接将它们相加：

$$
\max_{\{i_1,...,i_T \rbrace  \subset Z} \left( \sum_{t=1}^{T} r_{i_t} + \gamma \prod_{\sigma_{ijk} > 0} \sigma_{ijk} \right), \quad (4) 
$$

其中:

- $ \gamma $ 是一个超参数，用于调整质量和多样性之间的权衡。

我们将从推荐器的角度展示公式(4)的合理性和洞察力。

- 一方面，工业推荐器通常计算质量分数以代表用户的预期效用，如**视频观看时间或参与度**。
- 另一方面，多样性有时被视为**探索**，以更多地了解用户[28, 32]。

因此，质量和多样性之间的权衡对于推荐器来说是一种**利用-探索(EE)**权衡。特别是，考虑将item序列视为具有以下高斯参数化的多臂老虎机：

$$
N \left( \sum_{i=1}^{T} r_i, \prod_{\sigma_{ijk} > 0} \sigma_{ijk}^2 \right), \quad (5) 
$$

其中：**更好的多样性提供了item序列中更高的方差**[13, 18]。这也与多样性体积定义一致，更大的体积直观上代表更大的方差。注意，高斯变量的上置信界与其标准差成正比。本着面对不确定性时的乐观原则，公式(4)是一种**UCB类型的臂选择策略**[3, 21]。

SSD将整个item序列视为用户观察到的时间序列，并通过频谱分析分解其滑动表示。因此，我们称我们提出的方法为滑动频谱分解。

## 4.2 贪婪推理

我们已经将多样化feeds推荐问题表述为公式(4)中的最大优化问题。优化多样性项是一个组合张量分解问题，被证明是NP-hard[16]。在这一部分，我们提供了一个快速的贪婪推理算法来解决实践中的高效推理问题。

在贪婪推理的第t步中：

- 前t-1个item已经被选中，我们需要从候选集 $ Z \setminus I_{1:t} $ 中选择一个item，
- 其中 $ I_{p:q} $ 指的是 $\lbrace i_p, i_{p+1}, ..., i_{q-1} \rbrace  $。

让我们从时间步骤 $ t \leq w $ 开始。

当 $ t = 1 $ 时，选择质量最高的item是直接的。**在其他情况下，我们不需要知道每个奇异值的实际值，即我们只关心累积乘积**。回想一下，累积乘积在几何上等于体积。

当 $ t = 2 $ 并且我们考虑候选item j 时，**体积是由 $ i_1 $ 和 j 跨越的平行四边形的面积**：

$$ \| \mathbf{v}_{i_1} \| \| \mathbf{v}_j \sin(\mathbf{v}_{i_1}, \mathbf{v}_j) \| $$

- 其中 $ \| \cdot \| $ 表示 L2-范数。

注意 $ v_j \sin(v_{i_1}, v_j) $ 实际上是正交化的 $v_j $，标记为 $ v_j^{\perp } $，相对于 $v_{i_1} $：

$$
\mathbf{v}_j^{\perp } = \mathbf{v}_j - \frac{\langle \mathbf{v}_j, \mathbf{v}_{i_1} \rangle}{\langle \mathbf{v}_{i_1}, \mathbf{v}_{i_1} \rangle} \mathbf{v}_{i_1}, \quad (6)
$$

其中：

- $ j $ 在 $ i_1 $ 上的投影已从 $ \mathbf{v}_j $ 中移除。

当 $ t = 3 $ 时，相应的平行六面体的体积也可以通过对 $v_{i_1} $ 和 $v_{\perp i2} $ 的正交化候选项来计算。一般来说，这种正交化是**格拉姆-施密特过程[33]**，公式化为：

$$ 
\mathbf{v}_{ik}^{\perp} = 
  \begin{cases} 
  \mathbf{v}_{ik}, & \text{if } k = 1 \\
  T_{I_{1:k}}(\mathbf{v}_{ik}), & \text{otherwise}
  \end{cases}, \quad (7)
$$

其中：

$$
T_{I_{1:k}}(\mathbf{v}_{i_k}) = \mathbf{v}_{i_k} - \sum_{i \in I_{1:k}} \frac{\langle \mathbf{v}_{i_k}, \mathbf{v}_{i}^{\perp} \rangle}{\langle \mathbf{v}_{i}^{\perp}, \mathbf{v}_{i}^{\perp} \rangle} \mathbf{v}_{i}^{\perp}. \quad (8) 
$$

特别是，当没有滑动窗口时，我们可以重用候选item的正交化结果，这相当于一步修改的格拉姆-施密特（MGS）正交化[33]。有了这个技巧，我们的贪婪推理算法只有 $ O(NdT) $ 的时间复杂度，外加 $ O(1) $ 的空间复杂度。$ t \leq w $ 也相当于没有滑动窗口的情况。算法总结在算法1中。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/1fcdbf183cf043ccda9deb941240b93fee7fd6d01b91598c7a928f4f01b0116cf45788d0e7f67ad66c923fca45bbaca2?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=t1.jpg&amp;size=750">

算法1

让我们继续考虑 $ t > w $ 的时间步骤，我们需要考虑多个窗口。为了简化，让我们首先考虑 $ t = w + 1 $。遵循之前策略的一个可能方法是从 $ i_2 $ 开始正交化 $ I_{2:w+1} $。**然而，这种方法完全忽略了item $ i_1 $ 以及第一个窗口，这与通过组合多个窗口来测量整体多样性的SSD相悖**。因此，我们在当前窗口执行MGS，同时保留所有选定item的正交化结果，**允许当前窗口继承有关先前窗口的信息**。因此，在时间步骤 $ t $ 中，贪婪推理考虑以下目标：

$$
\max_{j \in Z\setminus I_{1:t}} r_j + \gamma \| T_{I_{l:t}} (\mathbf{v}_j) \|  \prod_{i \in I_{1:t}} \|\mathbf{v}_{i}^{\perp} \|, \quad (9) 
$$

其中:

- $ l = \max(1, t - w + 1) $。

注意上述目标保持了X的一阶正交化。由于X在前两阶上是对称的，公式(9)确保了正交化之后，在相同的列中任意一组连续的 $ w $ 个元素在第一阶和第二阶上是正交的。

与没有滑动窗口的情况相比，我们需要额外的还原操作。例如，在时间步骤 $ w + 1 $ 中，我们需要对 $ Z \setminus I_{1:w+1} $ 中所有剩余的候选项在 $ i_1 $ 上的投影进行还原。这些还原操作需要 $ O(NdT) $ 的时间复杂度，外加 $ O(wN) $ 的空间来存储这些投影。因此，总的时间复杂度仍然是 $ O(NdT) $。为了进一步加速实际实现，我们进一步提出应用循环队列技巧来减少内存复制[10]。算法总结在算法2中。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/bc5d3df70f176da453b17d802d77721527f8346862f1d12a527369f5ee3b08a0f9ed416ad0e52f07225d0cd80f03d003?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=a2.jpg&amp;size=750">

算法2

## 4.3 分析

之前我们已经介绍了用于多样化feeds推荐的SSD（滑动频谱分解）和相应的贪婪推理算法。SSD将item序列视为用户观察到的时间序列，通过在整个序列中组合多个滑动窗口来与用户浏览feeds时的感知对齐。这种观点是我们与其他多样化推荐工作的主要区别之一。
SSD使用由多个窗口组成的三阶张量的体积来定义多样性。与之最相关的想法是DPP（行列式点过程）[9]。在本节中，我们首先证明在没有滑动窗口的情况下，SSD中的多样性项与DPP中的相同。然后我们分析这两种方法之间的区别。最后，我们比较了SSD和DPP在有无滑动窗口情况下贪婪推理的复杂性。

当多样性仅在单个窗口内需要时，考虑对 $P_t = U \sigma V^T \in R^{t \times d} $ 进行奇异值分解，其中 $\mathbf{P}_t$ 的第i行是 $ \mathbf{v}_{i_t} $。然后我们可以得到：

$$ 
\det(\mathbf{P}_t \mathbf{P}_t^T) = \det(\mathbf{U} \Sigma \mathbf{V}^T \mathbf{V} \Sigma^T \mathbf{U}^T) = (\det(\Sigma))^2. \quad (10) 
$$

注意：

- $ \mathbf{P}_t \mathbf{P}_t^T $ 是DPP中的核心矩阵，当忽略质量时，右侧是SSD目标中的平方多样性项。矩阵的行列式表示几何中的体积，即DPP也使用由 $ I_1:t+1 $ 跨越的 $ t $ 维超平行六面体的体积来表示多样性。因此，没有滑动窗口的情况下，SSD和DPP对多样性的定义是相同的。在滑动窗口的情况下，SSD将这种体积推广到三阶张量，以组合多个窗口，我们认为这更符合用户在feeds推荐中的感知。

DPP和SSD之间的主要区别有两个方面。

- 1.DPP是来自物理学的强大概率技术，用于测量多样性，其中一组item的选择概率与核矩阵相对于的行列式成正比。DPP的假设中没有顺序概念。换句话说，是贪婪推理过程为DPP的推荐提供了序列。对于长序列，必须考虑滑动窗口以满足用户的感知。然而，DPP没有提供组合多个窗口的方法，完全忽略视窗外的信息过于严格。SSD反而将feeds视为时间序列，将顺序和滑动窗口都包含在轨迹张量中。
- 2.在DPP的框架中，选择概率与体积成正比，其中质量作为相应item embedding的乘数。这种组合在几何上是可解释的，体积随质量的增加而单调增加。换句话说，在DPP中，质量是自然嵌入的一种增强器。对于feeds推荐，推荐器大多数时间利用用户的过去互动，同时探索他们的兴趣。受到这种行为的启发，SSD反而认为多样性在质量下扮演着探索者的角色，采用利用-探索策略。

回想一下，[9]为DPP提出了一个快速的贪婪推理算法，其中需要一个核矩阵 $ \mathbf{K} $。对于大规模推荐器，预先计算具有密集item embedding的 $ \mathbf{K} $ 在离线时是不切实际的。在在线服务期间，$ \mathbf{K} $ 需要 $ O(N^2d) $ 的时间复杂度和额外的 $ O(N^2) $ 空间。回想一下，没有滑动窗口的情况下，SSD与DPP返回相同的结果，但在我们的提议的贪婪推理算法中，不需要 $ \mathbf{K} $。此外，在滑动窗口情况下，我们只与最后选择的item进行正交化，使时间复杂度与窗口大小 $ w $ 无关。复杂性比较总结在表1中。在贪婪推理下，SSD比DPP更高效。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/1fcdbf183cf043ccda9deb941240b93fee7fd6d01b91598c7a928f4f01b0116cf45788d0e7f67ad66c923fca45bbaca2?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=t1.jpg&amp;size=750">

表1

# 5 item embedding

在上一节中介绍的SSD方法要求item embedding在内积空间中。任何item $ i $ 由embedding向量 $ \mathbf{v}_i $ 表示，它与任何其他item $ j $ 的相似度计算为 $ \langle \mathbf{v}_i, \mathbf{v}_j \rangle $。这里，我们描述了如何在长尾效应下计算准确的item相似度的embedding向量。尽管与[5]有所不同，我们称我们的策略为CB2CF。

## 5.1 模型架构

嵌入模型的网络结构如图5所示。我们采用了**并联网络（siamese）**架构[6]，在视觉和自然语言应用[25]中广泛用于相似度计算。并联网络能够自然地从item pair对中学习item embedding，无需在训练期间决定item的顺序，或在推理时选择模型的分支。给定一个item，我们以**item描述和封面图像**为输入，并在预训练模型的帮助下分别为它们创建文本表示和图像表示。对于文本描述，我们采用BERT[12]作为基础模型，并遵循标准流程，将对应第一个标记的隐藏状态作为嵌入。对于封面图像，使用Inception-V3[31]模型获得图像表示。然后，我们通过连接它们相应的表示，然后通过一个全连接输出层到目标嵌入 $ \mathbf{v} $。最后，我们计算成对item embedding之间的**余弦距离**。我们将在5.3节中解释采用余弦距离的原因。我们将这个问题视为二元分类任务，并使用交叉熵损失作为目标。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/c69a8f944aa301e5379a10235e62c0649afb70c317f84600112fe56047d5a81d95e6100d0e20b15d522cfccc130e2ad3?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;fname=5.jpg&amp;size=750">

图5 

## 5.2 训练数据

接下来，我们讨论如何为嵌入模型收集训练样本。

首先，只有**item内容，如文本描述、封面图像和视频封面图**像被用作嵌入模型中的特征。用户参与度不作为特征使用。这样做，模型被迫纯粹从item内容中推断相似度。这防止了模型至少在特征级别上受到长尾效应的影响，因为：**即使用户参与度很少(或没有)的item，也可以通过模型以足够的内容特征可靠地计算其embedding向量**。

其次，对于任何有用户参与的item $i$，如果item $j$ 通过ItemCF方法[22]以item $i$ 作为种子item被检索出来，并且item $j$ 在最终推荐结果中获得了足够的曝光，我们有很高的信心认为从用户的角度来看，**item i和j是非常相似的**。ItemCF基于用户参与度确保了i和j之间基本的用户感知相似度。如果j多次在推荐系统中存活下来，为许多用户获得曝光，那么j对许多用户来说很可能与i相似。**我们将这些item pair对 $ < i, j > $ 视为正样本**。

这个样本集受长尾效应的影响不大，因为即使用户参与度很少的item也可以作为种子item i。然而，item j更可能是头部item，因为我们的策略要求它有一些最小的曝光。这也是我们不对j需要任何用户参与度的原因，因为这将进一步增加j成为头部item的概率。

设计的一个优点是：它使得**长尾item和头部item之间建立相似关系成为可能**。这可以帮助嵌入模型从item内容中泛化，推断出相似度，即使是长尾item。

最后，**对于任何有用户参与的item $ i $，我们随机采样一个通过ItemCF方法检索的item $ j' $，并使用这些item pair对 $ < i, j' > $ 作为负样本**。如果我们允许 $ j' $ 是任何随机item，我们发现在实践中负样本对嵌入模型来说太容易了，它停止过早地学习。所有上述训练样本都可以从现有的推荐系统中轻松自动收集。我们的方法与原始的CB2CF工作[5]不同，因为我们不将item内容映射到CF向量[27]。相反，我们迫使模型从item内容中学习，推断出由ItemCF方法产生的加强相似性信号。

## 5.3 归一化

如前所述，SSD将选定item embedding跨越的平行四边形体积推广到滑动窗口情况，以匹配用户在feeds推荐中的感知。在使用CB2CF训练中的内积作为距离时，item的L2范数是无界的。这种无界性可能导致item之间严重的不公平，因为它为体积提供了不可控的贡献。因此，我们特别指定余弦相似度作为CB2CF训练中的距离，使所有嵌入具有相同的L2范数，即位于高维单位球表面。

另一个问题是**余弦距离和体积之间的不匹配**。体积通常在内积空间中定义，如果两个向量的内积为0，则它们完全不同。使用余弦距离时，完全不同的对的值变为-1。我们通过在**归一化后添加一个额外的维度元素1**来解决这个问题：

$$ 
\mathbf{v} = \left[ \frac{\mathbf{v}^{\prime}}{\|\mathbf{v}^{\prime}\|}, 1 \right], \quad (11) 
$$

其中：

- $ \mathbf{v}^{\prime} $ 是CB2CF的输出。

这种转换保持了由余弦描述的相似度，并在SSD中实现了公平性和几何属性。

# 实验

略

- 1.[https://arxiv.org/pdf/2107.05204](https://arxiv.org/pdf/2107.05204)