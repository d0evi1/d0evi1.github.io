---
layout: post
title: PAL position bias介绍
description: 
modified: 2019-11-01
tags: 
---

华为在《PAL: a position-bias aware learning framework for CTR prediction in live recommender systems》提出了一种解决position-bias方法。

# 摘要

在推荐系统中精准预测CTR很重要。CTR模型通常基于来自traffic logs收集得到的feedback训练得到。然而，**在user feedback中存在position bias，因为用户在一个item上的点击(clicks)不仅仅只因为用户喜欢这个item，还有可能是因为它具有一个较好的position**。解决该问题的一种方式是：在训练数据中将position建模成一个feature。由于很简单，这种方法在工作界被广泛应用。**然而，使用不同的default position值可能会导型完全不同的推荐结果**。因些，该方法会导致次优(sub-optimal)的线上效果。为了解决该问题，在该paper中，我们提出了一种**P**osition **A**ware **L**earning framework（PAL）来解决该问题。**它可以建模在offline training中的position-bias，并在online inference时不使用position information**。我们在一个三周的AB test上进行实验，结果表明，PAL的效果在CTR和CVR（转化率ConVersion Rate）指标上要比baseline好3%-35%。

# 1.介绍

实际生产环境中的推荐系统包含两个过程：offline training和online inference，如图2所示。在offline training中，会基于从traffic logs中收集到的user-item interaction信息训练一个CTR预估模型。在online inference中，训练好的模型会部署到真实线上来做出预测。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/f7519feaedcb57e591995eeb65c4a8866bb80bf721ebc76db21c7bc243cf2d4f9c84b5b514ee2035026abe67bbbde3d2?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=2.jpg&amp;size=750">

图2 不同position上的CTR

有个问题是，user-item interaction是受展示该item的positions影响的。在[14]中，CTR会随着display position快速下降。相似的，我们也在华为maintream APP store上观察到了这样的现象。如图1所示，不管是整体的App Store (图1(a))，或是单个特定App（图1(b)），我们可以观察到，normalized CTR会随着position显著下降。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/9ea04d07f3d7f05b0ab8c273448ee18615757783b35b9ea70beee75fc6be6c1d76fb08ad9079a9be811dfb6f5d9fc431?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=1.jpg&amp;size=750">

图1 生成推荐的workflow

这样的观察表明，用户点击某个item可能不仅仅是因为喜欢这个item，还有可能是因为在一个好的position上。**因此，从traffic logs中收集得到的training data包含了positional bias**。我们将该现象称为“position-bias”。作为CTR信号的一个重要因子，在offline training中将position-bias建模到CTR预测模型中是很必要的。

尽管提出了许多click models来建模training data中的position-bias【1-3】，在现实问题中（在online inference中position信息是不提供的）这样的研究很有限。一个实用（practical）的方法是反向加权（inverse propensity weighting）【15】。在该方法中，在position信息使用一个用户定义的转换，接着该转换后的值固定。然而，如【10】所述，对于position信息很难设计一个好的转换，这会产生比自动学到的转换更差的效果。因此，【10】的作者提出在训练数据中将position建模成一个feature，这种方法在工业界广泛使用。特别的，在online inference中使用一个default position value来预测CTR，因为actual position information在那时并没提供。不幸的是，使用不同的default position values可能会导致完全不同的推荐效果，这会导致生成一个次优的online performance。

在本paper中，我们提出了PAL来建模position-bias。PAL的思想基于以下假设：一个item被用户点击基于两个因素（给定item被user看到）：

- a) item被用户看到的概率
- 用户在该item上点击的概率

每个factor在PAL中会被建模块“as a module”，这两个modules的outputs的产品是一个item被用户点击的概率。如果两个modules单独进行optimzied，它会导至整个系统达到一个次优的状态，因为两个modules的training objectves间不一致性（inconsistency），正如[18]中所述。为了避免这样的限制，并生成更好的CTR预测效果，PAL中的两个modules会同时进行jointly optimized。一旦这两个modules在offline training下训练完全成，第二个module可以部署到online inference上来预测CTR。


# 2.方法

## 2.1 概念

我们假设：offline的点击数据集为 ：$$S = \lbrace (x_i, pos_i \rightarrow y_i) \rbrace_{i=1}^N$$

其中：

- N是总样本数
- $$x_i$$是样本i的feature vector，它包含了：user profile, item features和context信息
- $$pos_i$$是样本i的position信息
- $$y_i$$是user feedback（如果user在该item进行点击，则$$y_i=1$$；否则$$y_i=0$$）

我们会使用x，pos，和y来分别表示feature vector、position信息和label。

## 2.2 Preliminary

有两个方法对在offline training中的position-bias进行建模，称为“as a feature”和"as a module"。

**As a feature**

该方法会将position信息建模成一个feature。在offline training中，CTR模型的input feature vector是x和pos的concatenation，例如：$$\hat{x} = [x, pos]$$。然后基于该concatenated feature vector训练一个CTR预测模型。

由于position信息被建模成offline training中的一个feature，在oline inference中也应包含一个表示“position”的feature，如图3的右侧所示。然而当执行online inference时，position信息是不提供的。一种解决该问题(在inference时缺失该position)的方法是：为每个position，按top-most position到bottom-most position顺序，判断最适合的item。可以分析得到，brute-force方法具有$$O(l n T)$$的时间复杂度（其中：l是ranking list的长度，n是candidate items的数目，T是inference的latency），它对于一个低延迟的在线环境来说是不可接受的。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/efd95483e4f604a55f2d8b73bd454136f533a4737cb0281d996d80432dbf2d31ede66b5278a905e274d96052cb89849d?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=3.jpg&amp;size=750">

图3	PAL framework vs. BASE

为了减短延时，可选择一种【10】中描述的具有O(nT)复杂度的方法，它会为所有items选择一个position来作为position feature的值。**然而，不同的position value会产生完全不同的推荐结果。因此，我们需要寻找一个合适的position值来达到好的online performance**。这里有两种方法来比较使用不同position values进行inference的效果： online experiment和offline evaluation。前者很好，但代价高。因此，我们必须采用offline evaluation来选择合适的position value。另外，不管是使用online experiment或offline evaluation来选择position value，它都不具备良好的泛化特性，因为对于某一个应用场景的online inferenece的position value并不适用于另一个场景。

**As a module**

为了解决将position信息作为一个feature的上述缺陷，我们提出了一个新的框架来将position信息作为一个module，因此，我们可以在offline training中建模position-bias，并在没有position信息的online inferenece中使用。

# 3.PAL Framework

我们的framework受以下假设的启发：**一个item被一个用户点击，只因为被该用户看到了**。更特别的，给定item被用户看到，那么我们认为用户点击一个item的概率依赖于两个因素：

- a) item被用户看到的概率
- b) 用户在该item上被点击的概率

如等式(1)所示：

$$
p(y=1 | x, pos) = p(seen | x, pos) p(y = 1 | x, pos, seen)
$$

...(1)

如果我们进一步假设：

- a) 一个item已经被看到(seen)的概率只与该相关position被观察到的概率相关
- b) 一个item被点击(click)的概率与该position是否被看到(seen)相互独立

那么，等式(1)被简化成等式(2) ：

$$
p(y=1 | x, pos) = p(seen | pos) p(y=1 | x, seen)
$$

...(2)

如图3左侧所示，我们的PAL框架基于等式(2)设计，并包含了两个modules：

- ProbSeen：第一个module会对概率$$p(seen \mid pos)$$建模，它通过图3中的"ProbSeen"进行表示，将position信息pos作为input
- pCTR：第二个module会对概率$$p(y=1 \mid x, seen)$$进行建模，它表示了图3中的"pCTR"，表示该模型predicted CTR。它的输入是training data中的feature vector x。

任意CTR预测模型（比如：linear models和deep learning models）都可以应用于这两个modules上。

接着，**学到的CTR被表示成图3中的"bCTR"，它会将在offline training中的position bias认为是这两个modules的输出的乘积**。如【18】所示，如果两个modules被单独进行优化，不同的training objectives间的不一致（inconsistency）会导致整体系统达到一个次优（sub-optimal）的状态。为了避免这样的次优（sub-optimal）效果，我们在该framework中会对这两个modules进行jointly和simultaneously训练。更特别的，PAL的loss function被定义成：

$$
L(\theta_{ps}, \theta_{pCTR}) = \frac{1}{N} \sum\limits_{i=1}^N l(y_i, bCTR_i) = \frac{1}{N} \sum\limits_{i=1}^N l(y_i, ProbSeen_i \times pCTR_i)
$$

...(3)

其中，$$\theta_{ps}$$和$$\theta_{pCTR}$$分别是ProbSeen module和pCTR module的参数，其中$$l(\cdot)$$是cross-entropy loss function。pCTR module，被用于online inference过程，并不会被直接最优化。实际上，当label和predicted bCTR间的logloss最小化时，ProbSeen和pCTR modules的参数可以如等式(4)和等式(5)通过SGD进行最优化，以便position-bias和user preference的影响会分别被隐式学到。

$$
\theta_{ps} = \theta_{ps} - \eta \cdot \frac{1}{N} \sum\limits_{i=1}^N (bCTR_i - y_i) \cdot pCTR_i \cdot \frac{\partial ProbSeen_i}{\partial \theta_{ps}}
$$

...(4)

$$
\theta_{pCTR} = \theta_{pCTR} - \eta \cdot \frac{1}{N} \sum\limits_{i=1}^N (bCTR_i - y_i) \cdot ProbSeen_i \cdot \frac{\partial pCTR_i}{\partial \theta_{pCTR}}
$$

...(5)

在offline training过程中，与[5,13,16]相似，early stop策略被用在训练过程中来获得well-trained model。一旦PAL被well-trained，module pCTR可以被部署到线上进行CTR inference。很容易观察到，position在PAL中的pCTR module并不需要，因此，我们不需要像“as a feature”那样在online inference时分配position values。

# 3.在线实验

在真实推荐系统中设计在线实验来验证PAL的效果。特别的，我们使用一个三周的AB test来验证PAL vs. "as a feature"的baseline方式。AB test在Company X的app Store的游戏中心的游戏推荐场景进行。

## 3.1 Datasets

在CompanyX的AppStore生产环境中，我们从traffic logs中抽样了10亿样本作为offline training dataset。为了更新我们的模型，training dataset以一个sliding time-window style的方式进行refresh。training的features包含了app features（例如：app id, category 等）、user features（比如：downloaded、click history等）、context features（例如：操作时间等）。

## 3.2 Baseline

baseline framework指的是“as a feature”策略。实际上，该baseline采用的是在[10]中的方法。正如所声明的，我们需要选择一个合适的position value作为online inference。然而，由于资源有限，对于使用所有可能positions来评估baseline framework是不可能的。因此，我们会选择合适的positions来进行offline experiment。

**Settings**。为了选择合适的position(s)，我们收集了**两个场景的数据集(dataset 1和dataset 2)**。test dataset通过next day的traffic logs中收集得到。我们在test dataset中使用不同的position values，范围从position 1到position 10. 与[5,11,13,16]相似，采用AUC和LogLoss来作为metrics对离线效果进行评估。

**结果和分析**。offline实验的结果如图5所示，其中Base_pk是具有position value k的baseline framework，它会为test data中的所有items分配该值。PAL框架所使用的test data没有position values。**从图5看到，分配不同position values，AUC和LogLoss值在test data上变化很大**。另外，BASE_p9可以达到最高的AUC，BASE_p5可以达到最低的LogLoss，**Base_p1可以在AUC和LogLoss上同时达到最差的效果**。我们选择最好的（BASE_p5和BASE_p9）以及最差的（BASE_p1）这两个作为baselines来做与PAL做online ABtest。**值得注意的是，PAL在offline experiment中对于AUC或LogLoss均不会达到最好的效果**。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/d56020246ea8ae100f7cc459122500b3395235aba7b939de2d4c3d2b160387618a1d17a9225724d33ddb186af9b5efb6?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=5.jpg&amp;size=750">

图5 offline实验结果

## 3.3 AB test

**Settings**。对于control group，2%的用户被随机选中，并使用baseline framework生成的推荐结果进行呈现。对于experimental group，2%的users使用PAL生成的推荐结果进行呈现。在baseline和PAL中使用的模型是DeepFM，并使用相同的网络结构和相同的特征集。由于资源限制，我们不会在同一时间部署三个baseline（BASE_p1, BASE_p5和BASE_p9）。相反的，他们只会一个接一个地部署，每个轮流一周时间，来对比PAL。更特别的，我们会在每周分别对比PAL vs. BASE_p1､ PAL vs. BASE_p5､PAL vs. BASE_p9.

**Metrics**

我们采用两种metrics来对比PAL和baselines的在线效果，称为：realistic CTR：$$rCTR = \frac{\#downloads}{\#impressions}$$ 以及 realistic Conversion Rate：$$rCVR = \frac{\#downloads}{\#users}$$，其中#downloads, #impressions 以及 #users分别表示天级别的下载数、曝光数、访问用户数。这与predicted CTR不同（例如图3中的“pCTR”），"rCTR"是我们在线观察到的realistic CTR。

**结果**

图4表示了online experiements的结果。蓝色和红色的histograms展示了PAL对比baseline在rCTR和rCVR上的提升。首先，rCTR和rCVR的metrics在整个三周的AB test上均获得提升，验证了PAL要比baselines要好。第二，我们也观察到，首周中（baseline使用BASE_p1）rCTR和rCVR（图4虚线）的平均提升是最高的，第二周最低（baseline使用BASE_p5）。该现象告诉我们，baseline的效果对于分配不同的position values区别很大，因为推荐可能与所分配的不同的position values完全不同。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/413550d8403388e7a0f736cc37ba9cec5822e532df9a1b5e3b28eac1bd173965e011d8a97b28f4a6028e993ffbf084fa?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=4.jpg&amp;size=750">

图4 Online AB test的结果

## 3.4 在线分析

为了完全理解AB test，并验证我们提出的框架在online inference上消除，我们分析了PAL和baselines的推荐结果。

**第一个实验是为了对比与ground truth ranking之间的ranking distance**。我们将ground truth ranking定义成一个关于items的list，它通过$$f(rCTR, bid)$$的值降序排列。会采用Spearman's Footrule来measure在两个rankings中的位移 (displacement)，它被广泛用于measure两个rankings间的距离。我们定义了【ground truth ranking】与【由PAL或baselines生成的ranking $$\delta_M$$】在top-L上的距离，如下所示：

$$
D(\delta_M, L) = \frac{1}{|U|} \sum\limits_{u \in U} (\sum\limits_{i=1}^L |i - \delta_{M,u}(i)| )
$$

...(6)

其中：

- u是在user group U中的一个具有popularity $$\mid U \mid$$的user
- $$\delta_{M,u}$$是由model M为user u生成的推荐列表
- $$\delta_{M,u}(i)$$：在ground truth ranking中的第i个item在推荐$$\delta_{M,u}$$中的position 处

我们对比了$$M \in \lbrace PAL, BASE_{p1}, BASE_{p5}, BASE_{p9} \rbrace$$以及$$L \in [1, 20]$$的$$D(\delta_M, L)$$，如图6(a)所示，其中，线色实线是PAL的结果，其它线是baselines的结果。我们可以看到，PAL会生成对比ground truth ranking最短的距离，这意味着由PAL生成的推荐与我们在线观察到的real ranking最相似。这通过PAL在offline training中使用position-bias建模、并在online inference中消除position-bias来完成，这可以解释，PAL的效果要好于baselines。

<img alt="图片名称" src="https://picabstract-preview-ftn.weiyun.com/ftn_pic_abs_v3/b632367a3dd4e680b15b883ffba43d0fbc5e401b2f6cfa551aa7edbf690e2129b876ed9adf50f7925ce096c33c036c3e?pictype=scale&amp;from=30113&amp;version=3.3.3.3&amp;uin=402636034&amp;fname=6.jpg&amp;size=750">

图6 online分析

**第二个实验对比了PAL和baselines间的个性化（personalization）**。Personalization@L 可以mearure 在一个跨不同users的ranking中top-L的inter-user diversity（推荐结果的一个重要因子）。Personalization@L由等式(7)定义：

$$
Personlization@L = \frac{1}{ |U| \times (|U|-1)} \sum\limits_{a \in U} \sum\limits_{b \in U} (1 - \frac{q_{ab}(L)}{L})
$$

...(7)

其中，$$\mid U \mid$$是user group U的size，$$q_{ab}(L)$$是user a和user b在top-L中公共items的数目。Personlization@L 越高表明，跨不同users在top-L positions上更diverse的推荐items。

我们分别计算了关于PAL 以及baselines的personalization@L。图6(b)表明，在top-5(L=5）、top-10(L=10)以及top-20(L=20)上不同frameworks关于推荐的的personalization。我们可以看到在推荐中由PAL生成的的top items会比baselines生成的更多样一些。由于PAL能在消除position-bias影响后更好地捕获到不同users的特定兴趣、以及根据用户个性化兴趣生成的推荐items。

# 参考

- 1.[https://www.researchgate.net/publication/335771749_PAL_a_position-bias_aware_learning_framework_for_CTR_prediction_in_live_recommender_systems](https://www.researchgate.net/publication/335771749_PAL_a_position-bias_aware_learning_framework_for_CTR_prediction_in_live_recommender_systems)